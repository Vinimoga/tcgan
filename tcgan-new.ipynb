{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÃ³digos relevantes para consulta...\n",
    "* vis.py: C:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\metrics\\vis.py\n",
    "* exp.py: C:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\exp.py\n",
    "* eval.py: C:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\eval.py\n",
    "* tcgan.py: C:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\model\\tcgan\\tcgan.py\n",
    "* base.py: C:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\metrics\\base.py\n",
    "* config.py: C:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\model\\tcgan\\config.py\n",
    "* config.py: C:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fire\n",
    "\n",
    "from mlpy.lib.utils.path import makedirs, tag_path\n",
    "from mlpy.lib.utils.log import set_logging\n",
    "from mlpy.lib.tfops.base import tf_keras_set_gpu_allow_growth\n",
    "from mlpy.configure import DIR_DATA_UCR15\n",
    "from mlpy.datasets.ucr_uea.data_names import UCR85_DATASETS\n",
    "\n",
    "from tcgan.lib.exp import Experiment\n",
    "from configure import DIR_LOG\n",
    "from tcgan.model.tcgan import TCGAN, TCGANConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/10 12:03:13 AM, INFO, github_: ****** process dataset 50words\n",
      "use_testset=True\n",
      "09/10 12:03:13 AM, INFO, github__50words: ****** configure init ******\n",
      "09/10 12:03:14 AM, INFO, github__50words: The settings are as follows: \n",
      "strides:2\n",
      "padding:same\n",
      "initializer:<tensorflow.python.keras.initializers.initializers_v2.TruncatedNormal object at 0x000001C21CB62DD8>\n",
      "leak_slope:0.2\n",
      "logger:<Logger github__50words (INFO)>\n",
      "log_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\n",
      "train_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\\training\n",
      "eval_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\\evaluation\n",
      "ckpt_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\\checkpoint\n",
      "ckpt_prefix:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\\checkpoint\\ckpt\n",
      "seed:42\n",
      "np_rs:RandomState(MT19937)\n",
      "verbose:1\n",
      "x_shape:(270, 1)\n",
      "noise_shape:(100,)\n",
      "noise_method:normal\n",
      "noise_sampler:<function random_normal at 0x000001C27DA2CB70>\n",
      "batch_size:16\n",
      "epochs:300\n",
      "g_lr:0.0002\n",
      "d_lr:0.0002\n",
      "g_beta1:0.5\n",
      "d_beta1:0.5\n",
      "g_units_base:32\n",
      "d_units_base:32\n",
      "d_layers:4\n",
      "g_layers:4\n",
      "d_dropout_rate:0.0\n",
      "g_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "d_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "kernel_size:10\n",
      "acc_threshold_to_train_d:0.75\n",
      "ckpt_max_to_keep:2\n",
      "n_epochs_to_save_ckpt:15\n",
      "n_to_evaluate:3\n",
      "n_epochs_to_evaluate:100\n",
      "n_examples_to_generate:16\n",
      "metrics:['nnd', 'mmd', 'vis']\n",
      "noise_seed:[[-0.28077507 -0.1377521  -0.6763296  ... -0.66411126  1.4531434\n",
      "   0.63142705]\n",
      " [ 1.4347553  -0.9590058   1.399536   ...  0.09790254 -0.8498453\n",
      "   0.8285087 ]\n",
      " [ 0.9079667  -0.53826797 -0.75165933 ...  0.00500222  0.46697247\n",
      "  -0.49156648]\n",
      " ...\n",
      " [ 1.0430238  -0.2649641  -0.44542065 ... -0.44225916  0.05121567\n",
      "   0.56583524]\n",
      " [-0.35650563  1.5591161   0.22819136 ...  1.8435367  -0.66581184\n",
      "  -0.97975284]\n",
      " [-1.3944459  -0.31205386  0.46640927 ... -0.12672192  2.9069102\n",
      "  -1.0910585 ]]\n",
      "\n",
      "Reuse layer=-3 for classification.\n",
      "(270, 1)\n",
      "09/10 12:03:15 AM, INFO, github__50words: Generator's summary: \n",
      "09/10 12:03:15 AM, INFO, github__50words: Model: \"functional_1\"\n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: Layer (type)                 Output Shape              Param #   \n",
      "09/10 12:03:15 AM, INFO, github__50words: =================================================================\n",
      "09/10 12:03:15 AM, INFO, github__50words: input_1 (InputLayer)         [(None, 100)]             0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: dense_0_dense (Dense)        (None, 4352)              439552    \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: dense_0_norm (BatchNormaliza (None, 4352)              17408     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: dense_0_relu (ReLU)          (None, 4352)              0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: reshape (Reshape)            (None, 17, 256)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_conv (Conv1DTranspose (None, 34, 128)           327808    \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_norm (BatchNormalizat (None, 34, 128)           512       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_relu (ReLU)           (None, 34, 128)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_conv (Conv1DTranspose (None, 68, 64)            81984     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_norm (BatchNormalizat (None, 68, 64)            256       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_relu (ReLU)           (None, 68, 64)            0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_conv (Conv1DTranspose (None, 135, 32)           20512     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_norm (BatchNormalizat (None, 135, 32)           128       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_relu (ReLU)           (None, 135, 32)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_conv (Conv1DTranspose (None, 270, 1)            321       \n",
      "09/10 12:03:15 AM, INFO, github__50words: =================================================================\n",
      "09/10 12:03:15 AM, INFO, github__50words: Total params: 888,481\n",
      "09/10 12:03:15 AM, INFO, github__50words: Trainable params: 879,329\n",
      "09/10 12:03:15 AM, INFO, github__50words: Non-trainable params: 9,152\n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: Discriminator's summary: \n",
      "09/10 12:03:15 AM, INFO, github__50words: Model: \"functional_3\"\n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: Layer (type)                 Output Shape              Param #   \n",
      "09/10 12:03:15 AM, INFO, github__50words: =================================================================\n",
      "09/10 12:03:15 AM, INFO, github__50words: input_2 (InputLayer)         [(None, 270, 1)]          0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_conv (Conv1D)         (None, 135, 32)           352       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_relu (LeakyReLU)      (None, 135, 32)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_dropout (Dropout)     (None, 135, 32)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_conv (Conv1D)         (None, 68, 64)            20544     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_relu (LeakyReLU)      (None, 68, 64)            0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_dropout (Dropout)     (None, 68, 64)            0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_conv (Conv1D)         (None, 34, 128)           82048     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_norm (BatchNormalizat (None, 34, 128)           512       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_relu (LeakyReLU)      (None, 34, 128)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_dropout (Dropout)     (None, 34, 128)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_conv (Conv1D)         (None, 17, 256)           327936    \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_norm (BatchNormalizat (None, 17, 256)           1024      \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_relu (LeakyReLU)      (None, 17, 256)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_dropout (Dropout)     (None, 17, 256)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: flatten (Flatten)            (None, 4352)              0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: dense (Dense)                (None, 1)                 4353      \n",
      "09/10 12:03:15 AM, INFO, github__50words: =================================================================\n",
      "09/10 12:03:15 AM, INFO, github__50words: Total params: 436,769\n",
      "09/10 12:03:15 AM, INFO, github__50words: Trainable params: 436,001\n",
      "09/10 12:03:15 AM, INFO, github__50words: Non-trainable params: 768\n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: ****** fit start ******\n",
      "09/10 12:03:15 AM, INFO, github__50words: train from scratch.\n",
      "09/10 12:03:16 AM, INFO, github__50words: ****** eval start ******\n",
      "09/10 12:03:17 AM, INFO, github__50words: tsne, time=1.0196175575256348\n",
      "09/10 12:03:17 AM, INFO, github__50words: nnd, time=0.08635735511779785\n",
      "09/10 12:03:18 AM, INFO, github__50words: mmd, time=0.7134261131286621\n",
      "09/10 12:03:18 AM, INFO, github__50words: ****** eval end ******\n",
      "09/10 12:03:24 AM, INFO, github__50words: epoch[1/300], d_loss=0.7246, g_loss=1.028, real_loss=0.1916, fake_loss=0.533, acc=0.811, , time=6.228\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-156bafc8c3c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                     **exp_cfg)\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mfire\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\fire\\core.py\u001b[0m in \u001b[0;36mFire\u001b[1;34m(component, command, name)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaller_locals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m   \u001b[0mcomponent_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Fire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparsed_flag_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcomponent_trace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHasError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\fire\\core.py\u001b[0m in \u001b[0;36m_Fire\u001b[1;34m(component, args, parsed_flag_args, context, name)\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[0mcomponent_trace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[0mtreatment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'class'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_class\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'routine'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m             target=component.__name__)\n\u001b[0m\u001b[0;32m    472\u001b[0m         \u001b[0mhandled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mFireError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\fire\\core.py\u001b[0m in \u001b[0;36m_CallAndUpdateTrace\u001b[1;34m(component, args, component_trace, treatment, target)\u001b[0m\n\u001b[0;32m    679\u001b[0m     \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvarargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m     \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvarargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtreatment\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\exp.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, i_run)\u001b[0m\n\u001b[0;32m    236\u001b[0m                                         \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                                         **self.kwargs)\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mexp_unit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_name_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres_eval_fnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres_out_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\exp.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\exp.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvaluatorGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_tr_gan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_te_gan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\model\\tcgan\\tcgan.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data, test_data, restore, ckpt_number)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_sampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[0m_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[0m_res_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tag = tag_path(os.path.abspath(os.getcwd()), 2)\n",
    "log_dir = makedirs(os.path.join(DIR_LOG, tag))\n",
    "logger = set_logging(tag, log_dir)\n",
    "# data_name_list = UCR85_DATASETS\n",
    "data_name_list = ['50words']\n",
    "\n",
    "model_cfg = dict(acc_threshold_to_train_d=0.75, kernel_size=10)\n",
    "exp_cfg = dict(use_testset=True, idx_layer=-3)\n",
    "exp = Experiment(tag, TCGAN, TCGANConfig, DIR_DATA_UCR15, data_name_list, log_dir,\n",
    "                    model_cfg_kwargs=model_cfg,\n",
    "                    **exp_cfg)\n",
    "\n",
    "fire.Fire(exp.run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sines data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mlpy.lib.utils.path import makedirs\n",
    "\n",
    "DIR_DATA = './TimeGANSine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine_data_generation(no, seq_len, dim):\n",
    "    \"\"\" copy from: https://github.com/jsyoon0823/TimeGAN/blob/master/data_loading.py\n",
    "    Sine data generation.\n",
    "\n",
    "  Args:\n",
    "    - no: the number of samples\n",
    "    - seq_len: sequence length of the time-series\n",
    "    - dim: feature dimensions\n",
    "\n",
    "  Returns:\n",
    "    - data: generated data\n",
    "  \"\"\"\n",
    "    # Initialize the output\n",
    "    data = list()\n",
    "\n",
    "    # Generate sine data\n",
    "    for i in range(no):\n",
    "        # Initialize each time-series\n",
    "        temp = list()\n",
    "        # For each feature\n",
    "        for k in range(dim):\n",
    "            # Randomly drawn frequency and phase\n",
    "            freq = np.random.uniform(0, 0.1)\n",
    "            phase = np.random.uniform(0, 0.1)\n",
    "\n",
    "            # Generate sine signal based on the drawn frequency and phase\n",
    "            temp_data = [np.sin(freq * j + phase) for j in range(seq_len)]\n",
    "            temp.append(temp_data)\n",
    "\n",
    "        # Align row/column\n",
    "        temp = np.transpose(np.asarray(temp))\n",
    "        # Normalize to [0,1]\n",
    "        temp = (temp + 1) * 0.5\n",
    "        # Stack the generated data\n",
    "        data.append(temp)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def sine_dim5_len24_random(r=0):  # the primitive data\n",
    "    seq_len = 24\n",
    "    no, dim = 10000, 5\n",
    "    data = sine_data_generation(no, seq_len, dim)\n",
    "    data = np.stack(data)\n",
    "    np.save(os.path.join(DIR_DATA, f'sine_dim{dim}_len{seq_len}_r{r}'), data)\n",
    "\n",
    "\n",
    "def sine_dim1_len100_random(r=0):\n",
    "    seq_len = 100\n",
    "    no, dim = 10000, 1\n",
    "    data = sine_data_generation(no, seq_len, dim)\n",
    "    data = np.stack(data)\n",
    "    np.save(os.path.join(DIR_DATA, f'sine_dim{dim}_len{seq_len}_r{r}'), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(DIR_DATA)\n",
    "\n",
    "# Prepare datasets for for multiple random runs.\n",
    "for r in range(5):\n",
    "    sine_dim5_len24_random(r)\n",
    "\n",
    "for r in range(5):\n",
    "    sine_dim1_len100_random(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrÃ³ximos passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = tag_path(os.path.abspath(os.getcwd()), 2)\n",
    "log_dir = makedirs(os.path.join(DIR_LOG, tag))\n",
    "logger = set_logging(tag, log_dir)\n",
    "# data_name_list = UCR85_DATASETS\n",
    "data_name_list = ['50words']\n",
    "\n",
    "model_cfg = dict(acc_threshold_to_train_d=0.75, kernel_size=10)\n",
    "exp_cfg = dict(use_testset=True, idx_layer=-3)\n",
    "exp = Experiment(tag, TCGAN, TCGANConfig, DIR_DATA_UCR15, data_name_list, log_dir,\n",
    "                    model_cfg_kwargs=model_cfg,\n",
    "                    **exp_cfg)\n",
    "\n",
    "fire.Fire(exp.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "c:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlpy.lib.data.utils import train_test_split, one_hot_to_dense\n",
    "import tensorflow as tf\n",
    "from tcgan.lib.eval import EvaluatorGAN, EvaluatorClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 271) (455, 271)\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Meu Drive\\\\Doutorado Unicamp\\\\Projeto\\\\github\\\\tcgan\\\\raw-data\\\\UCR_TS_Archive_2015\\\\50words\\\\50words_TRAIN'\n",
    "data_train = np.genfromtxt(path, delimiter=',', dtype=np.float32)\n",
    "path = 'C:\\\\Meu Drive\\\\Doutorado Unicamp\\\\Projeto\\\\github\\\\tcgan\\\\raw-data\\\\UCR_TS_Archive_2015\\\\50words\\\\50words_TEST'\n",
    "data_test = np.genfromtxt(path, delimiter=',', dtype=np.float32)\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse\n",
    "x_tr = data_train[:, 1::]\n",
    "y_tr = data_train[:, 0].astype(int)\n",
    "x_te = data_test[:, 1::]\n",
    "y_te = data_test[:, 0].astype(int)\n",
    "y_all = np.concatenate([y_tr, y_te])\n",
    "classes, y_all = np.unique(y_all, return_inverse=True)\n",
    "n_class = len(classes)\n",
    "x_tr = x_tr[..., np.newaxis]\n",
    "x_te = x_te[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data can be used in unsupervised learning\n",
    "x_all = np.vstack([x_tr, x_te])\n",
    "_, x_te_gan, _, _ = train_test_split(\n",
    "    x_all, y_all, train_size=0.9, random_state=42, stratify=y_all)\n",
    "x_tr_gan = x_all  # use all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/10 12:07:18 AM, INFO, github_: ****** configure init ******\n",
      "09/10 12:07:19 AM, INFO, github_: The settings are as follows: \n",
      "strides:2\n",
      "padding:same\n",
      "initializer:<tensorflow.python.keras.initializers.initializers_v2.TruncatedNormal object at 0x00000177DBEA8C50>\n",
      "leak_slope:0.2\n",
      "logger:<Logger github_ (INFO)>\n",
      "log_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\n",
      "train_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\training\n",
      "eval_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\evaluation\n",
      "ckpt_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\checkpoint\n",
      "ckpt_prefix:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\checkpoint\\ckpt\n",
      "seed:42\n",
      "np_rs:RandomState(MT19937)\n",
      "verbose:1\n",
      "x_shape:(270, 1)\n",
      "noise_shape:(100,)\n",
      "noise_method:normal\n",
      "noise_sampler:<function random_normal at 0x00000177BD0A5B70>\n",
      "batch_size:16\n",
      "epochs:300\n",
      "g_lr:0.0002\n",
      "d_lr:0.0002\n",
      "g_beta1:0.5\n",
      "d_beta1:0.5\n",
      "g_units_base:32\n",
      "d_units_base:32\n",
      "d_layers:4\n",
      "g_layers:4\n",
      "d_dropout_rate:0.0\n",
      "g_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "d_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "kernel_size:10\n",
      "acc_threshold_to_train_d:0.75\n",
      "ckpt_max_to_keep:2\n",
      "n_epochs_to_save_ckpt:15\n",
      "n_to_evaluate:3\n",
      "n_epochs_to_evaluate:100\n",
      "n_examples_to_generate:16\n",
      "metrics:['nnd', 'mmd', 'vis']\n",
      "noise_seed:[[-0.28077507 -0.1377521  -0.6763296  ... -0.66411126  1.4531434\n",
      "   0.63142705]\n",
      " [ 1.4347553  -0.9590058   1.399536   ...  0.09790254 -0.8498453\n",
      "   0.8285087 ]\n",
      " [ 0.9079667  -0.53826797 -0.75165933 ...  0.00500222  0.46697247\n",
      "  -0.49156648]\n",
      " ...\n",
      " [ 1.0430238  -0.2649641  -0.44542065 ... -0.44225916  0.05121567\n",
      "   0.56583524]\n",
      " [-0.35650563  1.5591161   0.22819136 ...  1.8435367  -0.66581184\n",
      "  -0.97975284]\n",
      " [-1.3944459  -0.31205386  0.46640927 ... -0.12672192  2.9069102\n",
      "  -1.0910585 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_tr.shape[1:]\n",
    "# input_shape = x_tr_gan.shape\n",
    "tag = tag_path(os.path.abspath(os.getcwd()), 2)\n",
    "log_dir = makedirs(os.path.join(DIR_LOG, tag))\n",
    "logger = set_logging(tag, log_dir)\n",
    "model_cfg = TCGANConfig(input_shape, log_dir, logger, **dict(acc_threshold_to_train_d=0.75, kernel_size=10))\n",
    "evaluator = EvaluatorGAN(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/10 12:07:25 AM, INFO, github_: Generator's summary: \n",
      "09/10 12:07:25 AM, INFO, github_: Model: \"functional_1\"\n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: Layer (type)                 Output Shape              Param #   \n",
      "09/10 12:07:25 AM, INFO, github_: =================================================================\n",
      "09/10 12:07:25 AM, INFO, github_: input_1 (InputLayer)         [(None, 100)]             0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: dense_0_dense (Dense)        (None, 4352)              439552    \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: dense_0_norm (BatchNormaliza (None, 4352)              17408     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: dense_0_relu (ReLU)          (None, 4352)              0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: reshape (Reshape)            (None, 17, 256)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_conv (Conv1DTranspose (None, 34, 128)           327808    \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_norm (BatchNormalizat (None, 34, 128)           512       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_relu (ReLU)           (None, 34, 128)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_conv (Conv1DTranspose (None, 68, 64)            81984     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_norm (BatchNormalizat (None, 68, 64)            256       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_relu (ReLU)           (None, 68, 64)            0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_conv (Conv1DTranspose (None, 135, 32)           20512     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_norm (BatchNormalizat (None, 135, 32)           128       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_relu (ReLU)           (None, 135, 32)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_conv (Conv1DTranspose (None, 270, 1)            321       \n",
      "09/10 12:07:25 AM, INFO, github_: =================================================================\n",
      "09/10 12:07:25 AM, INFO, github_: Total params: 888,481\n",
      "09/10 12:07:25 AM, INFO, github_: Trainable params: 879,329\n",
      "09/10 12:07:25 AM, INFO, github_: Non-trainable params: 9,152\n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: Discriminator's summary: \n",
      "09/10 12:07:25 AM, INFO, github_: Model: \"functional_3\"\n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: Layer (type)                 Output Shape              Param #   \n",
      "09/10 12:07:25 AM, INFO, github_: =================================================================\n",
      "09/10 12:07:25 AM, INFO, github_: input_2 (InputLayer)         [(None, 270, 1)]          0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_conv (Conv1D)         (None, 135, 32)           352       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_relu (LeakyReLU)      (None, 135, 32)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_dropout (Dropout)     (None, 135, 32)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_conv (Conv1D)         (None, 68, 64)            20544     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_relu (LeakyReLU)      (None, 68, 64)            0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_dropout (Dropout)     (None, 68, 64)            0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_conv (Conv1D)         (None, 34, 128)           82048     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_norm (BatchNormalizat (None, 34, 128)           512       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_relu (LeakyReLU)      (None, 34, 128)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_dropout (Dropout)     (None, 34, 128)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_conv (Conv1D)         (None, 17, 256)           327936    \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_norm (BatchNormalizat (None, 17, 256)           1024      \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_relu (LeakyReLU)      (None, 17, 256)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_dropout (Dropout)     (None, 17, 256)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: flatten (Flatten)            (None, 4352)              0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: dense (Dense)                (None, 1)                 4353      \n",
      "09/10 12:07:25 AM, INFO, github_: =================================================================\n",
      "09/10 12:07:25 AM, INFO, github_: Total params: 436,769\n",
      "09/10 12:07:25 AM, INFO, github_: Trainable params: 436,001\n",
      "09/10 12:07:25 AM, INFO, github_: Non-trainable params: 768\n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: ****** fit start ******\n",
      "09/10 12:07:25 AM, INFO, github_: train from scratch.\n",
      "09/10 12:07:26 AM, INFO, github_: ****** eval start ******\n",
      "09/10 12:07:27 AM, INFO, github_: tsne, time=0.7368571758270264\n",
      "09/10 12:07:27 AM, INFO, github_: nnd, time=0.046428680419921875\n",
      "09/10 12:07:28 AM, INFO, github_: mmd, time=1.5061471462249756\n",
      "09/10 12:07:28 AM, INFO, github_: ****** eval end ******\n",
      "09/10 12:07:33 AM, INFO, github_: epoch[1/300], d_loss=0.7177, g_loss=1.031, real_loss=0.189, fake_loss=0.5288, acc=0.8317, , time=4.63\n",
      "09/10 12:07:34 AM, INFO, github_: epoch[2/300], d_loss=0.8769, g_loss=1.724, real_loss=0.4643, fake_loss=0.4126, acc=0.8126, , time=1.569\n",
      "09/10 12:07:36 AM, INFO, github_: epoch[3/300], d_loss=1.332, g_loss=1.065, real_loss=0.6881, fake_loss=0.6436, acc=0.6323, , time=1.82\n",
      "09/10 12:07:38 AM, INFO, github_: epoch[4/300], d_loss=1.179, g_loss=1.117, real_loss=0.607, fake_loss=0.5725, acc=0.6931, , time=1.977\n",
      "09/10 12:07:40 AM, INFO, github_: epoch[5/300], d_loss=1.105, g_loss=1.067, real_loss=0.5581, fake_loss=0.547, acc=0.7315, , time=1.751\n",
      "09/10 12:07:42 AM, INFO, github_: epoch[6/300], d_loss=1.048, g_loss=1.097, real_loss=0.5242, fake_loss=0.5243, acc=0.756, , time=1.789\n",
      "09/10 12:07:44 AM, INFO, github_: epoch[7/300], d_loss=1.028, g_loss=1.145, real_loss=0.5129, fake_loss=0.5151, acc=0.7632, , time=2.116\n",
      "09/10 12:07:46 AM, INFO, github_: epoch[8/300], d_loss=1.042, g_loss=1.146, real_loss=0.5076, fake_loss=0.534, acc=0.7538, , time=2.069\n",
      "09/10 12:07:48 AM, INFO, github_: epoch[9/300], d_loss=0.9794, g_loss=1.104, real_loss=0.4718, fake_loss=0.5076, acc=0.7957, , time=2.103\n",
      "09/10 12:07:50 AM, INFO, github_: epoch[10/300], d_loss=1.036, g_loss=1.124, real_loss=0.5048, fake_loss=0.5316, acc=0.7529, , time=2.109\n",
      "09/10 12:07:52 AM, INFO, github_: epoch[11/300], d_loss=1.046, g_loss=1.111, real_loss=0.5259, fake_loss=0.5199, acc=0.7396, , time=2.101\n",
      "09/10 12:07:54 AM, INFO, github_: epoch[12/300], d_loss=1.027, g_loss=1.111, real_loss=0.5088, fake_loss=0.518, acc=0.7401, , time=2.191\n",
      "09/10 12:07:56 AM, INFO, github_: epoch[13/300], d_loss=0.9957, g_loss=1.115, real_loss=0.4957, fake_loss=0.5, acc=0.7865, , time=2.011\n",
      "09/10 12:07:59 AM, INFO, github_: epoch[14/300], d_loss=1.069, g_loss=1.079, real_loss=0.5248, fake_loss=0.5442, acc=0.7447, , time=2.274\n",
      "09/10 12:08:01 AM, INFO, github_: epoch[15/300], d_loss=1.027, g_loss=1.138, real_loss=0.5209, fake_loss=0.5061, acc=0.7578, , time=2.523\n",
      "09/10 12:08:05 AM, INFO, github_: epoch[16/300], d_loss=1.031, g_loss=1.09, real_loss=0.4992, fake_loss=0.5321, acc=0.7668, , time=2.697\n",
      "09/10 12:08:07 AM, INFO, github_: epoch[17/300], d_loss=1.027, g_loss=1.147, real_loss=0.5186, fake_loss=0.5082, acc=0.7517, , time=2.63\n",
      "09/10 12:08:10 AM, INFO, github_: epoch[18/300], d_loss=1.037, g_loss=1.057, real_loss=0.5009, fake_loss=0.5365, acc=0.7584, , time=2.613\n",
      "09/10 12:08:13 AM, INFO, github_: epoch[19/300], d_loss=1.058, g_loss=1.101, real_loss=0.5307, fake_loss=0.5271, acc=0.7542, , time=2.933\n",
      "09/10 12:08:16 AM, INFO, github_: epoch[20/300], d_loss=1.036, g_loss=1.052, real_loss=0.497, fake_loss=0.5393, acc=0.7698, , time=2.624\n",
      "09/10 12:08:18 AM, INFO, github_: epoch[21/300], d_loss=1.035, g_loss=1.102, real_loss=0.5098, fake_loss=0.5252, acc=0.76, , time=2.504\n",
      "09/10 12:08:20 AM, INFO, github_: epoch[22/300], d_loss=1.072, g_loss=1.026, real_loss=0.5134, fake_loss=0.5587, acc=0.7438, , time=2.355\n",
      "09/10 12:08:23 AM, INFO, github_: epoch[23/300], d_loss=1.051, g_loss=1.029, real_loss=0.5011, fake_loss=0.5497, acc=0.7445, , time=2.221\n",
      "09/10 12:08:25 AM, INFO, github_: epoch[24/300], d_loss=1.014, g_loss=1.129, real_loss=0.525, fake_loss=0.4893, acc=0.772, , time=2.459\n",
      "09/10 12:08:28 AM, INFO, github_: epoch[25/300], d_loss=1.039, g_loss=1.115, real_loss=0.5285, fake_loss=0.5104, acc=0.7598, , time=2.338\n",
      "09/10 12:08:30 AM, INFO, github_: epoch[26/300], d_loss=1.052, g_loss=1.07, real_loss=0.5172, fake_loss=0.5348, acc=0.7541, , time=2.558\n",
      "09/10 12:08:33 AM, INFO, github_: epoch[27/300], d_loss=1.022, g_loss=1.07, real_loss=0.4785, fake_loss=0.5436, acc=0.7622, , time=2.666\n",
      "09/10 12:08:36 AM, INFO, github_: epoch[28/300], d_loss=1.036, g_loss=1.069, real_loss=0.5005, fake_loss=0.535, acc=0.7549, , time=3.427\n",
      "09/10 12:08:40 AM, INFO, github_: epoch[29/300], d_loss=1.034, g_loss=1.04, real_loss=0.4933, fake_loss=0.5409, acc=0.7682, , time=3.767\n",
      "09/10 12:08:44 AM, INFO, github_: epoch[30/300], d_loss=0.9786, g_loss=1.092, real_loss=0.4587, fake_loss=0.5199, acc=0.7808, , time=3.611\n",
      "09/10 12:08:48 AM, INFO, github_: epoch[31/300], d_loss=1.007, g_loss=1.118, real_loss=0.4911, fake_loss=0.5162, acc=0.7596, , time=3.509\n",
      "09/10 12:08:52 AM, INFO, github_: epoch[32/300], d_loss=1.019, g_loss=1.103, real_loss=0.4889, fake_loss=0.5301, acc=0.7658, , time=3.771\n",
      "09/10 12:08:55 AM, INFO, github_: epoch[33/300], d_loss=1.041, g_loss=1.048, real_loss=0.4931, fake_loss=0.5475, acc=0.7563, , time=3.088\n",
      "09/10 12:08:58 AM, INFO, github_: epoch[34/300], d_loss=1.031, g_loss=1.092, real_loss=0.5041, fake_loss=0.5272, acc=0.7752, , time=3.105\n",
      "09/10 12:09:01 AM, INFO, github_: epoch[35/300], d_loss=1.014, g_loss=1.148, real_loss=0.503, fake_loss=0.5112, acc=0.7685, , time=2.937\n",
      "09/10 12:09:03 AM, INFO, github_: epoch[36/300], d_loss=0.9909, g_loss=1.094, real_loss=0.4765, fake_loss=0.5145, acc=0.793, , time=2.188\n",
      "09/10 12:09:05 AM, INFO, github_: epoch[37/300], d_loss=0.9941, g_loss=1.091, real_loss=0.4752, fake_loss=0.5189, acc=0.7894, , time=2.084\n",
      "09/10 12:09:07 AM, INFO, github_: epoch[38/300], d_loss=0.9982, g_loss=1.122, real_loss=0.483, fake_loss=0.5152, acc=0.7696, , time=2.044\n",
      "09/10 12:09:10 AM, INFO, github_: epoch[39/300], d_loss=0.9789, g_loss=1.169, real_loss=0.4823, fake_loss=0.4966, acc=0.7782, , time=2.407\n",
      "09/10 12:09:12 AM, INFO, github_: epoch[40/300], d_loss=0.959, g_loss=1.128, real_loss=0.4551, fake_loss=0.5039, acc=0.7992, , time=1.946\n",
      "09/10 12:09:14 AM, INFO, github_: epoch[41/300], d_loss=0.9621, g_loss=1.114, real_loss=0.4534, fake_loss=0.5087, acc=0.7817, , time=2.032\n",
      "09/10 12:09:16 AM, INFO, github_: epoch[42/300], d_loss=1.01, g_loss=1.109, real_loss=0.4768, fake_loss=0.5334, acc=0.7597, , time=2.073\n",
      "09/10 12:09:18 AM, INFO, github_: epoch[43/300], d_loss=0.9747, g_loss=1.155, real_loss=0.4825, fake_loss=0.4921, acc=0.7872, , time=2.013\n",
      "09/10 12:09:20 AM, INFO, github_: epoch[44/300], d_loss=0.9795, g_loss=1.13, real_loss=0.4813, fake_loss=0.4982, acc=0.7697, , time=1.948\n",
      "09/10 12:09:22 AM, INFO, github_: epoch[45/300], d_loss=0.9933, g_loss=1.134, real_loss=0.5004, fake_loss=0.4929, acc=0.789, , time=1.918\n",
      "09/10 12:09:24 AM, INFO, github_: epoch[46/300], d_loss=0.972, g_loss=1.13, real_loss=0.4715, fake_loss=0.5005, acc=0.7883, , time=1.986\n",
      "09/10 12:09:26 AM, INFO, github_: epoch[47/300], d_loss=0.9947, g_loss=1.129, real_loss=0.4846, fake_loss=0.5101, acc=0.7754, , time=2.016\n",
      "09/10 12:09:28 AM, INFO, github_: epoch[48/300], d_loss=0.9647, g_loss=1.112, real_loss=0.4405, fake_loss=0.5242, acc=0.789, , time=1.904\n",
      "09/10 12:09:30 AM, INFO, github_: epoch[49/300], d_loss=0.9737, g_loss=1.148, real_loss=0.4847, fake_loss=0.489, acc=0.7857, , time=2.002\n",
      "09/10 12:09:32 AM, INFO, github_: epoch[50/300], d_loss=0.9708, g_loss=1.146, real_loss=0.476, fake_loss=0.4948, acc=0.7879, , time=2.28\n",
      "09/10 12:09:34 AM, INFO, github_: epoch[51/300], d_loss=0.9817, g_loss=1.14, real_loss=0.4652, fake_loss=0.5164, acc=0.7779, , time=2.093\n",
      "09/10 12:09:36 AM, INFO, github_: epoch[52/300], d_loss=0.967, g_loss=1.149, real_loss=0.466, fake_loss=0.5011, acc=0.7904, , time=1.949\n",
      "09/10 12:09:38 AM, INFO, github_: epoch[53/300], d_loss=0.9546, g_loss=1.159, real_loss=0.4621, fake_loss=0.4925, acc=0.7987, , time=1.865\n",
      "09/10 12:09:40 AM, INFO, github_: epoch[54/300], d_loss=0.964, g_loss=1.109, real_loss=0.4517, fake_loss=0.5122, acc=0.7962, , time=1.855\n",
      "09/10 12:09:42 AM, INFO, github_: epoch[55/300], d_loss=0.9415, g_loss=1.164, real_loss=0.4453, fake_loss=0.4962, acc=0.7897, , time=2.015\n",
      "09/10 12:09:44 AM, INFO, github_: epoch[56/300], d_loss=0.9725, g_loss=1.115, real_loss=0.4475, fake_loss=0.525, acc=0.776, , time=1.975\n",
      "09/10 12:09:46 AM, INFO, github_: epoch[57/300], d_loss=0.9187, g_loss=1.191, real_loss=0.4499, fake_loss=0.4688, acc=0.8221, , time=1.983\n",
      "09/10 12:09:48 AM, INFO, github_: epoch[58/300], d_loss=0.9447, g_loss=1.216, real_loss=0.4734, fake_loss=0.4713, acc=0.793, , time=2.016\n",
      "09/10 12:09:50 AM, INFO, github_: epoch[59/300], d_loss=0.9439, g_loss=1.159, real_loss=0.434, fake_loss=0.51, acc=0.7872, , time=2.111\n",
      "09/10 12:09:53 AM, INFO, github_: epoch[60/300], d_loss=0.9821, g_loss=1.132, real_loss=0.4611, fake_loss=0.521, acc=0.7846, , time=2.404\n",
      "09/10 12:09:55 AM, INFO, github_: epoch[61/300], d_loss=0.9575, g_loss=1.168, real_loss=0.4621, fake_loss=0.4954, acc=0.7911, , time=2.405\n",
      "09/10 12:09:57 AM, INFO, github_: epoch[62/300], d_loss=0.9276, g_loss=1.182, real_loss=0.4322, fake_loss=0.4954, acc=0.806, , time=2.013\n",
      "09/10 12:09:59 AM, INFO, github_: epoch[63/300], d_loss=0.9447, g_loss=1.177, real_loss=0.4454, fake_loss=0.4993, acc=0.7949, , time=1.97\n",
      "09/10 12:10:02 AM, INFO, github_: epoch[64/300], d_loss=0.9194, g_loss=1.222, real_loss=0.4477, fake_loss=0.4718, acc=0.8082, , time=2.247\n",
      "09/10 12:10:04 AM, INFO, github_: epoch[65/300], d_loss=0.9448, g_loss=1.192, real_loss=0.4538, fake_loss=0.491, acc=0.8031, , time=2.206\n",
      "09/10 12:10:06 AM, INFO, github_: epoch[66/300], d_loss=0.9426, g_loss=1.252, real_loss=0.4834, fake_loss=0.4592, acc=0.8035, , time=2.03\n",
      "09/10 12:10:08 AM, INFO, github_: epoch[67/300], d_loss=0.9231, g_loss=1.175, real_loss=0.4351, fake_loss=0.4879, acc=0.8066, , time=2.016\n",
      "09/10 12:10:10 AM, INFO, github_: epoch[68/300], d_loss=0.9198, g_loss=1.183, real_loss=0.4309, fake_loss=0.4889, acc=0.8008, , time=1.941\n",
      "09/10 12:10:12 AM, INFO, github_: epoch[69/300], d_loss=0.9713, g_loss=1.23, real_loss=0.494, fake_loss=0.4773, acc=0.7804, , time=1.915\n",
      "09/10 12:10:14 AM, INFO, github_: epoch[70/300], d_loss=0.9195, g_loss=1.219, real_loss=0.455, fake_loss=0.4645, acc=0.8183, , time=1.869\n",
      "09/10 12:10:15 AM, INFO, github_: epoch[71/300], d_loss=0.9176, g_loss=1.231, real_loss=0.4451, fake_loss=0.4724, acc=0.8071, , time=1.895\n",
      "09/10 12:10:17 AM, INFO, github_: epoch[72/300], d_loss=0.957, g_loss=1.182, real_loss=0.4561, fake_loss=0.501, acc=0.7996, , time=1.873\n",
      "09/10 12:10:19 AM, INFO, github_: epoch[73/300], d_loss=0.9581, g_loss=1.187, real_loss=0.4435, fake_loss=0.5146, acc=0.7791, , time=2.064\n",
      "09/10 12:10:21 AM, INFO, github_: epoch[74/300], d_loss=0.9491, g_loss=1.242, real_loss=0.4757, fake_loss=0.4734, acc=0.7871, , time=1.954\n",
      "09/10 12:10:23 AM, INFO, github_: epoch[75/300], d_loss=0.9294, g_loss=1.199, real_loss=0.4446, fake_loss=0.4848, acc=0.8067, , time=1.848\n",
      "09/10 12:10:25 AM, INFO, github_: epoch[76/300], d_loss=0.9428, g_loss=1.229, real_loss=0.4644, fake_loss=0.4784, acc=0.8008, , time=1.935\n",
      "09/10 12:10:27 AM, INFO, github_: epoch[77/300], d_loss=0.9561, g_loss=1.193, real_loss=0.4576, fake_loss=0.4985, acc=0.7996, , time=1.861\n",
      "09/10 12:10:29 AM, INFO, github_: epoch[78/300], d_loss=0.911, g_loss=1.202, real_loss=0.4382, fake_loss=0.4728, acc=0.8149, , time=1.83\n",
      "09/10 12:10:31 AM, INFO, github_: epoch[79/300], d_loss=0.8842, g_loss=1.239, real_loss=0.4128, fake_loss=0.4715, acc=0.8142, , time=2.117\n",
      "09/10 12:10:33 AM, INFO, github_: epoch[80/300], d_loss=0.9267, g_loss=1.208, real_loss=0.4478, fake_loss=0.4789, acc=0.8098, , time=2.225\n",
      "09/10 12:10:36 AM, INFO, github_: epoch[81/300], d_loss=0.9473, g_loss=1.196, real_loss=0.4552, fake_loss=0.4921, acc=0.7827, , time=2.129\n",
      "09/10 12:10:37 AM, INFO, github_: epoch[82/300], d_loss=0.8992, g_loss=1.209, real_loss=0.4253, fake_loss=0.4739, acc=0.823, , time=1.869\n",
      "09/10 12:10:39 AM, INFO, github_: epoch[83/300], d_loss=0.9126, g_loss=1.25, real_loss=0.4391, fake_loss=0.4735, acc=0.8005, , time=1.841\n",
      "09/10 12:10:41 AM, INFO, github_: epoch[84/300], d_loss=0.8921, g_loss=1.184, real_loss=0.402, fake_loss=0.4901, acc=0.8293, , time=1.891\n",
      "09/10 12:10:43 AM, INFO, github_: epoch[85/300], d_loss=0.9285, g_loss=1.261, real_loss=0.4536, fake_loss=0.4749, acc=0.8008, , time=1.933\n",
      "09/10 12:10:45 AM, INFO, github_: epoch[86/300], d_loss=0.9003, g_loss=1.216, real_loss=0.4293, fake_loss=0.471, acc=0.8189, , time=1.945\n",
      "09/10 12:10:47 AM, INFO, github_: epoch[87/300], d_loss=0.9118, g_loss=1.231, real_loss=0.444, fake_loss=0.4678, acc=0.8124, , time=1.826\n",
      "09/10 12:10:49 AM, INFO, github_: epoch[88/300], d_loss=0.9367, g_loss=1.179, real_loss=0.4327, fake_loss=0.5041, acc=0.7972, , time=1.875\n",
      "09/10 12:10:51 AM, INFO, github_: epoch[89/300], d_loss=0.9026, g_loss=1.226, real_loss=0.4252, fake_loss=0.4775, acc=0.8106, , time=1.794\n",
      "09/10 12:10:52 AM, INFO, github_: epoch[90/300], d_loss=0.9066, g_loss=1.239, real_loss=0.4341, fake_loss=0.4725, acc=0.8119, , time=1.788\n",
      "09/10 12:10:55 AM, INFO, github_: epoch[91/300], d_loss=0.8998, g_loss=1.213, real_loss=0.4195, fake_loss=0.4803, acc=0.8169, , time=1.871\n",
      "09/10 12:10:56 AM, INFO, github_: epoch[92/300], d_loss=0.8966, g_loss=1.256, real_loss=0.4276, fake_loss=0.469, acc=0.8142, , time=1.913\n",
      "09/10 12:10:58 AM, INFO, github_: epoch[93/300], d_loss=0.886, g_loss=1.252, real_loss=0.4225, fake_loss=0.4635, acc=0.8175, , time=1.91\n",
      "09/10 12:11:01 AM, INFO, github_: epoch[94/300], d_loss=0.8991, g_loss=1.274, real_loss=0.4338, fake_loss=0.4653, acc=0.8057, , time=2.265\n",
      "09/10 12:11:03 AM, INFO, github_: epoch[95/300], d_loss=0.9082, g_loss=1.235, real_loss=0.4371, fake_loss=0.4711, acc=0.8154, , time=1.915\n",
      "09/10 12:11:04 AM, INFO, github_: epoch[96/300], d_loss=0.8731, g_loss=1.251, real_loss=0.4206, fake_loss=0.4525, acc=0.842, , time=1.837\n",
      "09/10 12:11:06 AM, INFO, github_: epoch[97/300], d_loss=0.8855, g_loss=1.232, real_loss=0.4132, fake_loss=0.4723, acc=0.8246, , time=1.857\n",
      "09/10 12:11:08 AM, INFO, github_: epoch[98/300], d_loss=0.908, g_loss=1.282, real_loss=0.4447, fake_loss=0.4633, acc=0.8072, , time=1.843\n",
      "09/10 12:11:10 AM, INFO, github_: epoch[99/300], d_loss=0.8965, g_loss=1.26, real_loss=0.443, fake_loss=0.4535, acc=0.8216, , time=1.844\n",
      "09/10 12:11:12 AM, INFO, github_: epoch[100/300], d_loss=0.8996, g_loss=1.261, real_loss=0.4399, fake_loss=0.4597, acc=0.8292, , time=1.885\n",
      "09/10 12:11:12 AM, INFO, github_: ****** eval start ******\n",
      "09/10 12:11:13 AM, INFO, github_: tsne, time=0.710540771484375\n",
      "09/10 12:11:13 AM, INFO, github_: nnd, time=0.05556654930114746\n",
      "09/10 12:11:13 AM, INFO, github_: mmd, time=0.09713554382324219\n",
      "09/10 12:11:13 AM, INFO, github_: ****** eval end ******\n",
      "09/10 12:11:15 AM, INFO, github_: epoch[101/300], d_loss=0.8886, g_loss=1.242, real_loss=0.4195, fake_loss=0.4692, acc=0.8197, , time=1.874\n",
      "09/10 12:11:16 AM, INFO, github_: epoch[102/300], d_loss=0.8991, g_loss=1.205, real_loss=0.4141, fake_loss=0.4849, acc=0.8142, , time=1.835\n",
      "09/10 12:11:18 AM, INFO, github_: epoch[103/300], d_loss=0.8817, g_loss=1.305, real_loss=0.4383, fake_loss=0.4434, acc=0.8227, , time=1.787\n",
      "09/10 12:11:20 AM, INFO, github_: epoch[104/300], d_loss=0.8946, g_loss=1.266, real_loss=0.4413, fake_loss=0.4533, acc=0.821, , time=1.827\n",
      "09/10 12:11:22 AM, INFO, github_: epoch[105/300], d_loss=0.8645, g_loss=1.312, real_loss=0.4318, fake_loss=0.4327, acc=0.8303, , time=1.851\n",
      "09/10 12:11:24 AM, INFO, github_: epoch[106/300], d_loss=0.8814, g_loss=1.223, real_loss=0.4165, fake_loss=0.4649, acc=0.823, , time=1.903\n",
      "09/10 12:11:26 AM, INFO, github_: epoch[107/300], d_loss=0.8859, g_loss=1.173, real_loss=0.3951, fake_loss=0.4908, acc=0.8299, , time=1.875\n",
      "09/10 12:11:28 AM, INFO, github_: epoch[108/300], d_loss=0.8714, g_loss=1.259, real_loss=0.4303, fake_loss=0.441, acc=0.8385, , time=1.787\n",
      "09/10 12:11:30 AM, INFO, github_: epoch[109/300], d_loss=0.9103, g_loss=1.211, real_loss=0.4317, fake_loss=0.4786, acc=0.8193, , time=2.048\n",
      "09/10 12:11:32 AM, INFO, github_: epoch[110/300], d_loss=0.897, g_loss=1.244, real_loss=0.4116, fake_loss=0.4854, acc=0.8157, , time=1.916\n",
      "09/10 12:11:34 AM, INFO, github_: epoch[111/300], d_loss=0.8715, g_loss=1.277, real_loss=0.4241, fake_loss=0.4474, acc=0.8301, , time=1.849\n",
      "09/10 12:11:36 AM, INFO, github_: epoch[112/300], d_loss=0.9157, g_loss=1.202, real_loss=0.4315, fake_loss=0.4841, acc=0.8152, , time=1.988\n",
      "09/10 12:11:37 AM, INFO, github_: epoch[113/300], d_loss=0.8656, g_loss=1.247, real_loss=0.4101, fake_loss=0.4555, acc=0.8259, , time=1.842\n",
      "09/10 12:11:39 AM, INFO, github_: epoch[114/300], d_loss=0.8952, g_loss=1.252, real_loss=0.4273, fake_loss=0.4679, acc=0.8257, , time=1.758\n",
      "09/10 12:11:41 AM, INFO, github_: epoch[115/300], d_loss=0.884, g_loss=1.182, real_loss=0.3896, fake_loss=0.4943, acc=0.8181, , time=1.823\n",
      "09/10 12:11:43 AM, INFO, github_: epoch[116/300], d_loss=0.8935, g_loss=1.188, real_loss=0.3997, fake_loss=0.4939, acc=0.8112, , time=1.807\n",
      "09/10 12:11:45 AM, INFO, github_: epoch[117/300], d_loss=0.8913, g_loss=1.277, real_loss=0.4359, fake_loss=0.4554, acc=0.821, , time=1.874\n",
      "09/10 12:11:47 AM, INFO, github_: epoch[118/300], d_loss=0.8674, g_loss=1.284, real_loss=0.417, fake_loss=0.4504, acc=0.8225, , time=1.905\n",
      "09/10 12:11:49 AM, INFO, github_: epoch[119/300], d_loss=0.8753, g_loss=1.321, real_loss=0.4296, fake_loss=0.4458, acc=0.8243, , time=1.847\n",
      "09/10 12:11:50 AM, INFO, github_: epoch[120/300], d_loss=0.8578, g_loss=1.247, real_loss=0.4033, fake_loss=0.4545, acc=0.8356, , time=1.79\n",
      "09/10 12:11:53 AM, INFO, github_: epoch[121/300], d_loss=0.8582, g_loss=1.271, real_loss=0.4077, fake_loss=0.4505, acc=0.8377, , time=1.763\n",
      "09/10 12:11:54 AM, INFO, github_: epoch[122/300], d_loss=0.8579, g_loss=1.287, real_loss=0.417, fake_loss=0.4409, acc=0.8377, , time=1.85\n",
      "09/10 12:11:56 AM, INFO, github_: epoch[123/300], d_loss=0.914, g_loss=1.209, real_loss=0.4157, fake_loss=0.4983, acc=0.8074, , time=1.85\n",
      "09/10 12:11:58 AM, INFO, github_: epoch[124/300], d_loss=0.8863, g_loss=1.177, real_loss=0.3788, fake_loss=0.5075, acc=0.8269, , time=1.902\n",
      "09/10 12:12:00 AM, INFO, github_: epoch[125/300], d_loss=0.8488, g_loss=1.231, real_loss=0.3774, fake_loss=0.4713, acc=0.8405, , time=2.245\n",
      "09/10 12:12:02 AM, INFO, github_: epoch[126/300], d_loss=0.8724, g_loss=1.26, real_loss=0.4028, fake_loss=0.4697, acc=0.845, , time=1.945\n",
      "09/10 12:12:04 AM, INFO, github_: epoch[127/300], d_loss=0.8736, g_loss=1.282, real_loss=0.4363, fake_loss=0.4374, acc=0.8345, , time=1.94\n",
      "09/10 12:12:06 AM, INFO, github_: epoch[128/300], d_loss=0.8957, g_loss=1.247, real_loss=0.4295, fake_loss=0.4663, acc=0.8182, , time=1.89\n",
      "09/10 12:12:08 AM, INFO, github_: epoch[129/300], d_loss=0.8566, g_loss=1.243, real_loss=0.4013, fake_loss=0.4553, acc=0.8413, , time=1.764\n",
      "09/10 12:12:10 AM, INFO, github_: epoch[130/300], d_loss=0.8662, g_loss=1.223, real_loss=0.3764, fake_loss=0.4897, acc=0.8111, , time=1.87\n",
      "09/10 12:12:12 AM, INFO, github_: epoch[131/300], d_loss=0.8758, g_loss=1.236, real_loss=0.3924, fake_loss=0.4835, acc=0.8174, , time=1.897\n",
      "09/10 12:12:14 AM, INFO, github_: epoch[132/300], d_loss=0.8579, g_loss=1.261, real_loss=0.3965, fake_loss=0.4614, acc=0.8359, , time=1.903\n",
      "09/10 12:12:15 AM, INFO, github_: epoch[133/300], d_loss=0.872, g_loss=1.261, real_loss=0.4179, fake_loss=0.4542, acc=0.8406, , time=1.88\n",
      "09/10 12:12:17 AM, INFO, github_: epoch[134/300], d_loss=0.8592, g_loss=1.288, real_loss=0.4221, fake_loss=0.4371, acc=0.8403, , time=1.761\n",
      "09/10 12:12:19 AM, INFO, github_: epoch[135/300], d_loss=0.8604, g_loss=1.243, real_loss=0.3927, fake_loss=0.4677, acc=0.8319, , time=1.843\n",
      "09/10 12:12:21 AM, INFO, github_: epoch[136/300], d_loss=0.8813, g_loss=1.286, real_loss=0.4314, fake_loss=0.4499, acc=0.827, , time=1.897\n",
      "09/10 12:12:23 AM, INFO, github_: epoch[137/300], d_loss=0.8625, g_loss=1.218, real_loss=0.3974, fake_loss=0.4651, acc=0.8433, , time=1.842\n",
      "09/10 12:12:25 AM, INFO, github_: epoch[138/300], d_loss=0.8795, g_loss=1.283, real_loss=0.4248, fake_loss=0.4546, acc=0.8249, , time=1.843\n",
      "09/10 12:12:27 AM, INFO, github_: epoch[139/300], d_loss=0.8435, g_loss=1.246, real_loss=0.3863, fake_loss=0.4572, acc=0.8441, , time=1.819\n",
      "09/10 12:12:29 AM, INFO, github_: epoch[140/300], d_loss=0.8375, g_loss=1.34, real_loss=0.4095, fake_loss=0.428, acc=0.8445, , time=1.737\n",
      "09/10 12:12:31 AM, INFO, github_: epoch[141/300], d_loss=0.8567, g_loss=1.208, real_loss=0.3764, fake_loss=0.4803, acc=0.8372, , time=2.132\n",
      "09/10 12:12:33 AM, INFO, github_: epoch[142/300], d_loss=0.8609, g_loss=1.258, real_loss=0.3961, fake_loss=0.4648, acc=0.8334, , time=1.97\n",
      "09/10 12:12:34 AM, INFO, github_: epoch[143/300], d_loss=0.8513, g_loss=1.276, real_loss=0.4124, fake_loss=0.4389, acc=0.8534, , time=1.799\n",
      "09/10 12:12:36 AM, INFO, github_: epoch[144/300], d_loss=0.8892, g_loss=1.261, real_loss=0.4363, fake_loss=0.4529, acc=0.8273, , time=1.812\n",
      "09/10 12:12:38 AM, INFO, github_: epoch[145/300], d_loss=0.8695, g_loss=1.29, real_loss=0.4215, fake_loss=0.448, acc=0.8325, , time=1.832\n",
      "09/10 12:12:40 AM, INFO, github_: epoch[146/300], d_loss=0.8683, g_loss=1.222, real_loss=0.3959, fake_loss=0.4724, acc=0.8469, , time=1.877\n",
      "09/10 12:12:42 AM, INFO, github_: epoch[147/300], d_loss=0.8643, g_loss=1.338, real_loss=0.4493, fake_loss=0.415, acc=0.8312, , time=1.747\n",
      "09/10 12:12:43 AM, INFO, github_: epoch[148/300], d_loss=0.8329, g_loss=1.299, real_loss=0.3918, fake_loss=0.4411, acc=0.8448, , time=1.723\n",
      "09/10 12:12:45 AM, INFO, github_: epoch[149/300], d_loss=0.8353, g_loss=1.312, real_loss=0.4088, fake_loss=0.4265, acc=0.8439, , time=1.788\n",
      "09/10 12:12:47 AM, INFO, github_: epoch[150/300], d_loss=0.8477, g_loss=1.269, real_loss=0.3915, fake_loss=0.4562, acc=0.8572, , time=1.848\n",
      "09/10 12:12:49 AM, INFO, github_: epoch[151/300], d_loss=0.8604, g_loss=1.297, real_loss=0.4241, fake_loss=0.4363, acc=0.8508, , time=1.891\n",
      "09/10 12:12:51 AM, INFO, github_: epoch[152/300], d_loss=0.852, g_loss=1.287, real_loss=0.3991, fake_loss=0.4529, acc=0.8272, , time=1.839\n",
      "09/10 12:12:53 AM, INFO, github_: epoch[153/300], d_loss=0.8578, g_loss=1.299, real_loss=0.4157, fake_loss=0.4421, acc=0.8397, , time=1.707\n",
      "09/10 12:12:55 AM, INFO, github_: epoch[154/300], d_loss=0.8521, g_loss=1.226, real_loss=0.3859, fake_loss=0.4662, acc=0.8396, , time=1.799\n",
      "09/10 12:12:56 AM, INFO, github_: epoch[155/300], d_loss=0.8112, g_loss=1.245, real_loss=0.3629, fake_loss=0.4482, acc=0.8632, , time=1.732\n",
      "09/10 12:12:59 AM, INFO, github_: epoch[156/300], d_loss=0.8581, g_loss=1.271, real_loss=0.4089, fake_loss=0.4491, acc=0.8439, , time=2.125\n",
      "09/10 12:13:01 AM, INFO, github_: epoch[157/300], d_loss=0.8336, g_loss=1.254, real_loss=0.3734, fake_loss=0.4603, acc=0.844, , time=2.185\n",
      "09/10 12:13:03 AM, INFO, github_: epoch[158/300], d_loss=0.859, g_loss=1.209, real_loss=0.3806, fake_loss=0.4783, acc=0.8367, , time=1.87\n",
      "09/10 12:13:04 AM, INFO, github_: epoch[159/300], d_loss=0.8374, g_loss=1.295, real_loss=0.3834, fake_loss=0.4539, acc=0.8384, , time=1.794\n",
      "09/10 12:13:06 AM, INFO, github_: epoch[160/300], d_loss=0.8483, g_loss=1.241, real_loss=0.4037, fake_loss=0.4446, acc=0.849, , time=1.78\n",
      "09/10 12:13:08 AM, INFO, github_: epoch[161/300], d_loss=0.8386, g_loss=1.199, real_loss=0.3663, fake_loss=0.4723, acc=0.8586, , time=1.737\n",
      "09/10 12:13:10 AM, INFO, github_: epoch[162/300], d_loss=0.8587, g_loss=1.322, real_loss=0.4214, fake_loss=0.4373, acc=0.8441, , time=1.864\n",
      "09/10 12:13:12 AM, INFO, github_: epoch[163/300], d_loss=0.8581, g_loss=1.193, real_loss=0.3559, fake_loss=0.5022, acc=0.8249, , time=1.879\n",
      "09/10 12:13:14 AM, INFO, github_: epoch[164/300], d_loss=0.8549, g_loss=1.269, real_loss=0.3793, fake_loss=0.4755, acc=0.8241, , time=1.852\n",
      "09/10 12:13:15 AM, INFO, github_: epoch[165/300], d_loss=0.8327, g_loss=1.317, real_loss=0.4081, fake_loss=0.4246, acc=0.8488, , time=1.861\n",
      "09/10 12:13:18 AM, INFO, github_: epoch[166/300], d_loss=0.821, g_loss=1.24, real_loss=0.3489, fake_loss=0.4721, acc=0.84, , time=1.763\n",
      "09/10 12:13:19 AM, INFO, github_: epoch[167/300], d_loss=0.841, g_loss=1.272, real_loss=0.3906, fake_loss=0.4503, acc=0.8467, , time=1.923\n",
      "09/10 12:13:21 AM, INFO, github_: epoch[168/300], d_loss=0.8476, g_loss=1.252, real_loss=0.379, fake_loss=0.4686, acc=0.8467, , time=1.91\n",
      "09/10 12:13:23 AM, INFO, github_: epoch[169/300], d_loss=0.8159, g_loss=1.251, real_loss=0.3669, fake_loss=0.449, acc=0.8595, , time=1.762\n",
      "09/10 12:13:25 AM, INFO, github_: epoch[170/300], d_loss=0.8138, g_loss=1.369, real_loss=0.4071, fake_loss=0.4067, acc=0.8601, , time=1.803\n",
      "09/10 12:13:27 AM, INFO, github_: epoch[171/300], d_loss=0.836, g_loss=1.286, real_loss=0.3943, fake_loss=0.4417, acc=0.8522, , time=2.22\n",
      "09/10 12:13:29 AM, INFO, github_: epoch[172/300], d_loss=0.869, g_loss=1.298, real_loss=0.4301, fake_loss=0.4389, acc=0.8308, , time=1.963\n",
      "09/10 12:13:31 AM, INFO, github_: epoch[173/300], d_loss=0.8087, g_loss=1.289, real_loss=0.3668, fake_loss=0.4418, acc=0.8437, , time=2.094\n",
      "09/10 12:13:33 AM, INFO, github_: epoch[174/300], d_loss=0.8365, g_loss=1.32, real_loss=0.4133, fake_loss=0.4232, acc=0.8436, , time=1.76\n",
      "09/10 12:13:35 AM, INFO, github_: epoch[175/300], d_loss=0.8354, g_loss=1.224, real_loss=0.3563, fake_loss=0.479, acc=0.8414, , time=1.766\n",
      "09/10 12:13:36 AM, INFO, github_: epoch[176/300], d_loss=0.8366, g_loss=1.216, real_loss=0.361, fake_loss=0.4756, acc=0.8472, , time=1.664\n",
      "09/10 12:13:38 AM, INFO, github_: epoch[177/300], d_loss=0.8848, g_loss=1.314, real_loss=0.4238, fake_loss=0.461, acc=0.8202, , time=1.801\n",
      "09/10 12:13:40 AM, INFO, github_: epoch[178/300], d_loss=0.8161, g_loss=1.303, real_loss=0.3755, fake_loss=0.4406, acc=0.8544, , time=1.862\n",
      "09/10 12:13:42 AM, INFO, github_: epoch[179/300], d_loss=0.8258, g_loss=1.25, real_loss=0.367, fake_loss=0.4589, acc=0.8543, , time=1.92\n",
      "09/10 12:13:44 AM, INFO, github_: epoch[180/300], d_loss=0.8427, g_loss=1.239, real_loss=0.3773, fake_loss=0.4655, acc=0.8404, , time=1.881\n",
      "09/10 12:13:46 AM, INFO, github_: epoch[181/300], d_loss=0.8473, g_loss=1.265, real_loss=0.3868, fake_loss=0.4605, acc=0.8361, , time=2.034\n",
      "09/10 12:13:48 AM, INFO, github_: epoch[182/300], d_loss=0.8143, g_loss=1.345, real_loss=0.406, fake_loss=0.4083, acc=0.8604, , time=1.841\n",
      "09/10 12:13:50 AM, INFO, github_: epoch[183/300], d_loss=0.8005, g_loss=1.348, real_loss=0.3892, fake_loss=0.4113, acc=0.8592, , time=2.086\n",
      "09/10 12:13:52 AM, INFO, github_: epoch[184/300], d_loss=0.8105, g_loss=1.236, real_loss=0.3534, fake_loss=0.4571, acc=0.8586, , time=1.948\n",
      "09/10 12:13:54 AM, INFO, github_: epoch[185/300], d_loss=0.8339, g_loss=1.315, real_loss=0.3982, fake_loss=0.4358, acc=0.8471, , time=2.34\n",
      "09/10 12:13:57 AM, INFO, github_: epoch[186/300], d_loss=0.8263, g_loss=1.269, real_loss=0.3755, fake_loss=0.4508, acc=0.85, , time=2.25\n",
      "09/10 12:13:59 AM, INFO, github_: epoch[187/300], d_loss=0.8351, g_loss=1.224, real_loss=0.3642, fake_loss=0.4709, acc=0.8453, , time=2.123\n",
      "09/10 12:14:01 AM, INFO, github_: epoch[188/300], d_loss=0.8458, g_loss=1.239, real_loss=0.3674, fake_loss=0.4784, acc=0.8299, , time=2.036\n",
      "09/10 12:14:03 AM, INFO, github_: epoch[189/300], d_loss=0.848, g_loss=1.283, real_loss=0.3854, fake_loss=0.4626, acc=0.8378, , time=2.022\n",
      "09/10 12:14:05 AM, INFO, github_: epoch[190/300], d_loss=0.8415, g_loss=1.275, real_loss=0.3958, fake_loss=0.4457, acc=0.8545, , time=1.981\n",
      "09/10 12:14:07 AM, INFO, github_: epoch[191/300], d_loss=0.8201, g_loss=1.269, real_loss=0.3638, fake_loss=0.4563, acc=0.8498, , time=2.112\n",
      "09/10 12:14:09 AM, INFO, github_: epoch[192/300], d_loss=0.8329, g_loss=1.285, real_loss=0.3624, fake_loss=0.4705, acc=0.8411, , time=2.04\n",
      "09/10 12:14:11 AM, INFO, github_: epoch[193/300], d_loss=0.7975, g_loss=1.342, real_loss=0.3725, fake_loss=0.425, acc=0.8536, , time=2.199\n",
      "09/10 12:14:13 AM, INFO, github_: epoch[194/300], d_loss=0.8299, g_loss=1.269, real_loss=0.3767, fake_loss=0.4532, acc=0.8417, , time=2.117\n",
      "09/10 12:14:15 AM, INFO, github_: epoch[195/300], d_loss=0.8171, g_loss=1.295, real_loss=0.3817, fake_loss=0.4354, acc=0.8588, , time=1.829\n",
      "09/10 12:14:18 AM, INFO, github_: epoch[196/300], d_loss=0.8159, g_loss=1.273, real_loss=0.3615, fake_loss=0.4544, acc=0.8495, , time=2.066\n",
      "09/10 12:14:20 AM, INFO, github_: epoch[197/300], d_loss=0.812, g_loss=1.226, real_loss=0.3455, fake_loss=0.4665, acc=0.8599, , time=2.029\n",
      "09/10 12:14:22 AM, INFO, github_: epoch[198/300], d_loss=0.8298, g_loss=1.256, real_loss=0.3672, fake_loss=0.4626, acc=0.8593, , time=2.072\n",
      "09/10 12:14:24 AM, INFO, github_: epoch[199/300], d_loss=0.8284, g_loss=1.38, real_loss=0.4064, fake_loss=0.422, acc=0.8456, , time=2.078\n",
      "09/10 12:14:26 AM, INFO, github_: epoch[200/300], d_loss=0.8524, g_loss=1.244, real_loss=0.362, fake_loss=0.4904, acc=0.8311, , time=2.443\n",
      "09/10 12:14:26 AM, INFO, github_: ****** eval start ******\n",
      "09/10 12:14:27 AM, INFO, github_: tsne, time=1.1073229312896729\n",
      "09/10 12:14:28 AM, INFO, github_: nnd, time=0.06820917129516602\n",
      "09/10 12:14:28 AM, INFO, github_: mmd, time=0.12205290794372559\n",
      "09/10 12:14:28 AM, INFO, github_: ****** eval end ******\n",
      "09/10 12:14:30 AM, INFO, github_: epoch[201/300], d_loss=0.844, g_loss=1.291, real_loss=0.3927, fake_loss=0.4513, acc=0.8385, , time=1.911\n",
      "09/10 12:14:31 AM, INFO, github_: epoch[202/300], d_loss=0.8176, g_loss=1.369, real_loss=0.4024, fake_loss=0.4152, acc=0.848, , time=1.902\n",
      "09/10 12:14:33 AM, INFO, github_: epoch[203/300], d_loss=0.8272, g_loss=1.24, real_loss=0.3619, fake_loss=0.4653, acc=0.8438, , time=1.887\n",
      "09/10 12:14:35 AM, INFO, github_: epoch[204/300], d_loss=0.8051, g_loss=1.369, real_loss=0.3979, fake_loss=0.4072, acc=0.8656, , time=1.87\n",
      "09/10 12:14:37 AM, INFO, github_: epoch[205/300], d_loss=0.8213, g_loss=1.311, real_loss=0.3962, fake_loss=0.4252, acc=0.8593, , time=1.931\n",
      "09/10 12:14:39 AM, INFO, github_: epoch[206/300], d_loss=0.7946, g_loss=1.394, real_loss=0.3968, fake_loss=0.3977, acc=0.8571, , time=1.856\n",
      "09/10 12:14:41 AM, INFO, github_: epoch[207/300], d_loss=0.8228, g_loss=1.339, real_loss=0.3953, fake_loss=0.4275, acc=0.8352, , time=1.774\n",
      "09/10 12:14:43 AM, INFO, github_: epoch[208/300], d_loss=0.8303, g_loss=1.367, real_loss=0.3789, fake_loss=0.4514, acc=0.8213, , time=1.903\n",
      "09/10 12:14:45 AM, INFO, github_: epoch[209/300], d_loss=0.8625, g_loss=1.238, real_loss=0.389, fake_loss=0.4735, acc=0.8312, , time=1.842\n",
      "09/10 12:14:46 AM, INFO, github_: epoch[210/300], d_loss=0.8197, g_loss=1.265, real_loss=0.3561, fake_loss=0.4636, acc=0.8584, , time=1.84\n",
      "09/10 12:14:49 AM, INFO, github_: epoch[211/300], d_loss=0.7972, g_loss=1.282, real_loss=0.3664, fake_loss=0.4308, acc=0.872, , time=1.808\n",
      "09/10 12:14:50 AM, INFO, github_: epoch[212/300], d_loss=0.825, g_loss=1.301, real_loss=0.3822, fake_loss=0.4428, acc=0.8543, , time=1.78\n",
      "09/10 12:14:52 AM, INFO, github_: epoch[213/300], d_loss=0.813, g_loss=1.322, real_loss=0.3745, fake_loss=0.4385, acc=0.862, , time=1.801\n",
      "09/10 12:14:54 AM, INFO, github_: epoch[214/300], d_loss=0.8069, g_loss=1.309, real_loss=0.3624, fake_loss=0.4445, acc=0.8485, , time=1.894\n",
      "09/10 12:14:56 AM, INFO, github_: epoch[215/300], d_loss=0.8087, g_loss=1.327, real_loss=0.3828, fake_loss=0.4258, acc=0.8561, , time=2.225\n",
      "09/10 12:14:58 AM, INFO, github_: epoch[216/300], d_loss=0.8092, g_loss=1.356, real_loss=0.3914, fake_loss=0.4177, acc=0.8515, , time=2.054\n",
      "09/10 12:15:00 AM, INFO, github_: epoch[217/300], d_loss=0.8196, g_loss=1.201, real_loss=0.32, fake_loss=0.4996, acc=0.8385, , time=1.895\n",
      "09/10 12:15:02 AM, INFO, github_: epoch[218/300], d_loss=0.7899, g_loss=1.338, real_loss=0.3829, fake_loss=0.407, acc=0.8619, , time=1.768\n",
      "09/10 12:15:04 AM, INFO, github_: epoch[219/300], d_loss=0.8036, g_loss=1.385, real_loss=0.4043, fake_loss=0.3993, acc=0.8696, , time=1.72\n",
      "09/10 12:15:06 AM, INFO, github_: epoch[220/300], d_loss=0.8341, g_loss=1.245, real_loss=0.3305, fake_loss=0.5036, acc=0.8301, , time=1.774\n",
      "09/10 12:15:07 AM, INFO, github_: epoch[221/300], d_loss=0.8287, g_loss=1.452, real_loss=0.4191, fake_loss=0.4096, acc=0.8385, , time=1.967\n",
      "09/10 12:15:09 AM, INFO, github_: epoch[222/300], d_loss=0.8349, g_loss=1.35, real_loss=0.4225, fake_loss=0.4124, acc=0.848, , time=1.727\n",
      "09/10 12:15:11 AM, INFO, github_: epoch[223/300], d_loss=0.8104, g_loss=1.322, real_loss=0.3786, fake_loss=0.4319, acc=0.8381, , time=1.804\n",
      "09/10 12:15:13 AM, INFO, github_: epoch[224/300], d_loss=0.8162, g_loss=1.31, real_loss=0.3711, fake_loss=0.4451, acc=0.8463, , time=1.803\n",
      "09/10 12:15:15 AM, INFO, github_: epoch[225/300], d_loss=0.8199, g_loss=1.35, real_loss=0.4078, fake_loss=0.4121, acc=0.8514, , time=1.765\n",
      "09/10 12:15:17 AM, INFO, github_: epoch[226/300], d_loss=0.7952, g_loss=1.504, real_loss=0.4404, fake_loss=0.3548, acc=0.8615, , time=1.889\n",
      "09/10 12:15:19 AM, INFO, github_: epoch[227/300], d_loss=0.8524, g_loss=1.365, real_loss=0.4183, fake_loss=0.4341, acc=0.847, , time=1.929\n",
      "09/10 12:15:21 AM, INFO, github_: epoch[228/300], d_loss=0.8364, g_loss=1.316, real_loss=0.4129, fake_loss=0.4235, acc=0.8483, , time=2.028\n",
      "09/10 12:15:23 AM, INFO, github_: epoch[229/300], d_loss=0.8218, g_loss=1.297, real_loss=0.3815, fake_loss=0.4403, acc=0.8615, , time=2.025\n",
      "09/10 12:15:25 AM, INFO, github_: epoch[230/300], d_loss=0.7937, g_loss=1.418, real_loss=0.4006, fake_loss=0.3931, acc=0.8607, , time=2.409\n",
      "09/10 12:15:28 AM, INFO, github_: epoch[231/300], d_loss=0.8441, g_loss=1.35, real_loss=0.4006, fake_loss=0.4435, acc=0.837, , time=2.236\n",
      "09/10 12:15:30 AM, INFO, github_: epoch[232/300], d_loss=0.8268, g_loss=1.425, real_loss=0.427, fake_loss=0.3997, acc=0.8448, , time=2.059\n",
      "09/10 12:15:32 AM, INFO, github_: epoch[233/300], d_loss=0.799, g_loss=1.337, real_loss=0.3691, fake_loss=0.43, acc=0.8567, , time=1.988\n",
      "09/10 12:15:34 AM, INFO, github_: epoch[234/300], d_loss=0.8241, g_loss=1.347, real_loss=0.3945, fake_loss=0.4296, acc=0.8493, , time=1.99\n",
      "09/10 12:15:36 AM, INFO, github_: epoch[235/300], d_loss=0.8557, g_loss=1.31, real_loss=0.4077, fake_loss=0.448, acc=0.8321, , time=2.016\n",
      "09/10 12:15:38 AM, INFO, github_: epoch[236/300], d_loss=0.8314, g_loss=1.293, real_loss=0.3725, fake_loss=0.4589, acc=0.8366, , time=2.001\n",
      "09/10 12:15:40 AM, INFO, github_: epoch[237/300], d_loss=0.8305, g_loss=1.313, real_loss=0.4046, fake_loss=0.4259, acc=0.8644, , time=1.979\n",
      "09/10 12:15:42 AM, INFO, github_: epoch[238/300], d_loss=0.7893, g_loss=1.337, real_loss=0.3823, fake_loss=0.407, acc=0.8727, , time=2.078\n",
      "09/10 12:15:44 AM, INFO, github_: epoch[239/300], d_loss=0.8336, g_loss=1.294, real_loss=0.385, fake_loss=0.4486, acc=0.8416, , time=2.036\n",
      "09/10 12:15:46 AM, INFO, github_: epoch[240/300], d_loss=0.8274, g_loss=1.454, real_loss=0.4361, fake_loss=0.3914, acc=0.8428, , time=1.98\n",
      "09/10 12:15:48 AM, INFO, github_: epoch[241/300], d_loss=0.8286, g_loss=1.293, real_loss=0.3791, fake_loss=0.4495, acc=0.8603, , time=2.037\n",
      "09/10 12:15:50 AM, INFO, github_: epoch[242/300], d_loss=0.8587, g_loss=1.285, real_loss=0.4002, fake_loss=0.4584, acc=0.8321, , time=2.139\n",
      "09/10 12:15:52 AM, INFO, github_: epoch[243/300], d_loss=0.8242, g_loss=1.314, real_loss=0.3755, fake_loss=0.4487, acc=0.8378, , time=1.993\n",
      "09/10 12:15:54 AM, INFO, github_: epoch[244/300], d_loss=0.8191, g_loss=1.292, real_loss=0.3867, fake_loss=0.4324, acc=0.8642, , time=1.994\n",
      "09/10 12:15:56 AM, INFO, github_: epoch[245/300], d_loss=0.7952, g_loss=1.376, real_loss=0.3961, fake_loss=0.3992, acc=0.8621, , time=2.156\n",
      "09/10 12:15:59 AM, INFO, github_: epoch[246/300], d_loss=0.7735, g_loss=1.293, real_loss=0.3289, fake_loss=0.4446, acc=0.8732, , time=2.364\n",
      "09/10 12:16:01 AM, INFO, github_: epoch[247/300], d_loss=0.7719, g_loss=1.326, real_loss=0.3664, fake_loss=0.4054, acc=0.8891, , time=2.197\n",
      "09/10 12:16:03 AM, INFO, github_: epoch[248/300], d_loss=0.7752, g_loss=1.408, real_loss=0.3822, fake_loss=0.3929, acc=0.8676, , time=1.961\n",
      "09/10 12:16:05 AM, INFO, github_: epoch[249/300], d_loss=0.8127, g_loss=1.406, real_loss=0.4122, fake_loss=0.4005, acc=0.8466, , time=2.041\n",
      "09/10 12:16:07 AM, INFO, github_: epoch[250/300], d_loss=0.8186, g_loss=1.294, real_loss=0.3747, fake_loss=0.4439, acc=0.8514, , time=1.992\n",
      "09/10 12:16:09 AM, INFO, github_: epoch[251/300], d_loss=0.8387, g_loss=1.251, real_loss=0.3848, fake_loss=0.4539, acc=0.8477, , time=1.924\n",
      "09/10 12:16:11 AM, INFO, github_: epoch[252/300], d_loss=0.785, g_loss=1.32, real_loss=0.3739, fake_loss=0.411, acc=0.8754, , time=1.929\n",
      "09/10 12:16:13 AM, INFO, github_: epoch[253/300], d_loss=0.7695, g_loss=1.375, real_loss=0.3608, fake_loss=0.4087, acc=0.884, , time=1.744\n",
      "09/10 12:16:15 AM, INFO, github_: epoch[254/300], d_loss=0.771, g_loss=1.4, real_loss=0.3749, fake_loss=0.3961, acc=0.8696, , time=1.91\n",
      "09/10 12:16:16 AM, INFO, github_: epoch[255/300], d_loss=0.814, g_loss=1.357, real_loss=0.3959, fake_loss=0.4181, acc=0.855, , time=1.755\n",
      "09/10 12:16:18 AM, INFO, github_: epoch[256/300], d_loss=0.7932, g_loss=1.361, real_loss=0.3909, fake_loss=0.4023, acc=0.8801, , time=1.786\n",
      "09/10 12:16:20 AM, INFO, github_: epoch[257/300], d_loss=0.7788, g_loss=1.315, real_loss=0.3607, fake_loss=0.4181, acc=0.8623, , time=1.873\n",
      "09/10 12:16:22 AM, INFO, github_: epoch[258/300], d_loss=0.7614, g_loss=1.367, real_loss=0.351, fake_loss=0.4104, acc=0.8871, , time=1.872\n",
      "09/10 12:16:24 AM, INFO, github_: epoch[259/300], d_loss=0.7786, g_loss=1.302, real_loss=0.3469, fake_loss=0.4318, acc=0.8714, , time=1.741\n",
      "09/10 12:16:26 AM, INFO, github_: epoch[260/300], d_loss=0.7969, g_loss=1.305, real_loss=0.3544, fake_loss=0.4425, acc=0.8692, , time=2.037\n",
      "09/10 12:16:28 AM, INFO, github_: epoch[261/300], d_loss=0.7862, g_loss=1.26, real_loss=0.3276, fake_loss=0.4586, acc=0.8659, , time=2.066\n",
      "09/10 12:16:30 AM, INFO, github_: epoch[262/300], d_loss=0.8495, g_loss=1.27, real_loss=0.3976, fake_loss=0.4519, acc=0.8545, , time=1.78\n",
      "09/10 12:16:32 AM, INFO, github_: epoch[263/300], d_loss=0.7879, g_loss=1.278, real_loss=0.3257, fake_loss=0.4623, acc=0.836, , time=1.873\n",
      "09/10 12:16:33 AM, INFO, github_: epoch[264/300], d_loss=0.8247, g_loss=1.459, real_loss=0.4129, fake_loss=0.4118, acc=0.837, , time=1.721\n",
      "09/10 12:16:35 AM, INFO, github_: epoch[265/300], d_loss=0.7596, g_loss=1.361, real_loss=0.3498, fake_loss=0.4098, acc=0.8752, , time=1.791\n",
      "09/10 12:16:37 AM, INFO, github_: epoch[266/300], d_loss=0.8153, g_loss=1.362, real_loss=0.3904, fake_loss=0.4249, acc=0.8483, , time=1.663\n",
      "09/10 12:16:39 AM, INFO, github_: epoch[267/300], d_loss=0.8154, g_loss=1.335, real_loss=0.3733, fake_loss=0.4422, acc=0.8565, , time=1.753\n",
      "09/10 12:16:40 AM, INFO, github_: epoch[268/300], d_loss=0.8285, g_loss=1.297, real_loss=0.3548, fake_loss=0.4736, acc=0.828, , time=1.725\n",
      "09/10 12:16:42 AM, INFO, github_: epoch[269/300], d_loss=0.801, g_loss=1.396, real_loss=0.3766, fake_loss=0.4244, acc=0.8582, , time=1.786\n",
      "09/10 12:16:44 AM, INFO, github_: epoch[270/300], d_loss=0.7799, g_loss=1.28, real_loss=0.3424, fake_loss=0.4374, acc=0.874, , time=1.817\n",
      "09/10 12:16:46 AM, INFO, github_: epoch[271/300], d_loss=0.8295, g_loss=1.417, real_loss=0.4335, fake_loss=0.396, acc=0.8556, , time=1.771\n",
      "09/10 12:16:48 AM, INFO, github_: epoch[272/300], d_loss=0.7757, g_loss=1.407, real_loss=0.3792, fake_loss=0.3965, acc=0.8748, , time=1.816\n",
      "09/10 12:16:50 AM, INFO, github_: epoch[273/300], d_loss=0.7641, g_loss=1.402, real_loss=0.371, fake_loss=0.3932, acc=0.8824, , time=1.756\n",
      "09/10 12:16:51 AM, INFO, github_: epoch[274/300], d_loss=0.7934, g_loss=1.32, real_loss=0.3599, fake_loss=0.4334, acc=0.8657, , time=1.8\n",
      "09/10 12:16:53 AM, INFO, github_: epoch[275/300], d_loss=0.7594, g_loss=1.402, real_loss=0.3509, fake_loss=0.4085, acc=0.8617, , time=1.75\n",
      "09/10 12:16:55 AM, INFO, github_: epoch[276/300], d_loss=0.7661, g_loss=1.385, real_loss=0.357, fake_loss=0.4091, acc=0.8696, , time=2.298\n",
      "09/10 12:16:57 AM, INFO, github_: epoch[277/300], d_loss=0.77, g_loss=1.462, real_loss=0.3882, fake_loss=0.3818, acc=0.8724, , time=1.842\n",
      "09/10 12:16:59 AM, INFO, github_: epoch[278/300], d_loss=0.7955, g_loss=1.342, real_loss=0.3614, fake_loss=0.4341, acc=0.8592, , time=1.804\n",
      "09/10 12:17:01 AM, INFO, github_: epoch[279/300], d_loss=0.7707, g_loss=1.323, real_loss=0.3529, fake_loss=0.4178, acc=0.8843, , time=1.75\n",
      "09/10 12:17:03 AM, INFO, github_: epoch[280/300], d_loss=0.771, g_loss=1.266, real_loss=0.3321, fake_loss=0.4389, acc=0.8822, , time=1.771\n",
      "09/10 12:17:04 AM, INFO, github_: epoch[281/300], d_loss=0.7869, g_loss=1.258, real_loss=0.3539, fake_loss=0.4331, acc=0.8801, , time=1.662\n",
      "09/10 12:17:06 AM, INFO, github_: epoch[282/300], d_loss=0.8143, g_loss=1.315, real_loss=0.3667, fake_loss=0.4476, acc=0.8488, , time=1.849\n",
      "09/10 12:17:08 AM, INFO, github_: epoch[283/300], d_loss=0.8057, g_loss=1.381, real_loss=0.3917, fake_loss=0.414, acc=0.8577, , time=1.78\n",
      "09/10 12:17:10 AM, INFO, github_: epoch[284/300], d_loss=0.814, g_loss=1.282, real_loss=0.3502, fake_loss=0.4638, acc=0.8353, , time=1.766\n",
      "09/10 12:17:12 AM, INFO, github_: epoch[285/300], d_loss=0.7865, g_loss=1.372, real_loss=0.369, fake_loss=0.4175, acc=0.8685, , time=1.849\n",
      "09/10 12:17:14 AM, INFO, github_: epoch[286/300], d_loss=0.7958, g_loss=1.172, real_loss=0.3027, fake_loss=0.4931, acc=0.8654, , time=1.736\n",
      "09/10 12:17:15 AM, INFO, github_: epoch[287/300], d_loss=0.7689, g_loss=1.394, real_loss=0.3621, fake_loss=0.4068, acc=0.8687, , time=1.829\n",
      "09/10 12:17:17 AM, INFO, github_: epoch[288/300], d_loss=0.8171, g_loss=1.413, real_loss=0.4353, fake_loss=0.3818, acc=0.8587, , time=1.771\n",
      "09/10 12:17:19 AM, INFO, github_: epoch[289/300], d_loss=0.7818, g_loss=1.415, real_loss=0.3612, fake_loss=0.4207, acc=0.8555, , time=1.857\n",
      "09/10 12:17:21 AM, INFO, github_: epoch[290/300], d_loss=0.7952, g_loss=1.316, real_loss=0.3597, fake_loss=0.4355, acc=0.8685, , time=1.761\n",
      "09/10 12:17:23 AM, INFO, github_: epoch[291/300], d_loss=0.8222, g_loss=1.372, real_loss=0.411, fake_loss=0.4113, acc=0.8595, , time=2.018\n",
      "09/10 12:17:25 AM, INFO, github_: epoch[292/300], d_loss=0.8197, g_loss=1.236, real_loss=0.3402, fake_loss=0.4795, acc=0.8465, , time=2.039\n",
      "09/10 12:17:27 AM, INFO, github_: epoch[293/300], d_loss=0.7625, g_loss=1.318, real_loss=0.3445, fake_loss=0.4179, acc=0.8902, , time=1.95\n",
      "09/10 12:17:29 AM, INFO, github_: epoch[294/300], d_loss=0.8078, g_loss=1.296, real_loss=0.3666, fake_loss=0.4412, acc=0.8494, , time=1.768\n",
      "09/10 12:17:30 AM, INFO, github_: epoch[295/300], d_loss=0.7522, g_loss=1.371, real_loss=0.3486, fake_loss=0.4036, acc=0.8851, , time=1.813\n",
      "09/10 12:17:32 AM, INFO, github_: epoch[296/300], d_loss=0.794, g_loss=1.319, real_loss=0.3496, fake_loss=0.4443, acc=0.8598, , time=1.771\n",
      "09/10 12:17:34 AM, INFO, github_: epoch[297/300], d_loss=0.8098, g_loss=1.34, real_loss=0.3426, fake_loss=0.4672, acc=0.8451, , time=1.85\n",
      "09/10 12:17:36 AM, INFO, github_: epoch[298/300], d_loss=0.8084, g_loss=1.321, real_loss=0.3631, fake_loss=0.4453, acc=0.8525, , time=1.837\n",
      "09/10 12:17:38 AM, INFO, github_: epoch[299/300], d_loss=0.7852, g_loss=1.327, real_loss=0.3523, fake_loss=0.4329, acc=0.8582, , time=1.93\n",
      "09/10 12:17:40 AM, INFO, github_: epoch[300/300], d_loss=0.7929, g_loss=1.349, real_loss=0.3731, fake_loss=0.4199, acc=0.8526, , time=1.914\n",
      "09/10 12:17:40 AM, INFO, github_: ****** eval start ******\n",
      "09/10 12:17:41 AM, INFO, github_: tsne, time=0.6748576164245605\n",
      "09/10 12:17:41 AM, INFO, github_: nnd, time=0.058959245681762695\n",
      "09/10 12:17:41 AM, INFO, github_: mmd, time=0.10558795928955078\n",
      "09/10 12:17:41 AM, INFO, github_: ****** eval end ******\n",
      "09/10 12:17:41 AM, INFO, github_: ****** fit end ******\n"
     ]
    }
   ],
   "source": [
    "model = TCGAN(model_cfg, evaluator)\n",
    "model.fit(x_tr_gan, x_te_gan)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1778af18ba8>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_all[10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fake = model.generate_data(10).reshape(10,270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1778a4eb898>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_fake[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando sines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Meu Drive\\\\Doutorado Unicamp\\\\Projeto\\\\github\\\\tcgan\\\\raw-data\\\\TimeGANSine\\\\sine_dim1_len100_r4.npy'\n",
    "data = np.load(path).reshape(10000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x177dc8e4e10>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3zV9b3H8dcnIYGEDQlhBAh7ygy4FYsDXNyqrWhVxIFi1dZaW2yvdt17a2tta68DqaCACi6qqLjrrIMkQCCEIZuQAIFAICH7fO8fOddHGkEOcE5+Z7yfj0ce5DdyzvsLyZtfftOcc4iISOSL8zqAiIgEhwpdRCRKqNBFRKKECl1EJEqo0EVEokQzr944JSXFZWRkePX2IiIRKScnZ49zLvVwyzwr9IyMDLKzs716exGRiGRmW4+0TLtcRESihApdRCRKqNBFRKKECl1EJEqo0EVEosRRC93M5pjZbjPLO8JyM7O/mdkGM1tpZqOCH1NERI4mkC30p4EJ37J8ItDP/zENePzEY4mIyLE66nnozrmPzSzjW1aZBMxz9ffh/cLM2plZF+dcUZAyikiEqqqtY29ZNfsOVXOgopYDlTWUVdZSWVtHRXUdVbU+6nyOOp/DOUdcnBFvRny80bxZPC0S4khKiKd1iwRat2hGmxYJdGyVSIeWiSTEa49xY8G4sKgbsL3BdIF/3jcK3cymUb8VT48ePYLw1iLiFecce8qq2bK3nG17D7G15BCF+yvYWVpJYWkFxQeqOFhVG7L3b5uUQOc2LejctgVd2rYgvX0SPTq2pEeHZHqltKRtUkLI3jtcBaPQ7TDzDvvUDOfcLGAWQGZmpp6sIRIhDlTWsKbwAGuKDrB250HW7zrIxuJySitqvl7HDDq1bk6XtkkM7Nyas/qlktIqkY6tmtM+OYE2SQm08W9pJyXE0yIxnsT4OJrFGfFxhpnh8znqnKO2zlFVW0dljY+KmjrKKuu37g9U1LC3vJq9ZdXsKati14FKdh6oZHXhAfaUVf1b5pRWzemT2pIBnVszsHMbBnWp/zMpMb6p//qaTDAKvQDo3mA6HSgMwuuKiAdq63ysKTpIztYScgtKyd2+n017yr9e3j45gf5prbloWBf6praiV2pLenZIplv7JJo3O7GyjIsz4jAS4jnm4j1UXUvBvgq27j3EpuIyNhaXsWF3GYuW7aCsqv5q+fg4o1+nVgxPb8eIHu3I7NmePqmtiIs73HZp5AlGoS8GbjezhcDJQKn2n4tEjpo6HysLSvl84x6+2FTCsm37OFRdB9RvcQ/v3o7LRnVjSNe2DOrShrQ2zTELvwJMTmxG/7TW9E9rDaR9Pd/nc+zYX0F+0QHydpSSW1DK2/k7eT67fk9xu+QEMnu255TeHTm1T0cGdW4TsQV/1EI3swXAOCDFzAqAXwEJAM65mcAS4EJgA3AImBqqsCISHNtLDvHh+mI+WlfM5xv3UO4v8IGdW3PF6HQyMzqQ2bM9XdsleZz0xMXFGd07JNO9QzIXDOkM1O//37ynnOyt+8jZso8vN+/lvTW7gfrfQM7ol8rZ/VM5q38KnVq38DL+MTGvHhKdmZnpdLdFkabh8zmWb9/Hu/m7eX/NLr7aXQZAevskzuqfyhl9Uzild0c6tEz0OKl3ikor+HzjXj7dsIeP1+/5ep/88PS2jB+UxrmD0hjUpbXnv52YWY5zLvOwy1ToItGpzudYurmEN/OKeCtvJ7sPVtEszhjbqwPjB6VxzoBUeqW09LygwpHP51iz8wAfrN3Ne2t2s2L7fgB6dkxmwtDOXDi0C8PS23ryd6dCF4kRzjlWFpTy6opCXltZSPHBKlokxHHOgE5MGNqZcQM6xeTpfCdq98FK3svfzZt5RXy+cS+1PkfPjslcOrwrk0Z0pW+n1k2WRYUuEuV2llayaHkBL+UUsKm4nMT4OM4ZmMolw7vynYGdSE707Fk2UWf/oWreWb2LxbmFfLZxDz5Xv1vm8tHpXDq8K+2SQ7vbSoUuEoVq6nz8c+1uFizdxsfri/E5GJvRgctGdWPiSV20Jd4Edh+s5LXcIl7OKSC/6ACJ8XGcPySNq8f24JTeHUNytowKXSSKFJVW8NyX21iYtZ3ig1V0btOC72Wmc/modDJSWnodL2atLizlxewC/rF8B6UVNfTsmMwPTu7B9zO7B3WrXYUuEuGcc3y5uYS5n23hnfxd+JzjnAGduHpsD8YNSKWZ7msSNipr6ngzr4jnvtxG1pZ9NG8Wx6QRXbn+tF4M7trmhF9fhS4SoaprfSxZVcSTn24ib8cB2iUncGVmd645pSfdOyR7HU+OIr/wAPO/2Mory3dQUVPH6X07cuMZvRjXv9Nx745RoYtEmPKqWhYs3cbsTzdTVFpJn9SW3HhGby4b1Y0WCdF7L5JoVXqohueWbmPuZ1vYeaCS60/L4NeXDjmu1/q2Qtehb5Ewsv9QNXP+tYW5n22htKKGU3p34H++exJn90+N2MvRBdomJzB9XB9uOrMXS1YV0Se1VUjeR4UuEgb2llXx5KebmffZFsqr6zh/cBrTx/VhZI/2XkeTIEqIj2PSiG4he30VuoiH9h+q5omPNzH3sy1U1NRx8bCu3H5OXwZ0broLVSR6qNBFPHCwsoYnP9nMnE83U1ZdyyXDunLn+H707RSaX8UlNqjQRZpQVW0dz3yxjUc/2EBJeTUThnTmrvP6a4tcgkKFLtIEfD7HaysL+eNb69ixv4LT+3bk5xMGMiy9ndfRJIqo0EVCLGtLCf/1ej65BaUM7tKGBy4/iTP7pXodS6KQCl0kRAr2HeL3b67ljZVFdG7Tgj99bziXjeym0w8lZFToIkFWUV3H4x9t5ImPNmIGPz63H7ec1SeqH04s4UGFLhIkzjneyd/Fb1/LZ8f+Ci4d3pUZEwdGxWPcJDKo0EWCYOvecn61eDUfritmQFprnp92Cif37uh1LIkxKnSRE1Bd6+Pvn2zib+9/RUJ8HPddPJjrTu1Jgu5+KB5QoYscp+wtJdy7aBVf7S7jopO6cP8lg0lrEzlPiJfoo0IXOUYHK2v441vrmP/FVrq1S+Kp68dwzsBOXscSUaGLHIsP1u3mF4tWsfNAJTec3ou7z+9Py+b6MZLwoO9EkQCUHqrhd2/k81JOAf3TWvHYD07TnRAl7KjQRY7ig7W7mbFoJXvKqrn9nL7cMb4vzZvpnHIJPyp0kSMoq6rlv9/IZ8HS7QxIa82T143hpPS2XscSOSIVushhZG0p4ScvrKBgXwW3nt2Hu87rp61yCXsqdJEGqmt9PPz+eh7/cCPp7ZN58ZZTyczo4HUskYCo0EX8NhaX8eOFK1i1o5QrM7tz/yWDdQaLRBR9t0rMc87xQvZ2fr04n+YJccy8ZhQThnbxOpbIMVOhS0wrrajhF/9YxRsrizi1d0f+cuUIOrfV1Z4SmVToErNWbN/P7c8to6i0knsuGMCtZ/chXvcqlwgW0B2EzGyCma0zsw1mNuMwy9ub2T/MbKWZLTWzocGPKhIczjme/GQT35v5Gc7BC7ecyg/P6asyl4h31C10M4sHHgXOAwqALDNb7JzLb7DaL4AVzrnvmtlA//rjQxFY5ESUVtTw0xdzeTd/F+cNTuPBK4bRLjnR61giQRHILpexwAbn3CYAM1sITAIaFvpg4PcAzrm1ZpZhZmnOuV3BDixyvPJ2lDL92RyK9ldy38WDueH0DMy0VS7RI5BdLt2A7Q2mC/zzGsoFLgMws7FATyA9GAFFTpRzjgVLt3HZ459RW+d4/pZTufGMXipziTqBbKEf7rveNZp+AHjYzFYAq4DlQO03XshsGjANoEePHseWVOQ4VNbUcf+rebyQXcCZ/VL465Uj6NiqudexREIikEIvALo3mE4HChuu4Jw7AEwFsPrNns3+DxqtNwuYBZCZmdn4PwWRoCrYd4jpzyxj1Y5S7vhOX358bn8d+JSoFkihZwH9zKwXsAOYDFzdcAUzawcccs5VAzcBH/tLXsQTn23Yww+fW0ZtnePv12Vy3uA0ryOJhNxRC905V2tmtwNvA/HAHOfcajO71b98JjAImGdmddQfLL0xhJlFjsg5x5x/beF/lqyhd0pLZl2XSa+Ull7HEmkSAV1Y5JxbAixpNG9mg88/B/oFN5rIsamsqeOX/8jj5WUFnD84jT9fOYJWuheLxBB9t0tU2H2gkpvn55C7fT93ndufO77TlzjtL5cYo0KXiLeyYD83z8vmYGUtM68ZzYShnb2OJOIJFbpEtNdXFnL3C7mktGrOy9NPY1CXNl5HEvGMCl0iknOO//3nBv787noye7Zn5rWjSdH55RLjVOgScSpr6vj5yyt5dUUhl43qxu8vO0mPhxNBhS4RpqS8mpvnZZOzdR/3XDCA28b10SX8In4qdIkYm4rLmPp0FkWllTx69SguGqanCok0pEKXiJC1pYSb52UTZ8aCm09hdM/2XkcSCTsqdAl7r68s5Ccv5JLeLomnp46lR8dkryOJhCUVuoSt+icLbea/l6whs2d7/n5dJu1b6mEUIkeiQpew5PM5fvdGPk/9awsXntSZP39/BC0SdCaLyLdRoUvYqaqt4ycv5PLGyiKmnp7BfRcN1mX8IgFQoUtYOVBZw7R52XyxqYRfXDiQm8/srdMSRQKkQpewsftgJVPmZPHVroP89coR/MfIxk86FJFvo0KXsLB1bznXzl7KnrIqZl8/hrP7p3odSSTiqNDFc6sLS5kyJ4s6n49nbzqZkT10jrnI8VChi6eytpRww1NZtG7RjHnTTqVvp9ZeRxKJWCp08cwHa3cz/dkcurZNYv5NJ9OtXZLXkUQimgpdPPFabiF3Pb+CAZ1bM/eGsbr1rUgQqNClyT2ftY0Zi1YxpmcHnrw+kzYtEryOJBIVVOjSpGZ/upnfvZ7PWf1TeeKa0SQl6upPkWBRoUuTcM7xyD838NC765k4tDN/nTxCD6UQCTIVuoScc44H317HYx9u5LKR3fjjFcNoFh/ndSyRqKNCl5ByzvG719cw51+bufrkHvzXpKG6L4tIiKjQJWR8Psd9r+bx7JfbmHp6BvdfPFj3ZREJIRW6hITP57h30Sqez97O9HF9+NkFA1TmIiGmQpegq/M57nkpl0XLdnDn+H7cdW4/lblIE1ChS1DV1vn46Yu5vLKikLvP688d4/t5HUkkZqjQJWhq63z85IVcFucW8rMJA7htXF+vI4nEFBW6BEVtnY8fP7+C11cWMWPiQG49u4/XkURijgpdTlhtnY8fPb+CN1YWce/EgdyiMhfxhApdTkhtnY+7/M///MWFA5l2lspcxCu6XE+OW53PcfeLubyWW8iMiSpzEa8FVOhmNsHM1pnZBjObcZjlbc3sNTPLNbPVZjY1+FElnNT5HPe8mMurKwq554IB2mcuEgaOWuhmFg88CkwEBgNXmdngRqv9EMh3zg0HxgEPmVlikLNKmPD5HDNeXsmi5Tu4+7z+/PAcnc0iEg4C2UIfC2xwzm1yzlUDC4FJjdZxQGurv3qkFVAC1AY1qYQF5xz/+WoeL+YUcOf4fjrPXCSMBFLo3YDtDaYL/PMaegQYBBQCq4AfOed8jV/IzKaZWbaZZRcXFx9nZPGKc47fvJbPc19uY/q4Ptx1rspcJJwEUuiHu2bbNZq+AFgBdAVGAI+YWZtvfJFzs5xzmc65zNTU1GMOK95xzvHAm2t5+rMt3HhGL92bRSQMBVLoBUD3BtPp1G+JNzQVWOTqbQA2AwODE1HCwcPvf8UTH2/imlN68J8XDVKZi4ShQAo9C+hnZr38BzonA4sbrbMNGA9gZmnAAGBTMIOKd574aCN/fe8rrhidzm8vHaoyFwlTR72wyDlXa2a3A28D8cAc59xqM7vVv3wm8DvgaTNbRf0ump875/aEMLc0kXmfb+H3b67l4mFd+MPlw/RwCpEwFtCVos65JcCSRvNmNvi8EDg/uNHEay/lFHD/q6s5d1Aaf7lyBPEqc5GwpitF5bDeXFXEz17K5fS+HXnk6pEk6BmgImFPP6XyDR+tL+bOhcsZ2aM9f78ukxYJ8V5HEpEAqNDl32RtKeGW+dn069SaOdePITlR928TiRQqdPla3o5Sbngqi65tk5h341jaJiV4HUlEjoEKXQDYVFzGlDlLaZOUwDM3nUxKq+ZeRxKRY6RCF4pKK7h29lIA5t84lq7tkjxOJCLHQ4Ue40rKq7l29lIOVNQw94ax9E5t5XUkETlOOuIVw8qqapn61FK2lxxi3g1jGdqtrdeRROQEqNBjVFVtHbfOzyGv8ABPXDOak3t39DqSiJwg7XKJQXU+x09eyOXTDXv44+XDOHdwmteRRCQIVOgxxjnHrxev5o2VRfzywkFcPjrd60giEiQq9Bjzt/c3MP+Lrdxydm9uPqu313FEJIhU6DHk2S+38pf31nP5qHRmTNDt6kWijQo9RryVt5P7XsnjnAGpPHD5SbqnuUgUUqHHgKWbS7hz4XKGpbfj0R+M0p0TRaKUfrKj3PpdB7lpbhbp7ZN0sy2RKKdCj2JFpRVMmbOU5gnxzJ06lg4tE72OJCIhpEKPUqUVNVw/J4uDlbU8PXUM3Tskex1JREJMhR6FqmrruGV+Npv2lPHEtaMZ0lWX9IvEAu1QjTI+n+OnL67ki00lPDx5BKf3TfE6kog0EW2hR5kH3lrLa7mFzJg4kEkjunkdR0SakAo9ijz9r83M+ngTU07tyS26ClQk5qjQo8Tbq3fym9fzOX9wGvdfMkQXDonEIBV6FFi2bR93LljO8PR2PDx5JPFxKnORWKRCj3Bb9pRz09xsOrdtwewpmSQlxnsdSUQ8okKPYCXl1Ux9OgvnHE9dP4aOerCzSEzTaYsRqrKmjmnzstmxv4LnbjpZzwIVEW2hR6L6c81zyd66j798fwSZGR28jiQiYUCFHoEefGcdr68s4t6JA7loWBev44hImFChR5iFS7fx+IcbufrkHkzTueYi0oAKPYJ88lUxv3wlj7P7p/LbS3WuuYj8OxV6hFi/6yC3PbOMfp1a8cjVI2mmh1SISCMBtYKZTTCzdWa2wcxmHGb5PWa2wv+RZ2Z1ZqYjdUFSfLCKqU9l0SIxntnXj6F1iwSvI4lIGDpqoZtZPPAoMBEYDFxlZoMbruOce9A5N8I5NwK4F/jIOVcSisCxprKmjpvmZbO3vIrZUzLp1i7J60giEqYC2UIfC2xwzm1yzlUDC4FJ37L+VcCCYISLdT6f4+4XcllZsJ+HJ49kWHo7ryOJSBgLpNC7AdsbTBf4532DmSUDE4CXj7B8mpllm1l2cXHxsWaNOQ+9u443VtWfnnjBkM5exxGRMBdIoR/uVAp3hHUvAf51pN0tzrlZzrlM51xmampqoBlj0ks5BTz6wUauGtudm8/U6YkicnSBFHoB0L3BdDpQeIR1J6PdLSds6eYS7l20ktP6dOS3k4bq9EQRCUgghZ4F9DOzXmaWSH1pL268kpm1Bc4GXg1uxNiyZU85t8zPpnv7ZB7/wWgSdHqiiAToqDfncs7VmtntwNtAPDDHObfazG71L5/pX/W7wDvOufKQpY1ypRU13Dg3CwfMvn4MbZN1eqKIBC6guy0655YASxrNm9lo+mng6WAFizW1dT5uf24Z20oOMf/Gk+mV0tLrSCISYXT73DDx29fz+eSrPfzh8pM4pXdHr+OISATSDtowMO/zLcz7fCs3n9mLK8f08DqOiEQoFbrHPvmqmN+8ls/4gZ2YMXGQ13FEJIKp0D20sbiM255dRt/UVjx8lR7uLCInRoXukf2HqrlpbjaJ8XE8OSWTVs11OENEToxaxAM1dT5uf245BfsO8dzNp9C9Q7LXkUQkCqjQPfBfr+fz6YY9/PGKYYzR80BFJEi0y6WJPfPFVub6z2j5fmb3o3+BiEiAVOhN6PONe/n14tWMG5CqM1pEJOhU6E1k295DTH82h4yUlvxNZ7SISAio0JvAwcoabpqXhXPw5HWZtNEj5EQkBHRQNMR8Psddz69gY3E5824YS4bu0SIiIaIt9BB76N11vLdmN/ddNIjT+6Z4HUdEopgKPYQW5xZ+/dShKadleB1HRKKcCj1E8naU8rOXchmT0Z7fXKqnDolI6KnQQ6D4YBU3z8umQ3Iij18zmsRm+msWkdDTQdEgq6qtY/ozOew7VM1Lt55GSqvmXkcSkRihQg8i5xy/Xrya7K37+N+rRjK0W1uvI4lIDNG+gCB65sttLFi6ndvG9eGS4V29jiMiMUaFHiRfbNrLbxav5jsDO3H3+QO8jiMiMUiFHgQF+w5x27PL6NExmb9OHqHL+kXEEyr0E1RRXcct83OoqfPxd13WLyIe0kHRE+Cc42cvryS/6ABzpoyhT2orryOJSAzTFvoJmPXxJl7LLeSn5w/gnIGdvI4jIjFOhX6cPlpfzB/eWstFJ3XhtnF9vI4jIqJCPx5b9pRzx3PL6J/Wmge/N0yX9YtIWFChH6Pyqlqmzc8mLs74+3WZJCfqMISIhAcV+jFwzvHTF3PZsLuMR64aRfcOyV5HEhH5mgr9GDz24UbezNvJvRMHcUY/3dtcRMKLCj1AH6zdzZ/eWcekEV256cxeXscREfkGFXoANu8p586FyxnUuQ0PXKaDoCISnlToR1FWVcu0ednExxlPXDuapMR4ryOJiByWCv1bOOe458VcNhbrIKiIhL+ACt3MJpjZOjPbYGYzjrDOODNbYWarzeyj4Mb0xv8fBJ0xcaAOgopI2DvqSdRmFg88CpwHFABZZrbYOZffYJ12wGPABOfcNjOL+OvgP1xXfxD0kuFdufnM3l7HERE5qkC20McCG5xzm5xz1cBCYFKjda4GFjnntgE453YHN2bT2rq3nDsXLGdAWmv+cPlJOggqIhEhkELvBmxvMF3gn9dQf6C9mX1oZjlmdt3hXsjMpplZtpllFxcXH1/iEDtUXcst83MwM2ZdqytBRSRyBFLoh9s8dY2mmwGjgYuAC4D7zKz/N77IuVnOuUznXGZqauoxhw015xw/f3kV63Yd5G9XjaRHRx0EFZHIEcjmZwHQvcF0OlB4mHX2OOfKgXIz+xgYDqwPSsomMvvTzbyWW8g9Fwzg7P7h9x+OiMi3CWQLPQvoZ2a9zCwRmAwsbrTOq8CZZtbMzJKBk4E1wY0aWp9t3MPv31zLhCGddTtcEYlIR91Cd87VmtntwNtAPDDHObfazG71L5/pnFtjZm8BKwEf8KRzLi+UwYOpcH8Fdzy3nF4pLfnT94frIKiIRKSAjvg555YASxrNm9lo+kHgweBFaxqVNXVMfyaHqlofT1w7mlbNdRBURCJTTLeXc45fvbqa3IJSZl07Ws8EFZGIFtOX/i9Yup3ns7dzx3f6cv6Qzl7HERE5ITFb6Mu27eNXi/M4u38qPz73G2dYiohEnJgs9OKDVdz2zDI6t23Bw5NHEB+ng6AiEvlibh96TZ2P259bxv6KahZNP512yYleRxIRCYqYK/QH3lzLl5tL+MuVwxnctY3XcUREgiamdrkszi1k9qebuf60DL47Mt3rOCIiQRUzhb5u50F+/tJKMnu25xcXDvI6johI0MVEoZdW1HDL/GxatWjGYz8YRWKzmBi2iMSYqG82n89x9wu5FOyr4LEfjKJTmxZeRxIRCYmoL/THPtzAe2t28Z8XDWJMRgev44iIhExUF/pH64t56N31/MeIrkw5LcPrOCIiIRW1hb695BA/Wlj/GLn/uUyPkROR6BeVhV5ZU8f0Z3Oo8zlmXjNaj5ETkZgQdU3nnOO+V/LI23GA2VMyyUhp6XUkEZEmEXVb6AuWbufFnALuHN+P8YPSvI4jItJkoqrQV2zfz68Xr+bs/qn8aHw/r+OIiDSpqCn0vWVVTH8mh05tmusOiiISk6JiH3ptnY87FiynpLyal6efpjsoikhMiopCf+jd9Xy2cS8PXjGMod3aeh1HRMQTEb/L5e3VO3n8w41cfXIPvpfZ3es4IiKeiehC31Rcxk9fyGV4elt+dclgr+OIiHgqYgv9UHUttz6TQ0KzOB67ZjTNm8V7HUlExFMRWejOOWa8vIoNu8v436tG0q1dkteRREQ8F5GF/vRnW1icW8jd5w/g9L4pXscREQkLEVfo2VtK+O831nDe4DSmn93H6zgiImEj4go9KTGe0/qm8ND3hxOni4dERL4WceehD+nalnk3jPU6hohI2Im4LXQRETk8FbqISJRQoYuIRAkVuohIlAio0M1sgpmtM7MNZjbjMMvHmVmpma3wf9wf/KgiIvJtjnqWi5nFA48C5wEFQJaZLXbO5Tda9RPn3MUhyCgiIgEIZAt9LLDBObfJOVcNLAQmhTaWiIgcq0AKvRuwvcF0gX9eY6eaWa6ZvWlmQw73QmY2zcyyzSy7uLj4OOKKiMiRBHJh0eEux3SNppcBPZ1zZWZ2IfAK8I2HejrnZgGzAMys2My2HmPe/5cC7DnOr41ksTjuWBwzxOa4Y3HMcOzj7nmkBYEUegHQ8MkR6UBhwxWccwcafL7EzB4zsxTn3BFDOudSA3jvwzKzbOdc5vF+faSKxXHH4pghNscdi2OG4I47kF0uWUA/M+tlZonAZGBxo0Cdzcz8n4/1v+7eYAQUEZHAHHUL3TlXa2a3A28D8cAc59xqM7vVv3wmcAUw3cxqgQpgsnOu8W4ZEREJoYBuzuWcWwIsaTRvZoPPHwEeCW60bzWrCd8rnMTiuGNxzBCb447FMUMQx23akBYRiQ669F9EJEqo0EVEokTEFfrR7isTDcysu5l9YGZrzGy1mf3IP7+Dmb1rZl/5/2zvddZgM7N4M1tuZq/7p2NhzO3M7CUzW+v/Nz81RsZ9l//7O8/MFphZi2gbt5nNMbPdZpbXYN4Rx2hm9/q7bZ2ZXXCs7xdRhd7gvjITgcHAVWY22NtUIVEL3O2cGwScAvzQP84ZwPvOuX7A+/7paPMjYE2D6VgY88PAW865gcBw6scf1eM2s27AnUCmc24o9WfQTSb6xv00MKHRvMOO0f8zPhkY4v+ax/ydF7CIKnRi5L4yzrki59wy/+cHqf8B70b9WOf6V5sL/Ic3CUPDzNKBi4AnG8yO9jG3Ac4CZgM456qdc/uJ8j7h2UwAAAIQSURBVHH7NQOSzKwZkEz9BYtRNW7n3MdASaPZRxrjJGChc67KObcZ2EB95wUs0go90PvKRA0zywBGAl8Cac65IqgvfaCTd8lC4q/AzwBfg3nRPubeQDHwlH9X05Nm1pIoH7dzbgfwJ2AbUASUOufeIcrH7XekMZ5wv0VaoQdyX5moYWatgJeBHze8vUI0MrOLgd3OuRyvszSxZsAo4HHn3EignMjfzXBU/v3Gk4BeQFegpZld420qz51wv0VaoR/1vjLRwswSqC/zZ51zi/yzd5lZF//yLsBur/KFwOnApWa2hfpdad8xs2eI7jFD/fd0gXPuS//0S9QXfLSP+1xgs3Ou2DlXAywCTiP6xw1HHuMJ91ukFfpR7ysTDfz3xZkNrHHO/bnBosXAFP/nU4BXmzpbqDjn7nXOpTvnMqj/d/2nc+4aonjMAM65ncB2MxvgnzUeyCfKx039rpZTzCzZ//0+nvpjRdE+bjjyGBcDk82suZn1ov6OtUuP6ZWdcxH1AVwIrAc2Ar/0Ok+IxngG9b9qrQRW+D8uBDpSf1T8K/+fHbzOGqLxjwNe938e9WMGRgDZ/n/vV4D2MTLu3wBrgTxgPtA82sYNLKD+GEEN9VvgN37bGIFf+rttHTDxWN9Pl/6LiESJSNvlIiIiR6BCFxGJEip0EZEooUIXEYkSKnQRkSihQhcRiRIqdBGRKPF/p24+EZymnlgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data[10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp FISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "c:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fire\n",
    "\n",
    "from mlpy.lib.utils.path import makedirs, tag_path\n",
    "from mlpy.lib.utils.log import set_logging\n",
    "from mlpy.lib.tfops.base import tf_keras_set_gpu_allow_growth\n",
    "from mlpy.configure import DIR_DATA_UCR15\n",
    "from mlpy.datasets.ucr_uea.data_names import UCR85_DATASETS\n",
    "\n",
    "from tcgan.lib.exp import Experiment\n",
    "from configure import DIR_LOG\n",
    "from tcgan.model.tcgan import TCGAN, TCGANConfig\n",
    "\n",
    "import numpy as np\n",
    "from mlpy.lib.data.utils import train_test_split, one_hot_to_dense\n",
    "import tensorflow as tf\n",
    "from tcgan.lib.eval import EvaluatorGAN, EvaluatorClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = tag_path(os.path.abspath(os.getcwd()), 2)\n",
    "log_dir = makedirs(os.path.join(DIR_LOG, tag))\n",
    "logger = set_logging(tag, log_dir)\n",
    "# data_name_list = UCR85_DATASETS\n",
    "data_name_list = ['Fish']\n",
    "\n",
    "model_cfg = dict(acc_threshold_to_train_d=0.75, kernel_size=10)\n",
    "exp_cfg = dict(use_testset=True, idx_layer=-3)\n",
    "exp = Experiment(tag, TCGAN, TCGANConfig, DIR_DATA_UCR15, data_name_list, log_dir,\n",
    "                    model_cfg_kwargs=model_cfg,\n",
    "                    **exp_cfg)\n",
    "\n",
    "fire.Fire(exp.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 464) (175, 464)\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Meu Drive\\\\Doutorado Unicamp\\\\Projeto\\\\github\\\\tcgan\\\\raw-data\\\\UCR_TS_Archive_2015\\\\Fish\\\\Fish_TRAIN'\n",
    "data_train = np.genfromtxt(path, delimiter=',', dtype=np.float32)\n",
    "path = 'C:\\\\Meu Drive\\\\Doutorado Unicamp\\\\Projeto\\\\github\\\\tcgan\\\\raw-data\\\\UCR_TS_Archive_2015\\\\Fish\\\\Fish_TEST'\n",
    "data_test = np.genfromtxt(path, delimiter=',', dtype=np.float32)\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse\n",
    "x_tr = data_train[:, :-1]\n",
    "y_tr = data_train[:, -1].astype(int)\n",
    "x_te = data_test[:, :-1]\n",
    "y_te = data_test[:, -1].astype(int)\n",
    "y_all = np.concatenate([y_tr, y_te])\n",
    "classes, y_all = np.unique(y_all, return_inverse=True)\n",
    "n_class = len(classes)\n",
    "x_tr = x_tr[..., np.newaxis]\n",
    "x_te = x_te[..., np.newaxis]\n",
    "\n",
    "# all data can be used in unsupervised learning\n",
    "x_all = np.vstack([x_tr, x_te])\n",
    "_, x_te_gan, _, _ = train_test_split(\n",
    "    x_all, y_all, train_size=0.9, random_state=42, stratify=y_all)\n",
    "x_tr_gan = x_all  # use all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/23 09:59:29 AM, INFO, github_: ****** configure init ******\n",
      "09/23 09:59:30 AM, INFO, github_: The settings are as follows: \n",
      "strides:2\n",
      "padding:same\n",
      "initializer:<tensorflow.python.keras.initializers.initializers_v2.TruncatedNormal object at 0x00000273D5412198>\n",
      "leak_slope:0.2\n",
      "logger:<Logger github_ (INFO)>\n",
      "log_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\n",
      "train_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\training\n",
      "eval_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\evaluation\n",
      "ckpt_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\checkpoint\n",
      "ckpt_prefix:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\checkpoint\\ckpt\n",
      "seed:42\n",
      "np_rs:RandomState(MT19937)\n",
      "verbose:0\n",
      "x_shape:(463, 1)\n",
      "noise_shape:(100,)\n",
      "noise_method:normal\n",
      "noise_sampler:<function random_normal at 0x00000273B6556B70>\n",
      "batch_size:16\n",
      "epochs:300\n",
      "g_lr:0.0002\n",
      "d_lr:0.0002\n",
      "g_beta1:0.5\n",
      "d_beta1:0.5\n",
      "g_units_base:32\n",
      "d_units_base:32\n",
      "d_layers:4\n",
      "g_layers:4\n",
      "d_dropout_rate:0.0\n",
      "g_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "d_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "kernel_size:10\n",
      "acc_threshold_to_train_d:0.75\n",
      "ckpt_max_to_keep:2\n",
      "n_epochs_to_save_ckpt:15\n",
      "n_to_evaluate:3\n",
      "n_epochs_to_evaluate:100\n",
      "n_examples_to_generate:16\n",
      "metrics:['nnd', 'mmd', 'vis']\n",
      "noise_seed:[[-0.28077507 -0.1377521  -0.6763296  ... -0.66411126  1.4531434\n",
      "   0.63142705]\n",
      " [ 1.4347553  -0.9590058   1.399536   ...  0.09790254 -0.8498453\n",
      "   0.8285087 ]\n",
      " [ 0.9079667  -0.53826797 -0.75165933 ...  0.00500222  0.46697247\n",
      "  -0.49156648]\n",
      " ...\n",
      " [ 1.0430238  -0.2649641  -0.44542065 ... -0.44225916  0.05121567\n",
      "   0.56583524]\n",
      " [-0.35650563  1.5591161   0.22819136 ...  1.8435367  -0.66581184\n",
      "  -0.97975284]\n",
      " [-1.3944459  -0.31205386  0.46640927 ... -0.12672192  2.9069102\n",
      "  -1.0910585 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_tr.shape[1:]\n",
    "# input_shape = x_tr_gan.shape\n",
    "tag = tag_path(os.path.abspath(os.getcwd()), 2)\n",
    "log_dir = makedirs(os.path.join(DIR_LOG, tag))\n",
    "logger = set_logging(tag, log_dir)\n",
    "model_cfg = TCGANConfig(input_shape, log_dir, logger, **dict(acc_threshold_to_train_d=0.75, kernel_size=10))\n",
    "evaluator = EvaluatorGAN(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/23 09:59:32 AM, INFO, github_: ****** fit start ******\n",
      "09/23 09:59:32 AM, INFO, github_: train from scratch.\n",
      "09/23 09:59:32 AM, INFO, github_: ****** eval start ******\n",
      "09/23 09:59:33 AM, INFO, github_: tsne, time=0.38495349884033203\n",
      "09/23 09:59:33 AM, INFO, github_: nnd, time=0.008911609649658203\n",
      "09/23 09:59:33 AM, INFO, github_: mmd, time=0.6510536670684814\n",
      "09/23 09:59:33 AM, INFO, github_: ****** eval end ******\n",
      "09/23 09:59:37 AM, INFO, github_: epoch[1/300], d_loss=0.6722, g_loss=0.745, real_loss=0.01199, fake_loss=0.6603, acc=0.7948, , time=4.02\n",
      "09/23 09:59:38 AM, INFO, github_: epoch[2/300], d_loss=0.558, g_loss=0.927, real_loss=0.02696, fake_loss=0.5311, acc=0.929, , time=0.7948\n",
      "09/23 09:59:39 AM, INFO, github_: epoch[3/300], d_loss=0.5161, g_loss=0.9918, real_loss=0.01958, fake_loss=0.4965, acc=0.9444, , time=0.783\n",
      "09/23 09:59:40 AM, INFO, github_: epoch[4/300], d_loss=0.8169, g_loss=1.257, real_loss=0.4323, fake_loss=0.3846, acc=0.8991, , time=0.838\n",
      "09/23 09:59:41 AM, INFO, github_: epoch[5/300], d_loss=0.8661, g_loss=1.435, real_loss=0.4015, fake_loss=0.4646, acc=0.8139, , time=0.971\n",
      "09/23 09:59:42 AM, INFO, github_: epoch[6/300], d_loss=0.9939, g_loss=1.378, real_loss=0.5207, fake_loss=0.4732, acc=0.7679, , time=1.014\n",
      "09/23 09:59:43 AM, INFO, github_: epoch[7/300], d_loss=1.251, g_loss=1.175, real_loss=0.6486, fake_loss=0.6027, acc=0.6694, , time=1.065\n",
      "09/23 09:59:44 AM, INFO, github_: epoch[8/300], d_loss=1.164, g_loss=1.072, real_loss=0.6021, fake_loss=0.5616, acc=0.7114, , time=0.9963\n",
      "09/23 09:59:45 AM, INFO, github_: epoch[9/300], d_loss=1.297, g_loss=1.133, real_loss=0.6583, fake_loss=0.6384, acc=0.6696, , time=1.021\n",
      "09/23 09:59:46 AM, INFO, github_: epoch[10/300], d_loss=1.143, g_loss=1.021, real_loss=0.6078, fake_loss=0.5352, acc=0.7392, , time=1.071\n",
      "09/23 09:59:54 AM, INFO, github_: epoch[11/300], d_loss=1.141, g_loss=1.049, real_loss=0.5702, fake_loss=0.571, acc=0.6834, , time=7.835\n",
      "09/23 09:59:58 AM, INFO, github_: epoch[12/300], d_loss=1.11, g_loss=0.977, real_loss=0.5559, fake_loss=0.5538, acc=0.7579, , time=3.86\n",
      "09/23 09:59:59 AM, INFO, github_: epoch[13/300], d_loss=1.081, g_loss=1.032, real_loss=0.5728, fake_loss=0.5086, acc=0.7825, , time=1.584\n",
      "09/23 10:00:01 AM, INFO, github_: epoch[14/300], d_loss=1.107, g_loss=1.047, real_loss=0.5817, fake_loss=0.5254, acc=0.7593, , time=1.473\n",
      "09/23 10:00:02 AM, INFO, github_: epoch[15/300], d_loss=1.128, g_loss=1.107, real_loss=0.6029, fake_loss=0.5254, acc=0.7021, , time=1.405\n",
      "09/23 10:00:07 AM, INFO, github_: epoch[16/300], d_loss=1.102, g_loss=1.128, real_loss=0.628, fake_loss=0.4739, acc=0.733, , time=4.413\n",
      "09/23 10:00:12 AM, INFO, github_: epoch[17/300], d_loss=1.206, g_loss=0.967, real_loss=0.5885, fake_loss=0.618, acc=0.6954, , time=4.808\n",
      "09/23 10:00:13 AM, INFO, github_: epoch[18/300], d_loss=1.132, g_loss=1.023, real_loss=0.5973, fake_loss=0.5351, acc=0.7137, , time=1.389\n",
      "09/23 10:00:15 AM, INFO, github_: epoch[19/300], d_loss=1.151, g_loss=1.02, real_loss=0.5452, fake_loss=0.6058, acc=0.6656, , time=1.443\n",
      "09/23 10:00:16 AM, INFO, github_: epoch[20/300], d_loss=1.125, g_loss=0.9918, real_loss=0.5671, fake_loss=0.5574, acc=0.7151, , time=1.466\n",
      "09/23 10:00:18 AM, INFO, github_: epoch[21/300], d_loss=1.098, g_loss=0.996, real_loss=0.5498, fake_loss=0.5483, acc=0.7273, , time=1.385\n",
      "09/23 10:00:19 AM, INFO, github_: epoch[22/300], d_loss=1.184, g_loss=1.054, real_loss=0.6021, fake_loss=0.5822, acc=0.6745, , time=1.382\n",
      "09/23 10:00:20 AM, INFO, github_: epoch[23/300], d_loss=1.099, g_loss=0.9547, real_loss=0.5553, fake_loss=0.5433, acc=0.7601, , time=1.296\n",
      "09/23 10:00:22 AM, INFO, github_: epoch[24/300], d_loss=1.117, g_loss=0.9395, real_loss=0.5438, fake_loss=0.5731, acc=0.7102, , time=1.324\n",
      "09/23 10:00:23 AM, INFO, github_: epoch[25/300], d_loss=1.07, g_loss=0.9979, real_loss=0.5325, fake_loss=0.5372, acc=0.7429, , time=1.701\n",
      "09/23 10:00:31 AM, INFO, github_: epoch[26/300], d_loss=1.081, g_loss=0.9283, real_loss=0.5291, fake_loss=0.5516, acc=0.792, , time=7.58\n",
      "09/23 10:00:33 AM, INFO, github_: epoch[27/300], d_loss=1.069, g_loss=0.9408, real_loss=0.5288, fake_loss=0.5401, acc=0.8005, , time=1.929\n",
      "09/23 10:00:35 AM, INFO, github_: epoch[28/300], d_loss=1.095, g_loss=1.017, real_loss=0.5687, fake_loss=0.5265, acc=0.7502, , time=1.636\n",
      "09/23 10:00:36 AM, INFO, github_: epoch[29/300], d_loss=1.093, g_loss=0.9832, real_loss=0.5327, fake_loss=0.5598, acc=0.7246, , time=1.214\n",
      "09/23 10:00:37 AM, INFO, github_: epoch[30/300], d_loss=1.116, g_loss=1.052, real_loss=0.593, fake_loss=0.5232, acc=0.7435, , time=1.524\n",
      "09/23 10:00:43 AM, INFO, github_: epoch[31/300], d_loss=1.063, g_loss=0.979, real_loss=0.5351, fake_loss=0.5282, acc=0.7845, , time=2.671\n",
      "09/23 10:00:44 AM, INFO, github_: epoch[32/300], d_loss=1.077, g_loss=1.037, real_loss=0.5767, fake_loss=0.5001, acc=0.7618, , time=1.611\n",
      "09/23 10:00:49 AM, INFO, github_: epoch[33/300], d_loss=1.07, g_loss=1.008, real_loss=0.5488, fake_loss=0.5214, acc=0.7861, , time=4.651\n",
      "09/23 10:00:51 AM, INFO, github_: epoch[34/300], d_loss=1.102, g_loss=1.032, real_loss=0.5656, fake_loss=0.5363, acc=0.7374, , time=1.576\n",
      "09/23 10:00:52 AM, INFO, github_: epoch[35/300], d_loss=1.062, g_loss=1.057, real_loss=0.5709, fake_loss=0.4908, acc=0.764, , time=1.379\n",
      "09/23 10:00:53 AM, INFO, github_: epoch[36/300], d_loss=1.05, g_loss=1.022, real_loss=0.5188, fake_loss=0.5313, acc=0.7788, , time=1.437\n",
      "09/23 10:00:55 AM, INFO, github_: epoch[37/300], d_loss=1.05, g_loss=0.9932, real_loss=0.508, fake_loss=0.5422, acc=0.7575, , time=1.39\n",
      "09/23 10:00:56 AM, INFO, github_: epoch[38/300], d_loss=1.142, g_loss=1.066, real_loss=0.578, fake_loss=0.5643, acc=0.6914, , time=1.447\n",
      "09/23 10:00:58 AM, INFO, github_: epoch[39/300], d_loss=1.072, g_loss=1.058, real_loss=0.5548, fake_loss=0.5176, acc=0.7719, , time=1.299\n",
      "09/23 10:01:01 AM, INFO, github_: epoch[40/300], d_loss=1.081, g_loss=1.084, real_loss=0.6162, fake_loss=0.4651, acc=0.789, , time=2.985\n",
      "09/23 10:01:06 AM, INFO, github_: epoch[41/300], d_loss=1.037, g_loss=1.0, real_loss=0.5436, fake_loss=0.4935, acc=0.833, , time=5.365\n",
      "09/23 10:01:07 AM, INFO, github_: epoch[42/300], d_loss=1.046, g_loss=1.009, real_loss=0.517, fake_loss=0.5293, acc=0.7995, , time=1.417\n",
      "09/23 10:01:12 AM, INFO, github_: epoch[43/300], d_loss=1.104, g_loss=1.014, real_loss=0.4993, fake_loss=0.6043, acc=0.7232, , time=4.756\n",
      "09/23 10:01:13 AM, INFO, github_: epoch[44/300], d_loss=1.07, g_loss=1.006, real_loss=0.542, fake_loss=0.528, acc=0.7817, , time=1.125\n",
      "09/23 10:01:15 AM, INFO, github_: epoch[45/300], d_loss=1.066, g_loss=0.9714, real_loss=0.5123, fake_loss=0.554, acc=0.7551, , time=1.251\n",
      "09/23 10:01:18 AM, INFO, github_: epoch[46/300], d_loss=1.091, g_loss=1.025, real_loss=0.5801, fake_loss=0.5104, acc=0.7725, , time=1.271\n",
      "09/23 10:01:19 AM, INFO, github_: epoch[47/300], d_loss=1.097, g_loss=1.016, real_loss=0.5305, fake_loss=0.5665, acc=0.7384, , time=1.284\n",
      "09/23 10:01:20 AM, INFO, github_: epoch[48/300], d_loss=1.092, g_loss=1.089, real_loss=0.605, fake_loss=0.4872, acc=0.7677, , time=1.241\n",
      "09/23 10:01:27 AM, INFO, github_: epoch[49/300], d_loss=1.078, g_loss=0.9808, real_loss=0.5291, fake_loss=0.5488, acc=0.7484, , time=6.849\n",
      "09/23 10:01:37 AM, INFO, github_: epoch[50/300], d_loss=1.111, g_loss=1.084, real_loss=0.5587, fake_loss=0.5526, acc=0.7005, , time=10.39\n",
      "09/23 10:01:39 AM, INFO, github_: epoch[51/300], d_loss=1.107, g_loss=0.9822, real_loss=0.5722, fake_loss=0.5346, acc=0.7683, , time=1.882\n",
      "09/23 10:01:42 AM, INFO, github_: epoch[52/300], d_loss=1.081, g_loss=0.9885, real_loss=0.543, fake_loss=0.5378, acc=0.7628, , time=2.273\n",
      "09/23 10:01:43 AM, INFO, github_: epoch[53/300], d_loss=1.068, g_loss=0.9873, real_loss=0.5487, fake_loss=0.5194, acc=0.7875, , time=1.522\n",
      "09/23 10:01:49 AM, INFO, github_: epoch[54/300], d_loss=1.103, g_loss=1.023, real_loss=0.5819, fake_loss=0.5212, acc=0.7472, , time=6.297\n",
      "09/23 10:01:52 AM, INFO, github_: epoch[55/300], d_loss=1.03, g_loss=0.9505, real_loss=0.4851, fake_loss=0.5452, acc=0.7829, , time=2.143\n",
      "09/23 10:01:53 AM, INFO, github_: epoch[56/300], d_loss=1.089, g_loss=0.9602, real_loss=0.5311, fake_loss=0.5577, acc=0.7407, , time=1.21\n",
      "09/23 10:01:54 AM, INFO, github_: epoch[57/300], d_loss=1.013, g_loss=1.083, real_loss=0.532, fake_loss=0.4806, acc=0.7833, , time=1.584\n",
      "09/23 10:01:57 AM, INFO, github_: epoch[58/300], d_loss=1.184, g_loss=1.123, real_loss=0.6209, fake_loss=0.563, acc=0.6903, , time=2.068\n",
      "09/23 10:01:59 AM, INFO, github_: epoch[59/300], d_loss=1.158, g_loss=1.137, real_loss=0.6176, fake_loss=0.5401, acc=0.7096, , time=1.945\n",
      "09/23 10:02:04 AM, INFO, github_: epoch[60/300], d_loss=1.096, g_loss=1.052, real_loss=0.564, fake_loss=0.5317, acc=0.7323, , time=5.383\n",
      "09/23 10:02:07 AM, INFO, github_: epoch[61/300], d_loss=1.117, g_loss=1.003, real_loss=0.5582, fake_loss=0.5591, acc=0.7188, , time=1.474\n",
      "09/23 10:02:08 AM, INFO, github_: epoch[62/300], d_loss=1.093, g_loss=0.9764, real_loss=0.5408, fake_loss=0.5527, acc=0.7608, , time=1.246\n",
      "09/23 10:02:09 AM, INFO, github_: epoch[63/300], d_loss=1.066, g_loss=0.9702, real_loss=0.5273, fake_loss=0.5383, acc=0.7997, , time=1.37\n",
      "09/23 10:02:11 AM, INFO, github_: epoch[64/300], d_loss=1.054, g_loss=0.9713, real_loss=0.5098, fake_loss=0.5443, acc=0.7788, , time=2.106\n",
      "09/23 10:02:14 AM, INFO, github_: epoch[65/300], d_loss=1.058, g_loss=0.9496, real_loss=0.5011, fake_loss=0.5574, acc=0.7549, , time=2.49\n",
      "09/23 10:02:16 AM, INFO, github_: epoch[66/300], d_loss=1.025, g_loss=0.9372, real_loss=0.4798, fake_loss=0.545, acc=0.82, , time=1.782\n",
      "09/23 10:02:18 AM, INFO, github_: epoch[67/300], d_loss=1.052, g_loss=1.043, real_loss=0.5599, fake_loss=0.4922, acc=0.7936, , time=1.916\n",
      "09/23 10:02:19 AM, INFO, github_: epoch[68/300], d_loss=1.047, g_loss=1.003, real_loss=0.5449, fake_loss=0.5018, acc=0.803, , time=1.685\n",
      "09/23 10:02:21 AM, INFO, github_: epoch[69/300], d_loss=1.085, g_loss=1.016, real_loss=0.5412, fake_loss=0.5435, acc=0.7261, , time=2.026\n",
      "09/23 10:02:25 AM, INFO, github_: epoch[70/300], d_loss=1.091, g_loss=1.064, real_loss=0.5567, fake_loss=0.5347, acc=0.724, , time=3.761\n",
      "09/23 10:02:27 AM, INFO, github_: epoch[71/300], d_loss=1.087, g_loss=0.9968, real_loss=0.5229, fake_loss=0.5641, acc=0.7478, , time=2.024\n",
      "09/23 10:02:29 AM, INFO, github_: epoch[72/300], d_loss=1.056, g_loss=0.98, real_loss=0.5172, fake_loss=0.5386, acc=0.767, , time=1.737\n",
      "09/23 10:02:31 AM, INFO, github_: epoch[73/300], d_loss=1.046, g_loss=0.9531, real_loss=0.4907, fake_loss=0.5549, acc=0.7646, , time=2.082\n",
      "09/23 10:02:34 AM, INFO, github_: epoch[74/300], d_loss=1.048, g_loss=1.047, real_loss=0.5404, fake_loss=0.5073, acc=0.7449, , time=2.546\n",
      "09/23 10:02:36 AM, INFO, github_: epoch[75/300], d_loss=1.024, g_loss=0.9137, real_loss=0.4534, fake_loss=0.5704, acc=0.7957, , time=2.231\n",
      "09/23 10:02:37 AM, INFO, github_: epoch[76/300], d_loss=1.039, g_loss=0.9868, real_loss=0.5186, fake_loss=0.5205, acc=0.7963, , time=1.186\n",
      "09/23 10:02:39 AM, INFO, github_: epoch[77/300], d_loss=1.026, g_loss=0.9692, real_loss=0.4909, fake_loss=0.5356, acc=0.8153, , time=1.425\n",
      "09/23 10:02:40 AM, INFO, github_: epoch[78/300], d_loss=1.024, g_loss=1.068, real_loss=0.5316, fake_loss=0.4925, acc=0.7804, , time=1.368\n",
      "09/23 10:02:42 AM, INFO, github_: epoch[79/300], d_loss=1.104, g_loss=1.083, real_loss=0.5607, fake_loss=0.5432, acc=0.6987, , time=1.54\n",
      "09/23 10:02:43 AM, INFO, github_: epoch[80/300], d_loss=1.059, g_loss=1.022, real_loss=0.5435, fake_loss=0.5153, acc=0.7701, , time=1.302\n",
      "09/23 10:02:44 AM, INFO, github_: epoch[81/300], d_loss=1.048, g_loss=0.9883, real_loss=0.5253, fake_loss=0.5228, acc=0.7916, , time=1.265\n",
      "09/23 10:02:46 AM, INFO, github_: epoch[82/300], d_loss=1.13, g_loss=1.023, real_loss=0.5587, fake_loss=0.5711, acc=0.7092, , time=1.585\n",
      "09/23 10:02:47 AM, INFO, github_: epoch[83/300], d_loss=1.047, g_loss=1.009, real_loss=0.5194, fake_loss=0.5274, acc=0.7699, , time=1.561\n",
      "09/23 10:02:49 AM, INFO, github_: epoch[84/300], d_loss=1.08, g_loss=0.9471, real_loss=0.5226, fake_loss=0.5569, acc=0.7798, , time=1.451\n",
      "09/23 10:02:50 AM, INFO, github_: epoch[85/300], d_loss=1.048, g_loss=0.9989, real_loss=0.5024, fake_loss=0.5455, acc=0.7498, , time=1.487\n",
      "09/23 10:02:52 AM, INFO, github_: epoch[86/300], d_loss=1.101, g_loss=1.096, real_loss=0.5604, fake_loss=0.5411, acc=0.6877, , time=1.435\n",
      "09/23 10:02:53 AM, INFO, github_: epoch[87/300], d_loss=1.069, g_loss=0.9561, real_loss=0.5128, fake_loss=0.5565, acc=0.7658, , time=1.446\n",
      "09/23 10:02:55 AM, INFO, github_: epoch[88/300], d_loss=1.067, g_loss=1.003, real_loss=0.5254, fake_loss=0.5413, acc=0.7384, , time=1.555\n",
      "09/23 10:02:56 AM, INFO, github_: epoch[89/300], d_loss=1.083, g_loss=1.037, real_loss=0.5331, fake_loss=0.5498, acc=0.7281, , time=1.437\n",
      "09/23 10:02:57 AM, INFO, github_: epoch[90/300], d_loss=1.044, g_loss=1.035, real_loss=0.5482, fake_loss=0.496, acc=0.807, , time=1.285\n",
      "09/23 10:03:00 AM, INFO, github_: epoch[91/300], d_loss=1.057, g_loss=1.025, real_loss=0.5311, fake_loss=0.5256, acc=0.7614, , time=1.975\n",
      "09/23 10:03:02 AM, INFO, github_: epoch[92/300], d_loss=1.045, g_loss=1.042, real_loss=0.5219, fake_loss=0.5233, acc=0.7559, , time=2.415\n",
      "09/23 10:03:04 AM, INFO, github_: epoch[93/300], d_loss=1.083, g_loss=0.9907, real_loss=0.5351, fake_loss=0.5484, acc=0.7693, , time=2.281\n",
      "09/23 10:03:07 AM, INFO, github_: epoch[94/300], d_loss=1.125, g_loss=1.061, real_loss=0.5741, fake_loss=0.5507, acc=0.6972, , time=2.587\n",
      "09/23 10:03:10 AM, INFO, github_: epoch[95/300], d_loss=1.081, g_loss=1.033, real_loss=0.539, fake_loss=0.5418, acc=0.7403, , time=2.664\n",
      "09/23 10:03:12 AM, INFO, github_: epoch[96/300], d_loss=1.046, g_loss=0.9573, real_loss=0.4936, fake_loss=0.5527, acc=0.7802, , time=2.473\n",
      "09/23 10:03:15 AM, INFO, github_: epoch[97/300], d_loss=1.022, g_loss=1.107, real_loss=0.5479, fake_loss=0.4742, acc=0.7774, , time=2.734\n",
      "09/23 10:03:17 AM, INFO, github_: epoch[98/300], d_loss=1.057, g_loss=0.9887, real_loss=0.5302, fake_loss=0.527, acc=0.7981, , time=2.326\n",
      "09/23 10:03:20 AM, INFO, github_: epoch[99/300], d_loss=1.046, g_loss=0.9953, real_loss=0.4913, fake_loss=0.5549, acc=0.7711, , time=2.487\n",
      "09/23 10:03:22 AM, INFO, github_: epoch[100/300], d_loss=1.029, g_loss=0.9915, real_loss=0.475, fake_loss=0.5537, acc=0.7695, , time=1.935\n",
      "09/23 10:03:22 AM, INFO, github_: ****** eval start ******\n",
      "09/23 10:03:22 AM, INFO, github_: tsne, time=0.5862236022949219\n",
      "09/23 10:03:22 AM, INFO, github_: nnd, time=0.02389240264892578\n",
      "09/23 10:03:22 AM, INFO, github_: mmd, time=0.2214195728302002\n",
      "09/23 10:03:22 AM, INFO, github_: ****** eval end ******\n",
      "09/23 10:03:24 AM, INFO, github_: epoch[101/300], d_loss=1.063, g_loss=1.005, real_loss=0.5239, fake_loss=0.5392, acc=0.7559, , time=2.002\n",
      "09/23 10:03:27 AM, INFO, github_: epoch[102/300], d_loss=1.042, g_loss=1.036, real_loss=0.5105, fake_loss=0.5312, acc=0.7553, , time=2.254\n",
      "09/23 10:03:29 AM, INFO, github_: epoch[103/300], d_loss=1.041, g_loss=1.008, real_loss=0.5105, fake_loss=0.5302, acc=0.7841, , time=1.978\n",
      "09/23 10:03:31 AM, INFO, github_: epoch[104/300], d_loss=1.04, g_loss=1.038, real_loss=0.5133, fake_loss=0.5268, acc=0.7599, , time=2.355\n",
      "09/23 10:03:33 AM, INFO, github_: epoch[105/300], d_loss=0.9961, g_loss=1.087, real_loss=0.5214, fake_loss=0.4747, acc=0.8058, , time=2.014\n",
      "09/23 10:03:36 AM, INFO, github_: epoch[106/300], d_loss=1.037, g_loss=1.109, real_loss=0.5231, fake_loss=0.5142, acc=0.7411, , time=2.376\n",
      "09/23 10:03:39 AM, INFO, github_: epoch[107/300], d_loss=1.043, g_loss=1.051, real_loss=0.4876, fake_loss=0.5559, acc=0.751, , time=2.229\n",
      "09/23 10:03:41 AM, INFO, github_: epoch[108/300], d_loss=1.023, g_loss=1.03, real_loss=0.4949, fake_loss=0.5284, acc=0.7817, , time=2.325\n",
      "09/23 10:03:43 AM, INFO, github_: epoch[109/300], d_loss=1.038, g_loss=0.9864, real_loss=0.4952, fake_loss=0.5427, acc=0.7774, , time=2.328\n",
      "09/23 10:03:45 AM, INFO, github_: epoch[110/300], d_loss=1.066, g_loss=1.069, real_loss=0.5359, fake_loss=0.5303, acc=0.753, , time=2.162\n",
      "09/23 10:03:48 AM, INFO, github_: epoch[111/300], d_loss=1.051, g_loss=0.9997, real_loss=0.5047, fake_loss=0.5461, acc=0.779, , time=2.142\n",
      "09/23 10:03:50 AM, INFO, github_: epoch[112/300], d_loss=1.029, g_loss=0.9718, real_loss=0.4808, fake_loss=0.5482, acc=0.7865, , time=2.235\n",
      "09/23 10:03:52 AM, INFO, github_: epoch[113/300], d_loss=1.048, g_loss=1.023, real_loss=0.5063, fake_loss=0.5413, acc=0.7415, , time=2.433\n",
      "09/23 10:03:54 AM, INFO, github_: epoch[114/300], d_loss=1.042, g_loss=1.026, real_loss=0.5125, fake_loss=0.5296, acc=0.7693, , time=2.279\n",
      "09/23 10:03:57 AM, INFO, github_: epoch[115/300], d_loss=1.04, g_loss=1.079, real_loss=0.5371, fake_loss=0.5026, acc=0.7675, , time=2.199\n",
      "09/23 10:03:59 AM, INFO, github_: epoch[116/300], d_loss=1.046, g_loss=0.9827, real_loss=0.4914, fake_loss=0.5546, acc=0.7756, , time=2.151\n",
      "09/23 10:04:01 AM, INFO, github_: epoch[117/300], d_loss=1.005, g_loss=1.073, real_loss=0.5158, fake_loss=0.489, acc=0.7918, , time=2.146\n",
      "09/23 10:04:03 AM, INFO, github_: epoch[118/300], d_loss=0.9994, g_loss=1.033, real_loss=0.4795, fake_loss=0.52, acc=0.808, , time=2.041\n",
      "09/23 10:04:05 AM, INFO, github_: epoch[119/300], d_loss=1.0, g_loss=1.051, real_loss=0.5078, fake_loss=0.4923, acc=0.8095, , time=1.665\n",
      "09/23 10:04:07 AM, INFO, github_: epoch[120/300], d_loss=1.059, g_loss=1.051, real_loss=0.5092, fake_loss=0.5496, acc=0.7427, , time=1.991\n",
      "09/23 10:04:10 AM, INFO, github_: epoch[121/300], d_loss=1.033, g_loss=1.012, real_loss=0.4978, fake_loss=0.5356, acc=0.7658, , time=2.029\n",
      "09/23 10:04:11 AM, INFO, github_: epoch[122/300], d_loss=1.018, g_loss=1.055, real_loss=0.5298, fake_loss=0.4877, acc=0.7948, , time=1.727\n",
      "09/23 10:04:13 AM, INFO, github_: epoch[123/300], d_loss=1.114, g_loss=1.095, real_loss=0.5704, fake_loss=0.5432, acc=0.71, , time=1.893\n",
      "09/23 10:04:15 AM, INFO, github_: epoch[124/300], d_loss=1.135, g_loss=1.1, real_loss=0.5938, fake_loss=0.5414, acc=0.6794, , time=2.135\n",
      "09/23 10:04:18 AM, INFO, github_: epoch[125/300], d_loss=1.038, g_loss=1.027, real_loss=0.5106, fake_loss=0.5274, acc=0.7632, , time=2.317\n",
      "09/23 10:04:20 AM, INFO, github_: epoch[126/300], d_loss=1.012, g_loss=1.033, real_loss=0.5135, fake_loss=0.4989, acc=0.8127, , time=1.865\n",
      "09/23 10:04:21 AM, INFO, github_: epoch[127/300], d_loss=0.9973, g_loss=1.031, real_loss=0.4966, fake_loss=0.5007, acc=0.8123, , time=1.772\n",
      "09/23 10:04:23 AM, INFO, github_: epoch[128/300], d_loss=1.023, g_loss=0.9906, real_loss=0.4866, fake_loss=0.5368, acc=0.7902, , time=1.653\n",
      "09/23 10:04:25 AM, INFO, github_: epoch[129/300], d_loss=1.043, g_loss=0.938, real_loss=0.4725, fake_loss=0.571, acc=0.7831, , time=1.732\n",
      "09/23 10:04:27 AM, INFO, github_: epoch[130/300], d_loss=0.9998, g_loss=0.9958, real_loss=0.4705, fake_loss=0.5294, acc=0.8131, , time=2.38\n",
      "09/23 10:04:30 AM, INFO, github_: epoch[131/300], d_loss=1.009, g_loss=0.9939, real_loss=0.4838, fake_loss=0.5251, acc=0.8157, , time=2.716\n",
      "09/23 10:04:32 AM, INFO, github_: epoch[132/300], d_loss=1.018, g_loss=1.038, real_loss=0.5183, fake_loss=0.5, acc=0.822, , time=2.072\n",
      "09/23 10:04:34 AM, INFO, github_: epoch[133/300], d_loss=1.047, g_loss=1.03, real_loss=0.5117, fake_loss=0.5357, acc=0.7399, , time=2.547\n",
      "09/23 10:04:37 AM, INFO, github_: epoch[134/300], d_loss=1.092, g_loss=1.009, real_loss=0.5304, fake_loss=0.5619, acc=0.7325, , time=2.274\n",
      "09/23 10:04:39 AM, INFO, github_: epoch[135/300], d_loss=1.012, g_loss=1.067, real_loss=0.5055, fake_loss=0.5062, acc=0.7784, , time=2.31\n",
      "09/23 10:04:41 AM, INFO, github_: epoch[136/300], d_loss=1.021, g_loss=1.03, real_loss=0.5068, fake_loss=0.5147, acc=0.7967, , time=1.796\n",
      "09/23 10:04:44 AM, INFO, github_: epoch[137/300], d_loss=1.066, g_loss=1.149, real_loss=0.5463, fake_loss=0.5197, acc=0.7265, , time=2.528\n",
      "09/23 10:04:46 AM, INFO, github_: epoch[138/300], d_loss=1.025, g_loss=1.115, real_loss=0.535, fake_loss=0.4903, acc=0.7723, , time=2.06\n",
      "09/23 10:04:48 AM, INFO, github_: epoch[139/300], d_loss=1.069, g_loss=0.9905, real_loss=0.5126, fake_loss=0.5559, acc=0.7545, , time=2.15\n",
      "09/23 10:04:50 AM, INFO, github_: epoch[140/300], d_loss=1.026, g_loss=1.002, real_loss=0.4955, fake_loss=0.5307, acc=0.8001, , time=2.193\n",
      "09/23 10:04:53 AM, INFO, github_: epoch[141/300], d_loss=1.033, g_loss=1.054, real_loss=0.5086, fake_loss=0.5247, acc=0.7435, , time=2.417\n",
      "09/23 10:04:55 AM, INFO, github_: epoch[142/300], d_loss=1.057, g_loss=1.06, real_loss=0.4813, fake_loss=0.576, acc=0.7261, , time=2.419\n",
      "09/23 10:04:58 AM, INFO, github_: epoch[143/300], d_loss=1.07, g_loss=1.062, real_loss=0.5239, fake_loss=0.5465, acc=0.7362, , time=2.26\n",
      "09/23 10:05:00 AM, INFO, github_: epoch[144/300], d_loss=1.034, g_loss=1.044, real_loss=0.5018, fake_loss=0.5317, acc=0.7847, , time=2.351\n",
      "09/23 10:05:02 AM, INFO, github_: epoch[145/300], d_loss=1.033, g_loss=0.9683, real_loss=0.4603, fake_loss=0.5731, acc=0.7829, , time=2.142\n",
      "09/23 10:05:04 AM, INFO, github_: epoch[146/300], d_loss=1.028, g_loss=1.013, real_loss=0.4992, fake_loss=0.5293, acc=0.7902, , time=2.071\n",
      "09/23 10:05:06 AM, INFO, github_: epoch[147/300], d_loss=1.006, g_loss=1.055, real_loss=0.5216, fake_loss=0.4844, acc=0.7983, , time=2.226\n",
      "09/23 10:05:08 AM, INFO, github_: epoch[148/300], d_loss=1.013, g_loss=1.026, real_loss=0.5026, fake_loss=0.51, acc=0.7946, , time=2.061\n",
      "09/23 10:05:11 AM, INFO, github_: epoch[149/300], d_loss=1.053, g_loss=1.004, real_loss=0.5081, fake_loss=0.5446, acc=0.762, , time=2.107\n",
      "09/23 10:05:12 AM, INFO, github_: epoch[150/300], d_loss=1.032, g_loss=1.034, real_loss=0.504, fake_loss=0.5277, acc=0.7697, , time=1.883\n",
      "09/23 10:05:15 AM, INFO, github_: epoch[151/300], d_loss=0.9969, g_loss=0.998, real_loss=0.4675, fake_loss=0.5294, acc=0.8044, , time=1.691\n",
      "09/23 10:05:17 AM, INFO, github_: epoch[152/300], d_loss=1.011, g_loss=1.06, real_loss=0.5022, fake_loss=0.5093, acc=0.7981, , time=2.012\n",
      "09/23 10:05:19 AM, INFO, github_: epoch[153/300], d_loss=1.01, g_loss=1.063, real_loss=0.4979, fake_loss=0.5124, acc=0.7766, , time=1.981\n",
      "09/23 10:05:21 AM, INFO, github_: epoch[154/300], d_loss=1.024, g_loss=1.065, real_loss=0.503, fake_loss=0.5214, acc=0.7634, , time=2.195\n",
      "09/23 10:05:23 AM, INFO, github_: epoch[155/300], d_loss=1.047, g_loss=0.9937, real_loss=0.497, fake_loss=0.5497, acc=0.7786, , time=2.261\n",
      "09/23 10:05:25 AM, INFO, github_: epoch[156/300], d_loss=1.053, g_loss=1.036, real_loss=0.5343, fake_loss=0.5185, acc=0.7646, , time=2.154\n",
      "09/23 10:05:28 AM, INFO, github_: epoch[157/300], d_loss=1.081, g_loss=1.032, real_loss=0.5015, fake_loss=0.5796, acc=0.724, , time=2.365\n",
      "09/23 10:05:30 AM, INFO, github_: epoch[158/300], d_loss=1.048, g_loss=1.134, real_loss=0.5388, fake_loss=0.5092, acc=0.7447, , time=2.144\n",
      "09/23 10:05:32 AM, INFO, github_: epoch[159/300], d_loss=1.045, g_loss=1.047, real_loss=0.5221, fake_loss=0.5228, acc=0.7683, , time=2.185\n",
      "09/23 10:05:34 AM, INFO, github_: epoch[160/300], d_loss=1.054, g_loss=1.049, real_loss=0.5107, fake_loss=0.5431, acc=0.7642, , time=2.402\n",
      "09/23 10:05:36 AM, INFO, github_: epoch[161/300], d_loss=1.006, g_loss=1.041, real_loss=0.4778, fake_loss=0.5281, acc=0.7924, , time=1.767\n",
      "09/23 10:05:38 AM, INFO, github_: epoch[162/300], d_loss=1.017, g_loss=1.123, real_loss=0.5428, fake_loss=0.4743, acc=0.7715, , time=1.681\n",
      "09/23 10:05:40 AM, INFO, github_: epoch[163/300], d_loss=1.037, g_loss=1.162, real_loss=0.5416, fake_loss=0.4957, acc=0.7311, , time=1.994\n",
      "09/23 10:05:42 AM, INFO, github_: epoch[164/300], d_loss=1.027, g_loss=1.107, real_loss=0.5342, fake_loss=0.4932, acc=0.7541, , time=2.086\n",
      "09/23 10:05:44 AM, INFO, github_: epoch[165/300], d_loss=1.046, g_loss=1.126, real_loss=0.5473, fake_loss=0.499, acc=0.7394, , time=1.947\n",
      "09/23 10:05:46 AM, INFO, github_: epoch[166/300], d_loss=1.017, g_loss=0.9881, real_loss=0.4638, fake_loss=0.5531, acc=0.7845, , time=1.744\n",
      "09/23 10:05:48 AM, INFO, github_: epoch[167/300], d_loss=1.016, g_loss=1.08, real_loss=0.4924, fake_loss=0.5238, acc=0.7788, , time=1.934\n",
      "09/23 10:05:50 AM, INFO, github_: epoch[168/300], d_loss=1.02, g_loss=0.9572, real_loss=0.4496, fake_loss=0.5701, acc=0.7709, , time=2.004\n",
      "09/23 10:05:52 AM, INFO, github_: epoch[169/300], d_loss=0.9969, g_loss=1.053, real_loss=0.4985, fake_loss=0.4984, acc=0.8005, , time=2.009\n",
      "09/23 10:05:54 AM, INFO, github_: epoch[170/300], d_loss=0.9987, g_loss=1.015, real_loss=0.4699, fake_loss=0.5288, acc=0.8091, , time=2.047\n",
      "09/23 10:05:57 AM, INFO, github_: epoch[171/300], d_loss=1.035, g_loss=1.073, real_loss=0.5024, fake_loss=0.5325, acc=0.7516, , time=2.371\n",
      "09/23 10:05:59 AM, INFO, github_: epoch[172/300], d_loss=1.038, g_loss=1.091, real_loss=0.5208, fake_loss=0.5172, acc=0.7555, , time=2.454\n",
      "09/23 10:06:01 AM, INFO, github_: epoch[173/300], d_loss=1.047, g_loss=1.026, real_loss=0.5205, fake_loss=0.5267, acc=0.7689, , time=2.106\n",
      "09/23 10:06:03 AM, INFO, github_: epoch[174/300], d_loss=0.9995, g_loss=1.046, real_loss=0.4791, fake_loss=0.5204, acc=0.7932, , time=2.164\n",
      "09/23 10:06:05 AM, INFO, github_: epoch[175/300], d_loss=1.007, g_loss=1.074, real_loss=0.5119, fake_loss=0.4947, acc=0.8103, , time=1.523\n",
      "09/23 10:06:07 AM, INFO, github_: epoch[176/300], d_loss=1.019, g_loss=1.048, real_loss=0.4881, fake_loss=0.5306, acc=0.7843, , time=1.733\n",
      "09/23 10:06:09 AM, INFO, github_: epoch[177/300], d_loss=1.061, g_loss=1.098, real_loss=0.5284, fake_loss=0.5322, acc=0.7368, , time=1.947\n",
      "09/23 10:06:10 AM, INFO, github_: epoch[178/300], d_loss=1.028, g_loss=1.081, real_loss=0.5147, fake_loss=0.5131, acc=0.7752, , time=1.82\n",
      "09/23 10:06:12 AM, INFO, github_: epoch[179/300], d_loss=1.029, g_loss=1.025, real_loss=0.4829, fake_loss=0.5456, acc=0.7652, , time=2.032\n",
      "09/23 10:06:15 AM, INFO, github_: epoch[180/300], d_loss=1.056, g_loss=1.037, real_loss=0.5056, fake_loss=0.5502, acc=0.7537, , time=2.102\n",
      "09/23 10:06:17 AM, INFO, github_: epoch[181/300], d_loss=1.028, g_loss=1.027, real_loss=0.4693, fake_loss=0.5591, acc=0.7817, , time=1.924\n",
      "09/23 10:06:19 AM, INFO, github_: epoch[182/300], d_loss=1.037, g_loss=1.015, real_loss=0.5019, fake_loss=0.5352, acc=0.7508, , time=1.962\n",
      "09/23 10:06:21 AM, INFO, github_: epoch[183/300], d_loss=1.015, g_loss=1.012, real_loss=0.4698, fake_loss=0.5448, acc=0.7975, , time=1.854\n",
      "09/23 10:06:23 AM, INFO, github_: epoch[184/300], d_loss=1.037, g_loss=1.011, real_loss=0.4809, fake_loss=0.5558, acc=0.7512, , time=2.076\n",
      "09/23 10:06:25 AM, INFO, github_: epoch[185/300], d_loss=0.9811, g_loss=1.061, real_loss=0.4734, fake_loss=0.5076, acc=0.805, , time=1.99\n",
      "09/23 10:06:27 AM, INFO, github_: epoch[186/300], d_loss=0.9357, g_loss=1.147, real_loss=0.4706, fake_loss=0.4651, acc=0.8231, , time=1.961\n",
      "09/23 10:06:29 AM, INFO, github_: epoch[187/300], d_loss=1.019, g_loss=1.057, real_loss=0.4772, fake_loss=0.5423, acc=0.7646, , time=2.236\n",
      "09/23 10:06:32 AM, INFO, github_: epoch[188/300], d_loss=1.061, g_loss=1.058, real_loss=0.4992, fake_loss=0.5621, acc=0.7289, , time=2.345\n",
      "09/23 10:06:34 AM, INFO, github_: epoch[189/300], d_loss=1.023, g_loss=1.017, real_loss=0.4848, fake_loss=0.5377, acc=0.7794, , time=1.983\n",
      "09/23 10:06:36 AM, INFO, github_: epoch[190/300], d_loss=0.9993, g_loss=0.9908, real_loss=0.4437, fake_loss=0.5556, acc=0.7837, , time=2.014\n",
      "09/23 10:06:37 AM, INFO, github_: epoch[191/300], d_loss=1.033, g_loss=1.079, real_loss=0.5172, fake_loss=0.5155, acc=0.7717, , time=1.802\n",
      "09/23 10:06:39 AM, INFO, github_: epoch[192/300], d_loss=1.029, g_loss=1.074, real_loss=0.5034, fake_loss=0.5254, acc=0.7516, , time=1.97\n",
      "09/23 10:06:41 AM, INFO, github_: epoch[193/300], d_loss=1.028, g_loss=1.079, real_loss=0.5054, fake_loss=0.5229, acc=0.761, , time=1.809\n",
      "09/23 10:06:43 AM, INFO, github_: epoch[194/300], d_loss=1.031, g_loss=1.087, real_loss=0.4967, fake_loss=0.5338, acc=0.7715, , time=2.03\n",
      "09/23 10:06:45 AM, INFO, github_: epoch[195/300], d_loss=1.025, g_loss=1.13, real_loss=0.5072, fake_loss=0.5176, acc=0.7689, , time=2.123\n",
      "09/23 10:06:48 AM, INFO, github_: epoch[196/300], d_loss=1.018, g_loss=1.073, real_loss=0.5042, fake_loss=0.5135, acc=0.7965, , time=2.386\n",
      "09/23 10:06:51 AM, INFO, github_: epoch[197/300], d_loss=0.9908, g_loss=1.001, real_loss=0.4686, fake_loss=0.5222, acc=0.8249, , time=2.103\n",
      "09/23 10:06:53 AM, INFO, github_: epoch[198/300], d_loss=1.023, g_loss=1.083, real_loss=0.5248, fake_loss=0.4984, acc=0.778, , time=2.218\n",
      "09/23 10:06:55 AM, INFO, github_: epoch[199/300], d_loss=1.092, g_loss=1.027, real_loss=0.5189, fake_loss=0.5732, acc=0.7457, , time=2.428\n",
      "09/23 10:06:58 AM, INFO, github_: epoch[200/300], d_loss=1.03, g_loss=1.049, real_loss=0.505, fake_loss=0.5248, acc=0.7884, , time=2.274\n",
      "09/23 10:06:58 AM, INFO, github_: ****** eval start ******\n",
      "09/23 10:06:59 AM, INFO, github_: tsne, time=1.2822883129119873\n",
      "09/23 10:06:59 AM, INFO, github_: nnd, time=0.02918553352355957\n",
      "09/23 10:06:59 AM, INFO, github_: mmd, time=0.323284387588501\n",
      "09/23 10:06:59 AM, INFO, github_: ****** eval end ******\n",
      "09/23 10:07:02 AM, INFO, github_: epoch[201/300], d_loss=0.9986, g_loss=1.004, real_loss=0.4596, fake_loss=0.539, acc=0.7999, , time=2.303\n",
      "09/23 10:07:04 AM, INFO, github_: epoch[202/300], d_loss=1.009, g_loss=1.099, real_loss=0.5011, fake_loss=0.5078, acc=0.7652, , time=2.597\n",
      "09/23 10:07:07 AM, INFO, github_: epoch[203/300], d_loss=1.03, g_loss=1.003, real_loss=0.4859, fake_loss=0.5439, acc=0.7656, , time=2.373\n",
      "09/23 10:07:09 AM, INFO, github_: epoch[204/300], d_loss=0.9972, g_loss=1.097, real_loss=0.5063, fake_loss=0.4909, acc=0.7898, , time=2.137\n",
      "09/23 10:07:11 AM, INFO, github_: epoch[205/300], d_loss=0.9966, g_loss=1.057, real_loss=0.4927, fake_loss=0.5039, acc=0.8017, , time=2.417\n",
      "09/23 10:07:12 AM, INFO, github_: epoch[206/300], d_loss=1.002, g_loss=1.063, real_loss=0.4955, fake_loss=0.507, acc=0.7776, , time=1.122\n",
      "09/23 10:07:13 AM, INFO, github_: epoch[207/300], d_loss=0.9773, g_loss=1.036, real_loss=0.4673, fake_loss=0.51, acc=0.8044, , time=1.232\n",
      "09/23 10:07:15 AM, INFO, github_: epoch[208/300], d_loss=1.016, g_loss=1.108, real_loss=0.5225, fake_loss=0.4932, acc=0.793, , time=1.305\n",
      "09/23 10:07:16 AM, INFO, github_: epoch[209/300], d_loss=1.064, g_loss=1.09, real_loss=0.5265, fake_loss=0.5375, acc=0.719, , time=1.472\n",
      "09/23 10:07:18 AM, INFO, github_: epoch[210/300], d_loss=1.009, g_loss=1.069, real_loss=0.5004, fake_loss=0.509, acc=0.7904, , time=1.324\n",
      "09/23 10:07:19 AM, INFO, github_: epoch[211/300], d_loss=0.9722, g_loss=1.132, real_loss=0.5083, fake_loss=0.464, acc=0.8231, , time=1.182\n",
      "09/23 10:07:21 AM, INFO, github_: epoch[212/300], d_loss=0.9806, g_loss=1.107, real_loss=0.4983, fake_loss=0.4824, acc=0.8034, , time=1.328\n",
      "09/23 10:07:22 AM, INFO, github_: epoch[213/300], d_loss=1.013, g_loss=1.087, real_loss=0.5097, fake_loss=0.5032, acc=0.791, , time=1.271\n",
      "09/23 10:07:23 AM, INFO, github_: epoch[214/300], d_loss=0.9978, g_loss=1.066, real_loss=0.4892, fake_loss=0.5087, acc=0.7999, , time=1.243\n",
      "09/23 10:07:24 AM, INFO, github_: epoch[215/300], d_loss=1.048, g_loss=1.067, real_loss=0.5224, fake_loss=0.5259, acc=0.7946, , time=1.325\n",
      "09/23 10:07:26 AM, INFO, github_: epoch[216/300], d_loss=1.04, g_loss=1.043, real_loss=0.4947, fake_loss=0.5448, acc=0.7608, , time=1.421\n",
      "09/23 10:07:27 AM, INFO, github_: epoch[217/300], d_loss=0.9921, g_loss=1.032, real_loss=0.4804, fake_loss=0.5117, acc=0.8155, , time=1.418\n",
      "09/23 10:07:29 AM, INFO, github_: epoch[218/300], d_loss=1.063, g_loss=0.9642, real_loss=0.4703, fake_loss=0.5928, acc=0.7325, , time=1.719\n",
      "09/23 10:07:31 AM, INFO, github_: epoch[219/300], d_loss=1.043, g_loss=1.007, real_loss=0.4987, fake_loss=0.5445, acc=0.7786, , time=1.512\n",
      "09/23 10:07:32 AM, INFO, github_: epoch[220/300], d_loss=1.023, g_loss=1.041, real_loss=0.4857, fake_loss=0.5372, acc=0.7628, , time=1.464\n",
      "09/23 10:07:33 AM, INFO, github_: epoch[221/300], d_loss=1.001, g_loss=1.069, real_loss=0.4863, fake_loss=0.5142, acc=0.7831, , time=1.413\n",
      "09/23 10:07:35 AM, INFO, github_: epoch[222/300], d_loss=1.001, g_loss=1.035, real_loss=0.4833, fake_loss=0.5175, acc=0.7969, , time=1.189\n",
      "09/23 10:07:36 AM, INFO, github_: epoch[223/300], d_loss=0.9825, g_loss=0.9521, real_loss=0.42, fake_loss=0.5625, acc=0.8026, , time=1.219\n",
      "09/23 10:07:37 AM, INFO, github_: epoch[224/300], d_loss=0.9945, g_loss=1.054, real_loss=0.469, fake_loss=0.5255, acc=0.7806, , time=1.301\n",
      "09/23 10:07:38 AM, INFO, github_: epoch[225/300], d_loss=0.9712, g_loss=1.152, real_loss=0.5057, fake_loss=0.4655, acc=0.791, , time=1.258\n",
      "09/23 10:07:40 AM, INFO, github_: epoch[226/300], d_loss=1.019, g_loss=1.039, real_loss=0.4804, fake_loss=0.5384, acc=0.779, , time=1.159\n",
      "09/23 10:07:41 AM, INFO, github_: epoch[227/300], d_loss=1.031, g_loss=1.1, real_loss=0.5299, fake_loss=0.5006, acc=0.7731, , time=1.601\n",
      "09/23 10:07:43 AM, INFO, github_: epoch[228/300], d_loss=0.9777, g_loss=1.063, real_loss=0.4775, fake_loss=0.5002, acc=0.8174, , time=1.218\n",
      "09/23 10:07:44 AM, INFO, github_: epoch[229/300], d_loss=1.017, g_loss=1.124, real_loss=0.5384, fake_loss=0.4791, acc=0.7912, , time=1.356\n",
      "09/23 10:07:45 AM, INFO, github_: epoch[230/300], d_loss=1.006, g_loss=1.08, real_loss=0.4865, fake_loss=0.5199, acc=0.7804, , time=1.36\n",
      "09/23 10:07:47 AM, INFO, github_: epoch[231/300], d_loss=1.005, g_loss=1.045, real_loss=0.488, fake_loss=0.5172, acc=0.8013, , time=1.496\n",
      "09/23 10:07:49 AM, INFO, github_: epoch[232/300], d_loss=0.9924, g_loss=1.08, real_loss=0.4919, fake_loss=0.5005, acc=0.803, , time=1.823\n",
      "09/23 10:07:50 AM, INFO, github_: epoch[233/300], d_loss=1.008, g_loss=1.033, real_loss=0.4829, fake_loss=0.5248, acc=0.7855, , time=1.677\n",
      "09/23 10:07:52 AM, INFO, github_: epoch[234/300], d_loss=0.9921, g_loss=1.097, real_loss=0.4975, fake_loss=0.4946, acc=0.7922, , time=1.535\n",
      "09/23 10:07:53 AM, INFO, github_: epoch[235/300], d_loss=0.9884, g_loss=0.9981, real_loss=0.4525, fake_loss=0.5359, acc=0.8153, , time=1.285\n",
      "09/23 10:07:55 AM, INFO, github_: epoch[236/300], d_loss=1.003, g_loss=1.093, real_loss=0.485, fake_loss=0.5182, acc=0.7896, , time=1.329\n",
      "09/23 10:07:56 AM, INFO, github_: epoch[237/300], d_loss=0.9989, g_loss=1.108, real_loss=0.5077, fake_loss=0.4912, acc=0.7863, , time=1.298\n",
      "09/23 10:07:57 AM, INFO, github_: epoch[238/300], d_loss=0.9969, g_loss=1.04, real_loss=0.482, fake_loss=0.5149, acc=0.8099, , time=1.288\n",
      "09/23 10:07:58 AM, INFO, github_: epoch[239/300], d_loss=0.9848, g_loss=1.032, real_loss=0.4681, fake_loss=0.5167, acc=0.8101, , time=1.125\n",
      "09/23 10:07:59 AM, INFO, github_: epoch[240/300], d_loss=1.036, g_loss=1.019, real_loss=0.4985, fake_loss=0.5371, acc=0.7642, , time=1.203\n",
      "09/23 10:08:01 AM, INFO, github_: epoch[241/300], d_loss=1.013, g_loss=1.069, real_loss=0.5029, fake_loss=0.5103, acc=0.8028, , time=1.163\n",
      "09/23 10:08:02 AM, INFO, github_: epoch[242/300], d_loss=1.006, g_loss=1.135, real_loss=0.5156, fake_loss=0.4902, acc=0.767, , time=1.41\n",
      "09/23 10:08:04 AM, INFO, github_: epoch[243/300], d_loss=1.026, g_loss=1.079, real_loss=0.4986, fake_loss=0.5277, acc=0.7766, , time=1.326\n",
      "09/23 10:08:05 AM, INFO, github_: epoch[244/300], d_loss=1.012, g_loss=1.007, real_loss=0.4673, fake_loss=0.5444, acc=0.7703, , time=1.202\n",
      "09/23 10:08:06 AM, INFO, github_: epoch[245/300], d_loss=1.03, g_loss=1.055, real_loss=0.5066, fake_loss=0.5234, acc=0.7579, , time=1.256\n",
      "09/23 10:08:07 AM, INFO, github_: epoch[246/300], d_loss=1.019, g_loss=1.017, real_loss=0.4523, fake_loss=0.5665, acc=0.752, , time=1.244\n",
      "09/23 10:08:09 AM, INFO, github_: epoch[247/300], d_loss=0.9811, g_loss=1.07, real_loss=0.4745, fake_loss=0.5066, acc=0.7971, , time=1.142\n",
      "09/23 10:08:10 AM, INFO, github_: epoch[248/300], d_loss=0.9893, g_loss=1.084, real_loss=0.482, fake_loss=0.5073, acc=0.7993, , time=1.241\n",
      "09/23 10:08:11 AM, INFO, github_: epoch[249/300], d_loss=0.9714, g_loss=1.085, real_loss=0.4828, fake_loss=0.4886, acc=0.8125, , time=1.362\n",
      "09/23 10:08:13 AM, INFO, github_: epoch[250/300], d_loss=0.9975, g_loss=0.9919, real_loss=0.4371, fake_loss=0.5603, acc=0.7896, , time=1.378\n",
      "09/23 10:08:14 AM, INFO, github_: epoch[251/300], d_loss=0.9849, g_loss=1.065, real_loss=0.4693, fake_loss=0.5156, acc=0.7934, , time=1.337\n",
      "09/23 10:08:15 AM, INFO, github_: epoch[252/300], d_loss=0.9672, g_loss=1.056, real_loss=0.4342, fake_loss=0.5329, acc=0.793, , time=1.227\n",
      "09/23 10:08:16 AM, INFO, github_: epoch[253/300], d_loss=1.025, g_loss=1.088, real_loss=0.5124, fake_loss=0.5126, acc=0.7944, , time=1.249\n",
      "09/23 10:08:18 AM, INFO, github_: epoch[254/300], d_loss=1.019, g_loss=0.9472, real_loss=0.4466, fake_loss=0.5722, acc=0.7875, , time=1.226\n",
      "09/23 10:08:19 AM, INFO, github_: epoch[255/300], d_loss=1.014, g_loss=1.05, real_loss=0.4909, fake_loss=0.5228, acc=0.7908, , time=1.31\n",
      "09/23 10:08:21 AM, INFO, github_: epoch[256/300], d_loss=0.9813, g_loss=1.122, real_loss=0.4815, fake_loss=0.4998, acc=0.7853, , time=1.424\n",
      "09/23 10:08:22 AM, INFO, github_: epoch[257/300], d_loss=1.073, g_loss=1.101, real_loss=0.5109, fake_loss=0.5626, acc=0.708, , time=1.494\n",
      "09/23 10:08:24 AM, INFO, github_: epoch[258/300], d_loss=0.9911, g_loss=1.133, real_loss=0.4873, fake_loss=0.5038, acc=0.7719, , time=1.737\n",
      "09/23 10:08:26 AM, INFO, github_: epoch[259/300], d_loss=0.9614, g_loss=1.068, real_loss=0.4602, fake_loss=0.5012, acc=0.8097, , time=1.919\n",
      "09/23 10:08:28 AM, INFO, github_: epoch[260/300], d_loss=0.9813, g_loss=1.094, real_loss=0.4902, fake_loss=0.4911, acc=0.8105, , time=1.907\n",
      "09/23 10:08:30 AM, INFO, github_: epoch[261/300], d_loss=0.9614, g_loss=1.139, real_loss=0.4782, fake_loss=0.4832, acc=0.7888, , time=2.167\n",
      "09/23 10:08:32 AM, INFO, github_: epoch[262/300], d_loss=0.978, g_loss=1.107, real_loss=0.5057, fake_loss=0.4722, acc=0.8139, , time=2.1\n",
      "09/23 10:08:34 AM, INFO, github_: epoch[263/300], d_loss=0.9964, g_loss=1.024, real_loss=0.4734, fake_loss=0.523, acc=0.8145, , time=1.698\n",
      "09/23 10:08:35 AM, INFO, github_: epoch[264/300], d_loss=0.9593, g_loss=1.052, real_loss=0.4555, fake_loss=0.5038, acc=0.8192, , time=1.586\n",
      "09/23 10:08:37 AM, INFO, github_: epoch[265/300], d_loss=0.9056, g_loss=1.205, real_loss=0.4656, fake_loss=0.44, acc=0.8423, , time=1.665\n",
      "09/23 10:08:41 AM, INFO, github_: epoch[266/300], d_loss=0.9083, g_loss=1.207, real_loss=0.4412, fake_loss=0.4671, acc=0.8135, , time=3.401\n",
      "09/23 10:08:42 AM, INFO, github_: epoch[267/300], d_loss=1.062, g_loss=1.134, real_loss=0.5562, fake_loss=0.5062, acc=0.7553, , time=1.132\n",
      "09/23 10:08:43 AM, INFO, github_: epoch[268/300], d_loss=1.014, g_loss=1.073, real_loss=0.4869, fake_loss=0.5271, acc=0.7744, , time=1.686\n",
      "09/23 10:08:47 AM, INFO, github_: epoch[269/300], d_loss=0.9997, g_loss=1.083, real_loss=0.5042, fake_loss=0.4954, acc=0.804, , time=3.683\n",
      "09/23 10:08:49 AM, INFO, github_: epoch[270/300], d_loss=1.037, g_loss=1.151, real_loss=0.5409, fake_loss=0.4959, acc=0.775, , time=2.055\n",
      "09/23 10:08:53 AM, INFO, github_: epoch[271/300], d_loss=1.056, g_loss=1.029, real_loss=0.5033, fake_loss=0.5527, acc=0.7762, , time=2.26\n",
      "09/23 10:08:55 AM, INFO, github_: epoch[272/300], d_loss=1.055, g_loss=1.116, real_loss=0.5256, fake_loss=0.5295, acc=0.7315, , time=1.953\n",
      "09/23 10:08:56 AM, INFO, github_: epoch[273/300], d_loss=0.9919, g_loss=1.09, real_loss=0.4725, fake_loss=0.5194, acc=0.7786, , time=1.808\n",
      "09/23 10:08:58 AM, INFO, github_: epoch[274/300], d_loss=1.007, g_loss=1.074, real_loss=0.514, fake_loss=0.4933, acc=0.8048, , time=1.678\n",
      "09/23 10:09:00 AM, INFO, github_: epoch[275/300], d_loss=1.02, g_loss=1.056, real_loss=0.4869, fake_loss=0.5331, acc=0.7804, , time=1.974\n",
      "09/23 10:09:02 AM, INFO, github_: epoch[276/300], d_loss=0.9884, g_loss=1.051, real_loss=0.4505, fake_loss=0.538, acc=0.7764, , time=2.33\n",
      "09/23 10:09:05 AM, INFO, github_: epoch[277/300], d_loss=1.003, g_loss=1.107, real_loss=0.5021, fake_loss=0.5004, acc=0.7851, , time=2.065\n",
      "09/23 10:09:07 AM, INFO, github_: epoch[278/300], d_loss=0.9736, g_loss=1.109, real_loss=0.462, fake_loss=0.5116, acc=0.7735, , time=2.375\n",
      "09/23 10:09:10 AM, INFO, github_: epoch[279/300], d_loss=1.065, g_loss=1.085, real_loss=0.5107, fake_loss=0.5544, acc=0.7522, , time=2.6\n",
      "09/23 10:09:11 AM, INFO, github_: epoch[280/300], d_loss=0.9777, g_loss=1.062, real_loss=0.4635, fake_loss=0.5143, acc=0.7995, , time=1.712\n",
      "09/23 10:09:13 AM, INFO, github_: epoch[281/300], d_loss=0.9606, g_loss=1.132, real_loss=0.486, fake_loss=0.4747, acc=0.7948, , time=2.011\n",
      "09/23 10:09:16 AM, INFO, github_: epoch[282/300], d_loss=0.9682, g_loss=1.142, real_loss=0.475, fake_loss=0.4932, acc=0.7981, , time=2.346\n",
      "09/23 10:09:18 AM, INFO, github_: epoch[283/300], d_loss=0.9825, g_loss=1.133, real_loss=0.5173, fake_loss=0.4652, acc=0.8015, , time=2.212\n",
      "09/23 10:09:20 AM, INFO, github_: epoch[284/300], d_loss=0.9764, g_loss=1.089, real_loss=0.4749, fake_loss=0.5015, acc=0.8115, , time=2.325\n",
      "09/23 10:09:22 AM, INFO, github_: epoch[285/300], d_loss=0.9825, g_loss=1.095, real_loss=0.4934, fake_loss=0.4892, acc=0.8046, , time=1.938\n",
      "09/23 10:09:25 AM, INFO, github_: epoch[286/300], d_loss=0.9655, g_loss=0.9803, real_loss=0.4114, fake_loss=0.5541, acc=0.8127, , time=1.854\n",
      "09/23 10:09:26 AM, INFO, github_: epoch[287/300], d_loss=0.9627, g_loss=1.071, real_loss=0.4608, fake_loss=0.5019, acc=0.7857, , time=1.842\n",
      "09/23 10:09:28 AM, INFO, github_: epoch[288/300], d_loss=0.9259, g_loss=1.189, real_loss=0.4944, fake_loss=0.4315, acc=0.8403, , time=1.754\n",
      "09/23 10:09:30 AM, INFO, github_: epoch[289/300], d_loss=0.9666, g_loss=1.071, real_loss=0.4549, fake_loss=0.5117, acc=0.7981, , time=2.293\n",
      "09/23 10:09:33 AM, INFO, github_: epoch[290/300], d_loss=0.9989, g_loss=1.091, real_loss=0.4994, fake_loss=0.4995, acc=0.7946, , time=2.314\n",
      "09/23 10:09:35 AM, INFO, github_: epoch[291/300], d_loss=0.9543, g_loss=1.128, real_loss=0.4734, fake_loss=0.4809, acc=0.8011, , time=2.131\n",
      "09/23 10:09:37 AM, INFO, github_: epoch[292/300], d_loss=0.9643, g_loss=1.1, real_loss=0.4619, fake_loss=0.5024, acc=0.807, , time=1.576\n",
      "09/23 10:09:38 AM, INFO, github_: epoch[293/300], d_loss=0.9815, g_loss=1.042, real_loss=0.4724, fake_loss=0.5091, acc=0.8115, , time=1.481\n",
      "09/23 10:09:39 AM, INFO, github_: epoch[294/300], d_loss=0.9697, g_loss=1.154, real_loss=0.5048, fake_loss=0.4649, acc=0.8235, , time=1.318\n",
      "09/23 10:09:41 AM, INFO, github_: epoch[295/300], d_loss=0.9714, g_loss=1.084, real_loss=0.4887, fake_loss=0.4827, acc=0.82, , time=1.387\n",
      "09/23 10:09:42 AM, INFO, github_: epoch[296/300], d_loss=0.9325, g_loss=1.117, real_loss=0.4569, fake_loss=0.4755, acc=0.8446, , time=1.372\n",
      "09/23 10:09:43 AM, INFO, github_: epoch[297/300], d_loss=0.9444, g_loss=1.137, real_loss=0.4561, fake_loss=0.4883, acc=0.8174, , time=1.26\n",
      "09/23 10:09:44 AM, INFO, github_: epoch[298/300], d_loss=0.9734, g_loss=1.051, real_loss=0.4717, fake_loss=0.5017, acc=0.83, , time=1.124\n",
      "09/23 10:09:46 AM, INFO, github_: epoch[299/300], d_loss=0.948, g_loss=1.085, real_loss=0.4679, fake_loss=0.4801, acc=0.8259, , time=1.161\n",
      "09/23 10:09:47 AM, INFO, github_: epoch[300/300], d_loss=0.9588, g_loss=1.077, real_loss=0.4632, fake_loss=0.4956, acc=0.8257, , time=1.257\n",
      "09/23 10:09:47 AM, INFO, github_: ****** eval start ******\n",
      "09/23 10:09:48 AM, INFO, github_: tsne, time=0.41984128952026367\n",
      "09/23 10:09:48 AM, INFO, github_: nnd, time=0.010013341903686523\n",
      "09/23 10:09:48 AM, INFO, github_: mmd, time=0.1180274486541748\n",
      "09/23 10:09:48 AM, INFO, github_: ****** eval end ******\n",
      "09/23 10:09:48 AM, INFO, github_: ****** fit end ******\n"
     ]
    }
   ],
   "source": [
    "model = TCGAN(model_cfg, evaluator)\n",
    "model.fit(x_tr_gan, x_te_gan)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_0_dense (Dense)        (None, 7424)              749824    \n",
      "_________________________________________________________________\n",
      "dense_0_norm (BatchNormaliza (None, 7424)              29696     \n",
      "_________________________________________________________________\n",
      "dense_0_relu (ReLU)          (None, 7424)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 29, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv_0_conv (Conv1DTranspose (None, 58, 128)           327808    \n",
      "_________________________________________________________________\n",
      "conv_0_norm (BatchNormalizat (None, 58, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv_0_relu (ReLU)           (None, 58, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv_1_conv (Conv1DTranspose (None, 116, 64)           81984     \n",
      "_________________________________________________________________\n",
      "conv_1_norm (BatchNormalizat (None, 116, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv_1_relu (ReLU)           (None, 116, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv_2_conv (Conv1DTranspose (None, 232, 32)           20512     \n",
      "_________________________________________________________________\n",
      "conv_2_norm (BatchNormalizat (None, 232, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv_2_relu (ReLU)           (None, 232, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv_3_conv (Conv1DTranspose (None, 463, 1)            321       \n",
      "=================================================================\n",
      "Total params: 1,211,041\n",
      "Trainable params: 1,195,745\n",
      "Non-trainable params: 15,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 7424])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generator.layers[1].weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "generated_sample_shape = input_shape\n",
    "noise_shape = (100, )\n",
    "input_layer = layers.Input(noise_shape)\n",
    "\n",
    "n_layers = 4\n",
    "kernel_size = 5\n",
    "strides = 2\n",
    "g_units_base=32\n",
    "\n",
    "steps = generated_sample_shape[0]\n",
    "layer_steps = [steps]\n",
    "for i in range(n_layers):\n",
    "    layer_steps.append(int(np.ceil(float(layer_steps[-1]) / float(strides))))\n",
    "layer_steps.reverse()\n",
    "\n",
    "conv_units = []\n",
    "if n_layers > 1:\n",
    "    conv_units.append(g_units_base)\n",
    "    for _ in range(n_layers - 2):  # minus the first and the last layers\n",
    "        conv_units.append(conv_units[-1] * 2)\n",
    "conv_units.reverse()\n",
    "# the last layer must be aligned to the number of dimensions of input.\n",
    "conv_units.append(generated_sample_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[29, 58, 116, 232, 463], [128, 64, 32, 1]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[layer_steps, conv_units]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = layers.Dense(layer_steps[0] * conv_units[0] * 2, kernel_initializer=tf.keras.initializers.truncated_normal(stddev=0.02))(input_layer)\n",
    "h = tf.keras.layers.BatchNormalization()(h)\n",
    "h = layers.ReLU()(h)\n",
    "h = layers.Reshape((layer_steps[0], conv_units[0] * 2))(h)\n",
    "assert h.shape[1] == layer_steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "camada = tf.keras.Model(input_layer, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7424)              749824    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7424)              29696     \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 7424)              0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 29, 256)           0         \n",
      "=================================================================\n",
      "Total params: 779,520\n",
      "Trainable params: 764,672\n",
      "Non-trainable params: 14,848\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "camada.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 29, 256])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = tf.random.normal((10,100))\n",
    "camada(z).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
