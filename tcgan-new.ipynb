{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "c:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fire\n",
    "\n",
    "from mlpy.lib.utils.path import makedirs, tag_path\n",
    "from mlpy.lib.utils.log import set_logging\n",
    "from mlpy.lib.tfops.base import tf_keras_set_gpu_allow_growth\n",
    "from mlpy.configure import DIR_DATA_UCR15\n",
    "from mlpy.datasets.ucr_uea.data_names import UCR85_DATASETS\n",
    "\n",
    "from tcgan.lib.exp import Experiment\n",
    "from configure import DIR_LOG\n",
    "from tcgan.model.tcgan import TCGAN, TCGANConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/10 12:03:13 AM, INFO, github_: ****** process dataset 50words\n",
      "use_testset=True\n",
      "09/10 12:03:13 AM, INFO, github__50words: ****** configure init ******\n",
      "09/10 12:03:14 AM, INFO, github__50words: The settings are as follows: \n",
      "strides:2\n",
      "padding:same\n",
      "initializer:<tensorflow.python.keras.initializers.initializers_v2.TruncatedNormal object at 0x000001C21CB62DD8>\n",
      "leak_slope:0.2\n",
      "logger:<Logger github__50words (INFO)>\n",
      "log_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\n",
      "train_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\\training\n",
      "eval_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\\evaluation\n",
      "ckpt_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\\checkpoint\n",
      "ckpt_prefix:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\0\\50words\\checkpoint\\ckpt\n",
      "seed:42\n",
      "np_rs:RandomState(MT19937)\n",
      "verbose:1\n",
      "x_shape:(270, 1)\n",
      "noise_shape:(100,)\n",
      "noise_method:normal\n",
      "noise_sampler:<function random_normal at 0x000001C27DA2CB70>\n",
      "batch_size:16\n",
      "epochs:300\n",
      "g_lr:0.0002\n",
      "d_lr:0.0002\n",
      "g_beta1:0.5\n",
      "d_beta1:0.5\n",
      "g_units_base:32\n",
      "d_units_base:32\n",
      "d_layers:4\n",
      "g_layers:4\n",
      "d_dropout_rate:0.0\n",
      "g_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "d_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "kernel_size:10\n",
      "acc_threshold_to_train_d:0.75\n",
      "ckpt_max_to_keep:2\n",
      "n_epochs_to_save_ckpt:15\n",
      "n_to_evaluate:3\n",
      "n_epochs_to_evaluate:100\n",
      "n_examples_to_generate:16\n",
      "metrics:['nnd', 'mmd', 'vis']\n",
      "noise_seed:[[-0.28077507 -0.1377521  -0.6763296  ... -0.66411126  1.4531434\n",
      "   0.63142705]\n",
      " [ 1.4347553  -0.9590058   1.399536   ...  0.09790254 -0.8498453\n",
      "   0.8285087 ]\n",
      " [ 0.9079667  -0.53826797 -0.75165933 ...  0.00500222  0.46697247\n",
      "  -0.49156648]\n",
      " ...\n",
      " [ 1.0430238  -0.2649641  -0.44542065 ... -0.44225916  0.05121567\n",
      "   0.56583524]\n",
      " [-0.35650563  1.5591161   0.22819136 ...  1.8435367  -0.66581184\n",
      "  -0.97975284]\n",
      " [-1.3944459  -0.31205386  0.46640927 ... -0.12672192  2.9069102\n",
      "  -1.0910585 ]]\n",
      "\n",
      "Reuse layer=-3 for classification.\n",
      "(270, 1)\n",
      "09/10 12:03:15 AM, INFO, github__50words: Generator's summary: \n",
      "09/10 12:03:15 AM, INFO, github__50words: Model: \"functional_1\"\n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: Layer (type)                 Output Shape              Param #   \n",
      "09/10 12:03:15 AM, INFO, github__50words: =================================================================\n",
      "09/10 12:03:15 AM, INFO, github__50words: input_1 (InputLayer)         [(None, 100)]             0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: dense_0_dense (Dense)        (None, 4352)              439552    \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: dense_0_norm (BatchNormaliza (None, 4352)              17408     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: dense_0_relu (ReLU)          (None, 4352)              0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: reshape (Reshape)            (None, 17, 256)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_conv (Conv1DTranspose (None, 34, 128)           327808    \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_norm (BatchNormalizat (None, 34, 128)           512       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_relu (ReLU)           (None, 34, 128)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_conv (Conv1DTranspose (None, 68, 64)            81984     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_norm (BatchNormalizat (None, 68, 64)            256       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_relu (ReLU)           (None, 68, 64)            0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_conv (Conv1DTranspose (None, 135, 32)           20512     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_norm (BatchNormalizat (None, 135, 32)           128       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_relu (ReLU)           (None, 135, 32)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_conv (Conv1DTranspose (None, 270, 1)            321       \n",
      "09/10 12:03:15 AM, INFO, github__50words: =================================================================\n",
      "09/10 12:03:15 AM, INFO, github__50words: Total params: 888,481\n",
      "09/10 12:03:15 AM, INFO, github__50words: Trainable params: 879,329\n",
      "09/10 12:03:15 AM, INFO, github__50words: Non-trainable params: 9,152\n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: Discriminator's summary: \n",
      "09/10 12:03:15 AM, INFO, github__50words: Model: \"functional_3\"\n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: Layer (type)                 Output Shape              Param #   \n",
      "09/10 12:03:15 AM, INFO, github__50words: =================================================================\n",
      "09/10 12:03:15 AM, INFO, github__50words: input_2 (InputLayer)         [(None, 270, 1)]          0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_conv (Conv1D)         (None, 135, 32)           352       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_relu (LeakyReLU)      (None, 135, 32)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_0_dropout (Dropout)     (None, 135, 32)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_conv (Conv1D)         (None, 68, 64)            20544     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_relu (LeakyReLU)      (None, 68, 64)            0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_1_dropout (Dropout)     (None, 68, 64)            0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_conv (Conv1D)         (None, 34, 128)           82048     \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_norm (BatchNormalizat (None, 34, 128)           512       \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_relu (LeakyReLU)      (None, 34, 128)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_2_dropout (Dropout)     (None, 34, 128)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_conv (Conv1D)         (None, 17, 256)           327936    \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_norm (BatchNormalizat (None, 17, 256)           1024      \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_relu (LeakyReLU)      (None, 17, 256)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: conv_3_dropout (Dropout)     (None, 17, 256)           0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: flatten (Flatten)            (None, 4352)              0         \n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: dense (Dense)                (None, 1)                 4353      \n",
      "09/10 12:03:15 AM, INFO, github__50words: =================================================================\n",
      "09/10 12:03:15 AM, INFO, github__50words: Total params: 436,769\n",
      "09/10 12:03:15 AM, INFO, github__50words: Trainable params: 436,001\n",
      "09/10 12:03:15 AM, INFO, github__50words: Non-trainable params: 768\n",
      "09/10 12:03:15 AM, INFO, github__50words: _________________________________________________________________\n",
      "09/10 12:03:15 AM, INFO, github__50words: ****** fit start ******\n",
      "09/10 12:03:15 AM, INFO, github__50words: train from scratch.\n",
      "09/10 12:03:16 AM, INFO, github__50words: ****** eval start ******\n",
      "09/10 12:03:17 AM, INFO, github__50words: tsne, time=1.0196175575256348\n",
      "09/10 12:03:17 AM, INFO, github__50words: nnd, time=0.08635735511779785\n",
      "09/10 12:03:18 AM, INFO, github__50words: mmd, time=0.7134261131286621\n",
      "09/10 12:03:18 AM, INFO, github__50words: ****** eval end ******\n",
      "09/10 12:03:24 AM, INFO, github__50words: epoch[1/300], d_loss=0.7246, g_loss=1.028, real_loss=0.1916, fake_loss=0.533, acc=0.811, , time=6.228\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-156bafc8c3c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                     **exp_cfg)\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mfire\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\fire\\core.py\u001b[0m in \u001b[0;36mFire\u001b[1;34m(component, command, name)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaller_locals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m   \u001b[0mcomponent_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Fire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparsed_flag_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcomponent_trace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHasError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\fire\\core.py\u001b[0m in \u001b[0;36m_Fire\u001b[1;34m(component, args, parsed_flag_args, context, name)\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[0mcomponent_trace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[0mtreatment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'class'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_class\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'routine'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m             target=component.__name__)\n\u001b[0m\u001b[0;32m    472\u001b[0m         \u001b[0mhandled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mFireError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\fire\\core.py\u001b[0m in \u001b[0;36m_CallAndUpdateTrace\u001b[1;34m(component, args, component_trace, treatment, target)\u001b[0m\n\u001b[0;32m    679\u001b[0m     \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvarargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m     \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvarargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtreatment\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\exp.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, i_run)\u001b[0m\n\u001b[0;32m    236\u001b[0m                                         \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                                         **self.kwargs)\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mexp_unit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_name_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres_eval_fnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres_out_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\exp.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\lib\\exp.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvaluatorGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_tr_gan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_te_gan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\tcgan\\model\\tcgan\\tcgan.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data, test_data, restore, ckpt_number)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_sampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[0m_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[0m_res_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\dami_\\anaconda3\\envs\\tcgan\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tag = tag_path(os.path.abspath(os.getcwd()), 2)\n",
    "log_dir = makedirs(os.path.join(DIR_LOG, tag))\n",
    "logger = set_logging(tag, log_dir)\n",
    "# data_name_list = UCR85_DATASETS\n",
    "data_name_list = ['50words']\n",
    "\n",
    "model_cfg = dict(acc_threshold_to_train_d=0.75, kernel_size=10)\n",
    "exp_cfg = dict(use_testset=True, idx_layer=-3)\n",
    "exp = Experiment(tag, TCGAN, TCGANConfig, DIR_DATA_UCR15, data_name_list, log_dir,\n",
    "                    model_cfg_kwargs=model_cfg,\n",
    "                    **exp_cfg)\n",
    "\n",
    "fire.Fire(exp.run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sines data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mlpy.lib.utils.path import makedirs\n",
    "\n",
    "DIR_DATA = './TimeGANSine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine_data_generation(no, seq_len, dim):\n",
    "    \"\"\" copy from: https://github.com/jsyoon0823/TimeGAN/blob/master/data_loading.py\n",
    "    Sine data generation.\n",
    "\n",
    "  Args:\n",
    "    - no: the number of samples\n",
    "    - seq_len: sequence length of the time-series\n",
    "    - dim: feature dimensions\n",
    "\n",
    "  Returns:\n",
    "    - data: generated data\n",
    "  \"\"\"\n",
    "    # Initialize the output\n",
    "    data = list()\n",
    "\n",
    "    # Generate sine data\n",
    "    for i in range(no):\n",
    "        # Initialize each time-series\n",
    "        temp = list()\n",
    "        # For each feature\n",
    "        for k in range(dim):\n",
    "            # Randomly drawn frequency and phase\n",
    "            freq = np.random.uniform(0, 0.1)\n",
    "            phase = np.random.uniform(0, 0.1)\n",
    "\n",
    "            # Generate sine signal based on the drawn frequency and phase\n",
    "            temp_data = [np.sin(freq * j + phase) for j in range(seq_len)]\n",
    "            temp.append(temp_data)\n",
    "\n",
    "        # Align row/column\n",
    "        temp = np.transpose(np.asarray(temp))\n",
    "        # Normalize to [0,1]\n",
    "        temp = (temp + 1) * 0.5\n",
    "        # Stack the generated data\n",
    "        data.append(temp)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def sine_dim5_len24_random(r=0):  # the primitive data\n",
    "    seq_len = 24\n",
    "    no, dim = 10000, 5\n",
    "    data = sine_data_generation(no, seq_len, dim)\n",
    "    data = np.stack(data)\n",
    "    np.save(os.path.join(DIR_DATA, f'sine_dim{dim}_len{seq_len}_r{r}'), data)\n",
    "\n",
    "\n",
    "def sine_dim1_len100_random(r=0):\n",
    "    seq_len = 100\n",
    "    no, dim = 10000, 1\n",
    "    data = sine_data_generation(no, seq_len, dim)\n",
    "    data = np.stack(data)\n",
    "    np.save(os.path.join(DIR_DATA, f'sine_dim{dim}_len{seq_len}_r{r}'), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(DIR_DATA)\n",
    "\n",
    "# Prepare datasets for for multiple random runs.\n",
    "for r in range(5):\n",
    "    sine_dim5_len24_random(r)\n",
    "\n",
    "for r in range(5):\n",
    "    sine_dim1_len100_random(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√≥ximos passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = tag_path(os.path.abspath(os.getcwd()), 2)\n",
    "log_dir = makedirs(os.path.join(DIR_LOG, tag))\n",
    "logger = set_logging(tag, log_dir)\n",
    "# data_name_list = UCR85_DATASETS\n",
    "data_name_list = ['50words']\n",
    "\n",
    "model_cfg = dict(acc_threshold_to_train_d=0.75, kernel_size=10)\n",
    "exp_cfg = dict(use_testset=True, idx_layer=-3)\n",
    "exp = Experiment(tag, TCGAN, TCGANConfig, DIR_DATA_UCR15, data_name_list, log_dir,\n",
    "                    model_cfg_kwargs=model_cfg,\n",
    "                    **exp_cfg)\n",
    "\n",
    "fire.Fire(exp.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlpy.lib.data.utils import train_test_split, one_hot_to_dense\n",
    "import tensorflow as tf\n",
    "from tcgan.lib.eval import EvaluatorGAN, EvaluatorClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 271) (455, 271)\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Meu Drive\\\\Doutorado Unicamp\\\\Projeto\\\\github\\\\tcgan\\\\raw-data\\\\UCR_TS_Archive_2015\\\\50words\\\\50words_TRAIN'\n",
    "data_train = np.genfromtxt(path, delimiter=',', dtype=np.float32)\n",
    "path = 'C:\\\\Meu Drive\\\\Doutorado Unicamp\\\\Projeto\\\\github\\\\tcgan\\\\raw-data\\\\UCR_TS_Archive_2015\\\\50words\\\\50words_TEST'\n",
    "data_test = np.genfromtxt(path, delimiter=',', dtype=np.float32)\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse\n",
    "x_tr = data_train[:, 1::]\n",
    "y_tr = data_train[:, 0].astype(int)\n",
    "x_te = data_test[:, 1::]\n",
    "y_te = data_test[:, 0].astype(int)\n",
    "y_all = np.concatenate([y_tr, y_te])\n",
    "classes, y_all = np.unique(y_all, return_inverse=True)\n",
    "n_class = len(classes)\n",
    "x_tr = x_tr[..., np.newaxis]\n",
    "x_te = x_te[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data can be used in unsupervised learning\n",
    "x_all = np.vstack([x_tr, x_te])\n",
    "_, x_te_gan, _, _ = train_test_split(\n",
    "    x_all, y_all, train_size=0.9, random_state=42, stratify=y_all)\n",
    "x_tr_gan = x_all  # use all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/10 12:07:18 AM, INFO, github_: ****** configure init ******\n",
      "09/10 12:07:19 AM, INFO, github_: The settings are as follows: \n",
      "strides:2\n",
      "padding:same\n",
      "initializer:<tensorflow.python.keras.initializers.initializers_v2.TruncatedNormal object at 0x00000177DBEA8C50>\n",
      "leak_slope:0.2\n",
      "logger:<Logger github_ (INFO)>\n",
      "log_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\n",
      "train_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\training\n",
      "eval_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\evaluation\n",
      "ckpt_dir:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\checkpoint\n",
      "ckpt_prefix:c:\\Meu Drive\\Doutorado Unicamp\\Projeto\\github\\tcgan\\cache\\github_\\checkpoint\\ckpt\n",
      "seed:42\n",
      "np_rs:RandomState(MT19937)\n",
      "verbose:1\n",
      "x_shape:(270, 1)\n",
      "noise_shape:(100,)\n",
      "noise_method:normal\n",
      "noise_sampler:<function random_normal at 0x00000177BD0A5B70>\n",
      "batch_size:16\n",
      "epochs:300\n",
      "g_lr:0.0002\n",
      "d_lr:0.0002\n",
      "g_beta1:0.5\n",
      "d_beta1:0.5\n",
      "g_units_base:32\n",
      "d_units_base:32\n",
      "d_layers:4\n",
      "g_layers:4\n",
      "d_dropout_rate:0.0\n",
      "g_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "d_norm:<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>\n",
      "kernel_size:10\n",
      "acc_threshold_to_train_d:0.75\n",
      "ckpt_max_to_keep:2\n",
      "n_epochs_to_save_ckpt:15\n",
      "n_to_evaluate:3\n",
      "n_epochs_to_evaluate:100\n",
      "n_examples_to_generate:16\n",
      "metrics:['nnd', 'mmd', 'vis']\n",
      "noise_seed:[[-0.28077507 -0.1377521  -0.6763296  ... -0.66411126  1.4531434\n",
      "   0.63142705]\n",
      " [ 1.4347553  -0.9590058   1.399536   ...  0.09790254 -0.8498453\n",
      "   0.8285087 ]\n",
      " [ 0.9079667  -0.53826797 -0.75165933 ...  0.00500222  0.46697247\n",
      "  -0.49156648]\n",
      " ...\n",
      " [ 1.0430238  -0.2649641  -0.44542065 ... -0.44225916  0.05121567\n",
      "   0.56583524]\n",
      " [-0.35650563  1.5591161   0.22819136 ...  1.8435367  -0.66581184\n",
      "  -0.97975284]\n",
      " [-1.3944459  -0.31205386  0.46640927 ... -0.12672192  2.9069102\n",
      "  -1.0910585 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_tr.shape[1:]\n",
    "# input_shape = x_tr_gan.shape\n",
    "tag = tag_path(os.path.abspath(os.getcwd()), 2)\n",
    "log_dir = makedirs(os.path.join(DIR_LOG, tag))\n",
    "logger = set_logging(tag, log_dir)\n",
    "model_cfg = TCGANConfig(input_shape, log_dir, logger, **dict(acc_threshold_to_train_d=0.75, kernel_size=10))\n",
    "evaluator = EvaluatorGAN(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/10 12:07:25 AM, INFO, github_: Generator's summary: \n",
      "09/10 12:07:25 AM, INFO, github_: Model: \"functional_1\"\n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: Layer (type)                 Output Shape              Param #   \n",
      "09/10 12:07:25 AM, INFO, github_: =================================================================\n",
      "09/10 12:07:25 AM, INFO, github_: input_1 (InputLayer)         [(None, 100)]             0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: dense_0_dense (Dense)        (None, 4352)              439552    \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: dense_0_norm (BatchNormaliza (None, 4352)              17408     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: dense_0_relu (ReLU)          (None, 4352)              0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: reshape (Reshape)            (None, 17, 256)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_conv (Conv1DTranspose (None, 34, 128)           327808    \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_norm (BatchNormalizat (None, 34, 128)           512       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_relu (ReLU)           (None, 34, 128)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_conv (Conv1DTranspose (None, 68, 64)            81984     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_norm (BatchNormalizat (None, 68, 64)            256       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_relu (ReLU)           (None, 68, 64)            0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_conv (Conv1DTranspose (None, 135, 32)           20512     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_norm (BatchNormalizat (None, 135, 32)           128       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_relu (ReLU)           (None, 135, 32)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_conv (Conv1DTranspose (None, 270, 1)            321       \n",
      "09/10 12:07:25 AM, INFO, github_: =================================================================\n",
      "09/10 12:07:25 AM, INFO, github_: Total params: 888,481\n",
      "09/10 12:07:25 AM, INFO, github_: Trainable params: 879,329\n",
      "09/10 12:07:25 AM, INFO, github_: Non-trainable params: 9,152\n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: Discriminator's summary: \n",
      "09/10 12:07:25 AM, INFO, github_: Model: \"functional_3\"\n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: Layer (type)                 Output Shape              Param #   \n",
      "09/10 12:07:25 AM, INFO, github_: =================================================================\n",
      "09/10 12:07:25 AM, INFO, github_: input_2 (InputLayer)         [(None, 270, 1)]          0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_conv (Conv1D)         (None, 135, 32)           352       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_relu (LeakyReLU)      (None, 135, 32)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_0_dropout (Dropout)     (None, 135, 32)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_conv (Conv1D)         (None, 68, 64)            20544     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_relu (LeakyReLU)      (None, 68, 64)            0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_1_dropout (Dropout)     (None, 68, 64)            0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_conv (Conv1D)         (None, 34, 128)           82048     \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_norm (BatchNormalizat (None, 34, 128)           512       \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_relu (LeakyReLU)      (None, 34, 128)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_2_dropout (Dropout)     (None, 34, 128)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_conv (Conv1D)         (None, 17, 256)           327936    \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_norm (BatchNormalizat (None, 17, 256)           1024      \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_relu (LeakyReLU)      (None, 17, 256)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: conv_3_dropout (Dropout)     (None, 17, 256)           0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: flatten (Flatten)            (None, 4352)              0         \n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: dense (Dense)                (None, 1)                 4353      \n",
      "09/10 12:07:25 AM, INFO, github_: =================================================================\n",
      "09/10 12:07:25 AM, INFO, github_: Total params: 436,769\n",
      "09/10 12:07:25 AM, INFO, github_: Trainable params: 436,001\n",
      "09/10 12:07:25 AM, INFO, github_: Non-trainable params: 768\n",
      "09/10 12:07:25 AM, INFO, github_: _________________________________________________________________\n",
      "09/10 12:07:25 AM, INFO, github_: ****** fit start ******\n",
      "09/10 12:07:25 AM, INFO, github_: train from scratch.\n",
      "09/10 12:07:26 AM, INFO, github_: ****** eval start ******\n",
      "09/10 12:07:27 AM, INFO, github_: tsne, time=0.7368571758270264\n",
      "09/10 12:07:27 AM, INFO, github_: nnd, time=0.046428680419921875\n",
      "09/10 12:07:28 AM, INFO, github_: mmd, time=1.5061471462249756\n",
      "09/10 12:07:28 AM, INFO, github_: ****** eval end ******\n",
      "09/10 12:07:33 AM, INFO, github_: epoch[1/300], d_loss=0.7177, g_loss=1.031, real_loss=0.189, fake_loss=0.5288, acc=0.8317, , time=4.63\n",
      "09/10 12:07:34 AM, INFO, github_: epoch[2/300], d_loss=0.8769, g_loss=1.724, real_loss=0.4643, fake_loss=0.4126, acc=0.8126, , time=1.569\n",
      "09/10 12:07:36 AM, INFO, github_: epoch[3/300], d_loss=1.332, g_loss=1.065, real_loss=0.6881, fake_loss=0.6436, acc=0.6323, , time=1.82\n",
      "09/10 12:07:38 AM, INFO, github_: epoch[4/300], d_loss=1.179, g_loss=1.117, real_loss=0.607, fake_loss=0.5725, acc=0.6931, , time=1.977\n",
      "09/10 12:07:40 AM, INFO, github_: epoch[5/300], d_loss=1.105, g_loss=1.067, real_loss=0.5581, fake_loss=0.547, acc=0.7315, , time=1.751\n",
      "09/10 12:07:42 AM, INFO, github_: epoch[6/300], d_loss=1.048, g_loss=1.097, real_loss=0.5242, fake_loss=0.5243, acc=0.756, , time=1.789\n",
      "09/10 12:07:44 AM, INFO, github_: epoch[7/300], d_loss=1.028, g_loss=1.145, real_loss=0.5129, fake_loss=0.5151, acc=0.7632, , time=2.116\n",
      "09/10 12:07:46 AM, INFO, github_: epoch[8/300], d_loss=1.042, g_loss=1.146, real_loss=0.5076, fake_loss=0.534, acc=0.7538, , time=2.069\n",
      "09/10 12:07:48 AM, INFO, github_: epoch[9/300], d_loss=0.9794, g_loss=1.104, real_loss=0.4718, fake_loss=0.5076, acc=0.7957, , time=2.103\n",
      "09/10 12:07:50 AM, INFO, github_: epoch[10/300], d_loss=1.036, g_loss=1.124, real_loss=0.5048, fake_loss=0.5316, acc=0.7529, , time=2.109\n",
      "09/10 12:07:52 AM, INFO, github_: epoch[11/300], d_loss=1.046, g_loss=1.111, real_loss=0.5259, fake_loss=0.5199, acc=0.7396, , time=2.101\n",
      "09/10 12:07:54 AM, INFO, github_: epoch[12/300], d_loss=1.027, g_loss=1.111, real_loss=0.5088, fake_loss=0.518, acc=0.7401, , time=2.191\n",
      "09/10 12:07:56 AM, INFO, github_: epoch[13/300], d_loss=0.9957, g_loss=1.115, real_loss=0.4957, fake_loss=0.5, acc=0.7865, , time=2.011\n",
      "09/10 12:07:59 AM, INFO, github_: epoch[14/300], d_loss=1.069, g_loss=1.079, real_loss=0.5248, fake_loss=0.5442, acc=0.7447, , time=2.274\n",
      "09/10 12:08:01 AM, INFO, github_: epoch[15/300], d_loss=1.027, g_loss=1.138, real_loss=0.5209, fake_loss=0.5061, acc=0.7578, , time=2.523\n",
      "09/10 12:08:05 AM, INFO, github_: epoch[16/300], d_loss=1.031, g_loss=1.09, real_loss=0.4992, fake_loss=0.5321, acc=0.7668, , time=2.697\n",
      "09/10 12:08:07 AM, INFO, github_: epoch[17/300], d_loss=1.027, g_loss=1.147, real_loss=0.5186, fake_loss=0.5082, acc=0.7517, , time=2.63\n",
      "09/10 12:08:10 AM, INFO, github_: epoch[18/300], d_loss=1.037, g_loss=1.057, real_loss=0.5009, fake_loss=0.5365, acc=0.7584, , time=2.613\n",
      "09/10 12:08:13 AM, INFO, github_: epoch[19/300], d_loss=1.058, g_loss=1.101, real_loss=0.5307, fake_loss=0.5271, acc=0.7542, , time=2.933\n",
      "09/10 12:08:16 AM, INFO, github_: epoch[20/300], d_loss=1.036, g_loss=1.052, real_loss=0.497, fake_loss=0.5393, acc=0.7698, , time=2.624\n",
      "09/10 12:08:18 AM, INFO, github_: epoch[21/300], d_loss=1.035, g_loss=1.102, real_loss=0.5098, fake_loss=0.5252, acc=0.76, , time=2.504\n",
      "09/10 12:08:20 AM, INFO, github_: epoch[22/300], d_loss=1.072, g_loss=1.026, real_loss=0.5134, fake_loss=0.5587, acc=0.7438, , time=2.355\n",
      "09/10 12:08:23 AM, INFO, github_: epoch[23/300], d_loss=1.051, g_loss=1.029, real_loss=0.5011, fake_loss=0.5497, acc=0.7445, , time=2.221\n",
      "09/10 12:08:25 AM, INFO, github_: epoch[24/300], d_loss=1.014, g_loss=1.129, real_loss=0.525, fake_loss=0.4893, acc=0.772, , time=2.459\n"
     ]
    }
   ],
   "source": [
    "model = TCGAN(model_cfg, evaluator)\n",
    "model.fit(x_tr_gan, x_te_gan)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
